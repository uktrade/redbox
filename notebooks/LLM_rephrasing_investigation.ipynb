{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "from redbox.app import Redbox\n",
    "from redbox.models.chain import AISettings, ChatLLMBackend, RedboxQuery, RedboxState\n",
    "from redbox.models.settings import get_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(user_uuid, prompts, documents, ai_setting):\n",
    "    q = RedboxQuery(\n",
    "        question=f\"@search {prompts[-1]}\",\n",
    "        s3_keys=documents,\n",
    "        user_uuid=user_uuid,\n",
    "        chat_history=prompts[:-1],\n",
    "        ai_settings=ai_setting,\n",
    "        permitted_s3_keys=documents,\n",
    "    )\n",
    "\n",
    "    return RedboxState(\n",
    "        request=q,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_app(app, state) -> RedboxState:\n",
    "    langfuse_handler = CallbackHandler()\n",
    "    return app.graph.invoke(state, config={\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic configuration\n",
    "env = get_settings()\n",
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "app = Redbox(debug=True, env=env)\n",
    "documents = [\"adela.iliescu@digital.trade.gov.uk/179._Design_Council.pdf\"]\n",
    "user_prompt = [\"How does the exposure to AI vary across different geographical areas?\"]\n",
    "\n",
    "x = get_state(uuid4(), prompts=[user_prompt], documents=documents, ai_setting=ai_setting)\n",
    "result = run_app(app, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single question\n",
    "env = get_settings()\n",
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "app = Redbox(debug=True, env=env)\n",
    "documents = [\"adela.iliescu@digital.trade.gov.uk/1 The power chapter.pdf\"]\n",
    "user_prompt = \"How does the exposure to AI vary across different geographical areas?\"\n",
    "\n",
    "llm_rephrased = []\n",
    "final_answer = []\n",
    "for _i in range(5):\n",
    "    x = get_state(uuid4(), prompts=[user_prompt], documents=documents, ai_setting=ai_setting)\n",
    "    result = run_app(app, x)\n",
    "    llm_rephrased.append(result[\"messages\"][0].content)\n",
    "    final_answer.append(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\"\"User prompt: {user_prompt};\\n\n",
    "#       Rephrase 1: {llm_rephrased[0]};\\n\n",
    "#       Rephrase 2: {llm_rephrased[1]};\\n\n",
    "#       Rephrase 3: {llm_rephrased[2]};\\n\n",
    "#       Rephrase 4: {llm_rephrased[3]};\\n\n",
    "#       Rephrase 5: {llm_rephrased[4]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\"\"Answer 1: {final_answer[0]};\\n\n",
    "#       Answer 2: {final_answer[1]};\\n\n",
    "#       Answer 3: {final_answer[2]};\\n\n",
    "#       Answer 4: {final_answer[3]};\\n\n",
    "#       Answer 5: {final_answer[4]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several questions test (might take a while)\n",
    "env = get_settings()\n",
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "app = Redbox(debug=True, env=env)\n",
    "documents = [\"adela.iliescu@digital.trade.gov.uk/179._Design_Council.pdf\"]\n",
    "user_prompt_list = [\n",
    "    \"How does the exposure to AI vary across different geographical areas?\",\n",
    "    \"According to the US Bureau of Labor Statistics data released in 2018, \"\n",
    "    \"what percentage of those in “computer and mathematical occupations” \"\n",
    "    \"were women\",\n",
    "    \"What are the four domains of power within Patricia Hill Collins's matrix of domination\",\n",
    "    \"What are the main points?\",\n",
    "    \"What are some issues in data science?\",\n",
    "    \"Why is data important\",\n",
    "]\n",
    "# Separate dictionaries for rephrased prompts and answers\n",
    "results_prompt = {}\n",
    "results_answer = {}\n",
    "\n",
    "for user_prompt in user_prompt_list:\n",
    "    # Initialize empty lists for each user prompt\n",
    "    results_prompt[user_prompt] = []\n",
    "    results_answer[user_prompt] = []\n",
    "\n",
    "    for _i in range(5):\n",
    "        x = get_state(uuid4(), prompts=[user_prompt], documents=documents, ai_setting=ai_setting)\n",
    "        result = run_app(app, x)\n",
    "\n",
    "        results_prompt[user_prompt].append(result[\"messages\"][0].content)\n",
    "        results_answer[user_prompt].append(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Several questions test (might take a while)\n",
    "env = get_settings()\n",
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "app = Redbox(debug=True, env=env)\n",
    "documents = [\"adela.iliescu@digital.trade.gov.uk/179._Design_Council.pdf\"]\n",
    "user_prompt_list = [\n",
    "    \"What industries are most exposed to Large Language Models (LLM) according to the report?\",\n",
    "    \"How does the report define and assess AI application-ability relatedness \"\n",
    "    \"in its methodology for calculating occupational exposure?\",\n",
    "    \"What training routes are associated with the highest exposure to AI for early-career employees?\",\n",
    "    \"What is the impact of AI on jobs?\",\n",
    "    \"Tell me about AI in the UK\",\n",
    "]\n",
    "# Separate dictionaries for rephrased prompts and answers\n",
    "results_prompt = {}\n",
    "results_answer = {}\n",
    "\n",
    "for user_prompt in user_prompt_list:\n",
    "    # Initialize empty lists for each user prompt\n",
    "    results_prompt[user_prompt] = []\n",
    "    results_answer[user_prompt] = []\n",
    "\n",
    "    for _i in range(5):\n",
    "        x = get_state(uuid4(), prompts=[user_prompt], documents=documents, ai_setting=ai_setting)\n",
    "        result = run_app(app, x)\n",
    "\n",
    "        results_prompt[user_prompt].append(result[\"messages\"][0].content)\n",
    "        results_answer[user_prompt].append(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = app.graph.get_graph()\n",
    "graph.draw_mermaid_png(draw_method=MermaidDrawMethod.API, output_file_path=\"./graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = app.graph.get_graph().nodes[\"p_retrieve_metadata\"].data.get_graph()\n",
    "graph.draw_mermaid_png(draw_method=MermaidDrawMethod.API, output_file_path=\"./graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = app.graph.get_graph().nodes[\"p_search\"].data.get_graph()\n",
    "graph.draw_mermaid_png(draw_method=MermaidDrawMethod.API, output_file_path=\"./graph.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
