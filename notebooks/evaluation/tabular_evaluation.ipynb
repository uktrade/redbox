{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01b6929",
   "metadata": {},
   "source": [
    "## Download evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e9b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "url = 'https://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip'\n",
    "downloaded_file = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42897dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp dev.zip ./data/tabular/dev.zip\n",
    "!rm -r dev.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661bf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./data/tabular/dev.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/tabular/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a045f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/tabular/dev.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b924130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./data/tabular/dev_20240627/dev_databases.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/tabular/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf6eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/tabular/dev_20240627/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ebffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting table: account\n",
      "Exporting table: card\n",
      "Exporting table: client\n",
      "Exporting table: disp\n",
      "Exporting table: district\n",
      "Exporting table: loan\n",
      "Exporting table: order\n",
      "Exporting table: trans\n",
      "All tables exported successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "# Path to your SQLite database file\n",
    "db_path = './data/tabular/dev_databases/financial/financial.sqlite'\n",
    "# Directory where CSVs will be saved\n",
    "output_dir = './data/tabular/csv_tables'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "# Fetch all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "# Export each table to CSV\n",
    "for table_name_tuple in tables:\n",
    "    table_name = table_name_tuple[0]\n",
    "    print(f\"Exporting table: {table_name}\")\n",
    "    # Quote the table name to handle reserved keywords\n",
    "    df = pd.read_sql_query(f'SELECT * FROM \"{table_name}\"', conn)\n",
    "    csv_path = os.path.join(output_dir, f\"{table_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "# Cleanup\n",
    "conn.close()\n",
    "print(\"All tables exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96cb82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./data/tabular/dev_databases/financial/financial.sqlite ./data/tabular/financial.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0769506",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/tabular/dev_databases\n",
    "!rm -r ./data/tabular/__MACOSX/*\n",
    "!rm -r ./data/tabular/__MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925058bb",
   "metadata": {},
   "source": [
    "## Test Tabular route within Redbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc978483",
   "metadata": {},
   "source": [
    "Now that the csv files are downloaded, upload them into Redbox via the UI and execute the questions within the financial_dataset_original.json. Save the SQL statements into the financial_dataset_results.json.\n",
    "Do not upload the trans table as it is too big (3Millions rows). We will test questions that do not involve querying this table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57001771",
   "metadata": {},
   "source": [
    "Once finished, delete the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d332ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/tabular/csv_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452dff1",
   "metadata": {},
   "source": [
    "## Compare results against ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5c794",
   "metadata": {},
   "source": [
    "Read evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "322a98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/tabular/financial_dataset_results.json') as f:\n",
    "    eval_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29e8b3",
   "metadata": {},
   "source": [
    "select a record from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4aa3a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "row= eval_data[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14495e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 173,\n",
       " 'db_id': 'financial',\n",
       " 'question': 'How often does account number 3 request an account statement to be released? What was the aim of debiting 3539 in total?',\n",
       " 'evidence': 'k_symbol refers to the purpose of payments',\n",
       " 'SQL': 'SELECT T1.frequency, T2.k_symbol FROM account AS T1 INNER JOIN (SELECT account_id, k_symbol, SUM(amount) AS total_amount FROM `order` GROUP BY account_id, k_symbol) AS T2 ON T1.account_id = T2.account_id WHERE T1.account_id = 3 AND T2.total_amount = 3539',\n",
       " 'answer': 5,\n",
       " 'difficulty': 'challenging',\n",
       " 'SQL_redbox_without_evidence': 'SELECT k_symbol, COUNT(*) as count, SUM(amount) as total_amount FROM order_table_7 WHERE account_id = 3 GROUP BY k_symbol',\n",
       " 'SQL_redbox_with_evidence': 'None',\n",
       " 'redbox_answer_without_evidence': 'For the first question about how often account number 3 requests an account statement, there is no explicit data in the database tables that tracks statement requests..the aim of debiting 3539 in total appears to be for an insurance payment made from account number 3.',\n",
       " 'redbox_answer_with_evidence': 'Agent stopped due to iteration limit or time limit. 3 attempts',\n",
       " 'is_accurate_without_evidence': 0,\n",
       " 'is_accurate_with_evidence': 0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5166bf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT T1.frequency, T2.k_symbol FROM account AS T1 INNER JOIN (SELECT account_id, k_symbol, SUM(amount) AS total_amount FROM `order` GROUP BY account_id, k_symbol) AS T2 ON T1.account_id = T2.account_id WHERE T1.account_id = 3 AND T2.total_amount = 3539'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['SQL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba482fe6",
   "metadata": {},
   "source": [
    "Check Ground truth answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "601efd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('POPLATEK MESICNE', 'POJISTNE')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "import sqlite3\n",
    "db_path = './data/tabular/financial.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(row['SQL'])\n",
    "results = cursor.fetchall()\n",
    "conn.close()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b198e",
   "metadata": {},
   "source": [
    "Download generated sqlite database from the docker container. For this, you need to change processes.py to disable the deletion of the database file after each query. The code line need to be commented out: state = delete_db_file_if_exists(state) \n",
    "- Get the name of the local db file generated by tabular route: \n",
    "1. docker exec -it redbox-django-app-1 bash\n",
    "\n",
    "2. find . -name *.db\n",
    "- Download db file from the docker container to your local host\n",
    "\n",
    "3. docker cp redbox-django-app-1:/usr/src/app/<name_local_db_file>.db ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77d6e9",
   "metadata": {},
   "source": [
    "Check the answer when no evidence (external knowledge) is supplied. In this case, the prompt is the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0d25b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1, 327.0), ('POJISTNE', 1, 3539.0), ('SIPO', 1, 1135.0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "db_path = './data/tabular/generated_db_a2df5245-db22-4872-911c-6564340f9027.db' #replace the name of the local db here\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#check results of the SQL query when evidence is not defined in the prompt\n",
    "#in this case, the prompt is the question\n",
    "cursor.execute(row['SQL_redbox_without_evidence'])\n",
    "results = cursor.fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75fcee",
   "metadata": {},
   "source": [
    "Check the answer when evidence (external knowledge) is supplied. In this case, the prompt is the question + evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a7452b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12553044, 15736752, 25.36203967738821)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check results of the SQL query when evidence is added to the prompt\n",
    "#in this case, the prompt is the question + evidence\n",
    "\n",
    "cursor.execute(row['SQL_redbox_with_evidence'])\n",
    "results = cursor.fetchall()\n",
    "conn.close()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dda35",
   "metadata": {},
   "source": [
    "then record the accuracy in the financial_dataset_results.json. \n",
    "- is_accurate is 0 if the results from redbox does not match ground truth, otherwise it is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afadf0",
   "metadata": {},
   "source": [
    "## Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6a0f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_with_evidence_list = []\n",
    "for row in eval_data:\n",
    "    if row[\"evidence\"] != \"\":\n",
    "        accuracy_with_evidence_list.append(row[\"is_accurate_with_evidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b804fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_without_evidence_list = []\n",
    "for row in eval_data:\n",
    "    accuracy_without_evidence_list.append(row[\"is_accurate_without_evidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d1e2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "accuracy_without_evidence=sum(accuracy_without_evidence_list)/len(accuracy_without_evidence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4a790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy when evidence (external knowledge) is not defined in the prompt\n",
    "accuracy_without_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a8e1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_with_evidence=sum(accuracy_with_evidence_list)/len(accuracy_with_evidence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7103e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5357142857142857"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy when evidence (external knowledge) is in the prompt\n",
    "accuracy_with_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09ebfc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_with_evidence_notchallenging_list = []\n",
    "for row in eval_data:\n",
    "    if row[\"evidence\"] != \"\" and row[\"difficulty\"] != \"challenging\":\n",
    "        accuracy_with_evidence_notchallenging_list.append(row[\"is_accurate_with_evidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20fb8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_with_evidence_notchallenging=sum(accuracy_with_evidence_notchallenging_list)/len(accuracy_with_evidence_notchallenging_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b056c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy when evidence (external knowledge) is in the prompt excluding challenging questions\n",
    "accuracy_with_evidence_notchallenging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ceedd",
   "metadata": {},
   "source": [
    "Final Clean-up : Delete database files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a5997",
   "metadata": {},
   "source": [
    "delete database file of evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41d05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/tabular/financial.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970e172",
   "metadata": {},
   "source": [
    "delete local database file created by tabular agent. Use the following command and replace the name of the database:\n",
    "- !rm -r ./data/tabular/name_local_db_file>.db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redbox-app-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
