{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Empty Response Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import AsyncMock, patch, MagicMock\n",
    "from uuid import uuid4\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../tests/.env.test\")\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redbox_app.redbox_core.consumers import ChatConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.asyncio\n",
    "async def test_llm_conversation_with_empty_response():\n",
    "    consumer = ChatConsumer(scope={\"user\", MagicMock(id=uuid4())})\n",
    "\n",
    "    # Mock Chat and Files\n",
    "    mock_session = MagicMock()\n",
    "    mock_user = MagicMock(id=uuid4())\n",
    "    mock_file = MagicMock(unique_name=\"file1\")\n",
    "    selected_files = [mock_file]\n",
    "    permitted_files = [mock_file]\n",
    "\n",
    "    # Mock Chat Messages\n",
    "    chat_message1 = MagicMock(role=\"user\", text=\"Hello\")\n",
    "    chat_message2 = MagicMock(role=\"ai\", text=\"\")  # Blank\n",
    "    # replaced django_app.redbox_app.redbox_core.models.ChatMessage by redbox_app.redbox_core.models.ChatMessage\n",
    "    with (\n",
    "        patch(\"redbox_app.redbox_core.models.ChatMessage\") as mock_filter,\n",
    "        patch.object(consumer, \"get_ai_settings\", new_callable=AsyncMock) as mock_get_ai_settings,\n",
    "        patch.object(consumer.redbox, \"run\", new_callable=AsyncMock) as mock_redbox_run,\n",
    "        patch.object(consumer, \"send_to_client\", new_callable=AsyncMock) as mock_send_to_client,\n",
    "        patch.object(consumer, \"save_ai_message\", new_callable=AsyncMock),\n",
    "    ):\n",
    "        mock_filter.return_value.order_by.return_value.__aiter__.return_value = [chat_message1, chat_message2]\n",
    "        mock_get_ai_settings.return_value = {}\n",
    "        mock_redbox_run.return_value = {}\n",
    "\n",
    "        with pytest.raises(ValueError, match=\"Null LLM Response Received\"):\n",
    "            await consumer.llm_conversation(selected_files, mock_session, mock_user, \"Test Title\", permitted_files)\n",
    "        mock_send_to_client.assert_called()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_llm_conversation_with_empty_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
