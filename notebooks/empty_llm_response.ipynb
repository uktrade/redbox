{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Empty Response Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import AsyncMock, patch, MagicMock\n",
    "from uuid import uuid4\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../tests/.env.test')\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redbox_app.redbox_core.consumers import ChatConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.asyncio\n",
    "async def test_llm_conversation_with_empty_response():\n",
    "    consumer = ChatConsumer(scope={\"user\", MagicMock(id=uuid4())})\n",
    "\n",
    "    # Mock Chat and Files\n",
    "    mock_session = MagicMock()\n",
    "    mock_user = MagicMock(id=uuid4())\n",
    "    mock_file = MagicMock(unique_name=\"file1\")\n",
    "    selected_files = [mock_file]\n",
    "    permitted_files = [mock_file]\n",
    "\n",
    "    # Mock Chat Messages\n",
    "    chat_message1=MagicMock(role=\"user\", text=\"Hello\")\n",
    "    chat_message2=MagicMock(role=\"ai\", text=\"\") # Blank\n",
    "\n",
    "    with patch(\"django_app.redbox_app.redbox_core.models.ChatMessage\") as mock_filter, \\\n",
    "        patch.object(consumer, \"get_ai_settings\", new_callable=AsyncMock) as mock_get_ai_settings, \\\n",
    "        patch.object(consumer.redbox, \"run\", new_callable=AsyncMock) as mock_redbox_run, \\\n",
    "        patch.object(consumer, \"send_to_client\", new_callable=AsyncMock) as mock_send_to_client, \\\n",
    "        patch.object(consumer, \"save_ai_message\", new_callable=AsyncMock):\n",
    "        \n",
    "        mock_filter.return_value.order_by.return_value.__aiter__.return_value=[chat_message1, chat_message2]\n",
    "        mock_get_ai_settings.return_value={}\n",
    "        mock_redbox_run.return_value={}\n",
    "\n",
    "        with pytest.raises(ValueError, match=\"Null LLM Response Received\"):\n",
    "            await consumer.llm_conversation(selected_files, mock_session, mock_user,\"Test Title\", permitted_files)\n",
    "        mock_send_to_client.assert_called()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_llm_conversation_with_empty_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
