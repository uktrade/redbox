{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REACT AGENT: End-to-end example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook should be run in the /django-app directory, with venv compiled from poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redbox.models.chain import AISettings\n",
    "from redbox.chains.components import get_chat_llm\n",
    "from redbox.models.settings import ChatLLMBackend\n",
    "from redbox.models.settings import Settings\n",
    "from redbox.models.file import ChunkResolution\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from uuid import uuid4\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from redbox.graph.nodes.tools import build_search_wikipedia_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redbox state and query - modified from chain.py\n",
    "# changing classes from Basemodel to Typeddict or AgentState\n",
    "\n",
    "from typing import TypedDict\n",
    "from pydantic import Field\n",
    "from uuid import UUID\n",
    "from typing import Literal\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class ChainChatMessage(TypedDict):\n",
    "    role: Literal[\"user\", \"ai\", \"system\"]\n",
    "    text: str\n",
    "\n",
    "\n",
    "class MyRedboxQuery(TypedDict):\n",
    "    question: str = Field(description=\"The last user chat message\")\n",
    "    s3_keys: list[str] = Field(description=\"List of files to process\", default_factory=list)\n",
    "    user_uuid: UUID = Field(description=\"User the chain in executing for\")\n",
    "    chat_history: list[ChainChatMessage] = Field(description=\"All previous messages in chat (excluding question)\")\n",
    "    ai_settings: AISettings = Field(description=\"User request AI settings\", default_factory=AISettings)\n",
    "    permitted_s3_keys: list[str] = Field(description=\"List of permitted files for response\", default_factory=list)\n",
    "\n",
    "\n",
    "class MyRedboxState(AgentState):\n",
    "    # class MyRedboxState(BaseModel):\n",
    "    request: MyRedboxQuery\n",
    "    config: dict\n",
    "    # documents: Annotated[DocumentState, document_reducer] = DocumentState()\n",
    "    # route_name: str | None = None\n",
    "    # metadata: Annotated[RequestMetadata | None, metadata_reducer] = None\n",
    "    # citations: list[Citation] | None = None\n",
    "    # steps_left: Annotated[int | None, RemainingStepsManager] = None\n",
    "    messages: Annotated[list[AnyMessage], add_messages] = Field(default_factory=list)\n",
    "    # is_last_step: str\n",
    "\n",
    "    @property\n",
    "    def last_message(self) -> AnyMessage:\n",
    "        if not self.messages:\n",
    "            raise ValueError(\"No messages in the state\")\n",
    "        return self.messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools - adjusting code in tools.py script\n",
    "# changes: accessing states like this: state[] since we are using TypedDict instead of  Basemodel\n",
    "\n",
    "from typing import Annotated, Union\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from opensearchpy import OpenSearch\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings.embeddings import Embeddings\n",
    "from langchain_core.tools import Tool, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from redbox.api.format import format_documents\n",
    "from redbox.chains.components import get_embeddings\n",
    "from redbox.models.file import ChunkCreatorType, ChunkMetadata\n",
    "from redbox.models.settings import get_settings\n",
    "from redbox.retriever.queries import (\n",
    "    add_document_filter_scores_to_query,\n",
    "    build_document_query,\n",
    ")\n",
    "from redbox.retriever.retrievers import query_to_documents\n",
    "from redbox.transform import merge_documents, sort_documents, bedrock_tokeniser\n",
    "\n",
    "\n",
    "def build_search_documents_tool(\n",
    "    es_client: Union[Elasticsearch, OpenSearch],\n",
    "    index_name: str,\n",
    "    embedding_model: Embeddings,\n",
    "    embedding_field_name: str,\n",
    "    chunk_resolution: ChunkResolution | None,\n",
    ") -> Tool:\n",
    "    \"\"\"Constructs a tool that searches the index and sets state.documents.\"\"\"\n",
    "\n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def _search_documents(query: str, state: Annotated[MyRedboxState, InjectedState]) -> tuple[str, list[Document]]:\n",
    "        \"\"\"\n",
    "        Search for documents uploaded by the user based on a query string.\n",
    "\n",
    "        This function performs a search over the user's uploaded documents\n",
    "        and returns snippets from the documents ordered by relevance and\n",
    "        grouped by document.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query string used to match documents.\n",
    "                This could be a keyword, phrase, question, or text from\n",
    "                the documents.\n",
    "\n",
    "        Returns:\n",
    "            dict[str, Any]: A collection of document objects that match the query.\n",
    "        \"\"\"\n",
    "        query_vector = state[\"config\"][\"embedding_model\"].embed_query(query)\n",
    "        selected_files = state[\"request\"][\"s3_keys\"]\n",
    "        permitted_files = state[\"request\"][\"permitted_s3_keys\"]\n",
    "        ai_settings = state[\"request\"][\"ai_settings\"]\n",
    "\n",
    "        # Initial pass\n",
    "        initial_query = build_document_query(\n",
    "            query=query,\n",
    "            query_vector=query_vector,\n",
    "            selected_files=selected_files,\n",
    "            permitted_files=permitted_files,\n",
    "            embedding_field_name=state[\"config\"][\"embedding_field_name\"],\n",
    "            chunk_resolution=state[\"config\"][\"chunk_resolution\"],\n",
    "            ai_settings=ai_settings,\n",
    "        )\n",
    "        initial_documents = query_to_documents(\n",
    "            es_client=state[\"config\"][\"es_client\"], index_name=state[\"config\"][\"index_name\"], query=initial_query\n",
    "        )\n",
    "\n",
    "        # Handle nothing found (as when no files are permitted)\n",
    "        if not initial_documents:\n",
    "            return \"\", []\n",
    "\n",
    "            # Adjacent documents\n",
    "        with_adjacent_query = add_document_filter_scores_to_query(\n",
    "            elasticsearch_query=initial_query,\n",
    "            ai_settings=ai_settings,\n",
    "            centres=initial_documents,\n",
    "        )\n",
    "        adjacent_boosted = query_to_documents(\n",
    "            es_client=state[\"config\"][\"es_client\"], index_name=state[\"config\"][\"index_name\"], query=with_adjacent_query\n",
    "        )\n",
    "\n",
    "        # Merge and sort\n",
    "        merged_documents = merge_documents(initial=initial_documents, adjacent=adjacent_boosted)\n",
    "        sorted_documents = sort_documents(documents=merged_documents)\n",
    "\n",
    "        # Return as state update\n",
    "        return format_documents(sorted_documents), sorted_documents\n",
    "\n",
    "    return _search_documents\n",
    "\n",
    "\n",
    "def build_govuk_search_tool(filter=True) -> Tool:\n",
    "    \"\"\"Constructs a tool that searches gov.uk and sets state[\"documents\"].\"\"\"\n",
    "\n",
    "    tokeniser = bedrock_tokeniser\n",
    "\n",
    "    def recalculate_similarity(response, query, num_results):\n",
    "        embedding_model = get_embeddings(get_settings())\n",
    "        em_query = embedding_model.embed_query(query)\n",
    "        for r in response.get(\"results\"):\n",
    "            description = r.get(\"description\")\n",
    "            em_des = embedding_model.embed_query(description)\n",
    "            r[\"similarity\"] = cosine_similarity(np.array(em_query).reshape(1, -1), np.array(em_des).reshape(1, -1))[0][\n",
    "                0\n",
    "            ]\n",
    "        response[\"results\"] = sorted(response.get(\"results\"), key=lambda x: x[\"similarity\"], reverse=True)[:num_results]\n",
    "        return response\n",
    "\n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def _search_govuk(query: str, state: Annotated[MyRedboxState, InjectedState]) -> tuple[str, list[Document]]:\n",
    "        \"\"\"\n",
    "        Search for documents on gov.uk based on a query string.\n",
    "        This endpoint is used to search for documents on gov.uk. There are many types of documents on gov.uk.\n",
    "        Types include:\n",
    "        - guidance\n",
    "        - policy\n",
    "        - legislation\n",
    "        - news\n",
    "        - travel advice\n",
    "        - departmental reports\n",
    "        - statistics\n",
    "        - consultations\n",
    "        - appeals\n",
    "        \"\"\"\n",
    "\n",
    "        url_base = \"https://www.gov.uk\"\n",
    "        required_fields = [\n",
    "            \"format\",\n",
    "            \"title\",\n",
    "            \"description\",\n",
    "            \"indexable_content\",\n",
    "            \"link\",\n",
    "        ]\n",
    "        ai_settings = state[\"request\"][\"ai_settings\"]\n",
    "        response = requests.get(\n",
    "            f\"{url_base}/api/search.json\",\n",
    "            params={\n",
    "                \"q\": query,\n",
    "                \"count\": (\n",
    "                    ai_settings.tool_govuk_retrieved_results if filter else ai_settings.tool_govuk_returned_results\n",
    "                ),\n",
    "                \"fields\": required_fields,\n",
    "            },\n",
    "            headers={\"Accept\": \"application/json\"},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "\n",
    "        if filter:\n",
    "            response = recalculate_similarity(response, query, ai_settings.tool_govuk_returned_results)\n",
    "\n",
    "        mapped_documents = []\n",
    "        for i, doc in enumerate(response[\"results\"]):\n",
    "            if any(field not in doc for field in required_fields):\n",
    "                continue\n",
    "\n",
    "            mapped_documents.append(\n",
    "                Document(\n",
    "                    page_content=doc[\"indexable_content\"],\n",
    "                    metadata=ChunkMetadata(\n",
    "                        index=i,\n",
    "                        uri=f\"{url_base}{doc['link']}\",\n",
    "                        token_count=tokeniser(doc[\"indexable_content\"]),\n",
    "                        creator_type=ChunkCreatorType.gov_uk,\n",
    "                    ).model_dump(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return format_documents(mapped_documents), mapped_documents\n",
    "\n",
    "    return _search_govuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(user_uuid, prompts, documents, ai_setting):\n",
    "    redbox_query = MyRedboxQuery(\n",
    "        question=f\"{prompts[-1]}\",\n",
    "        s3_keys=documents,\n",
    "        user_uuid=user_uuid,\n",
    "        chat_history=prompts[:-1],\n",
    "        ai_settings=ai_setting,\n",
    "        permitted_s3_keys=documents,\n",
    "    )\n",
    "    return redbox_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD YOU DOCUMENTS AND QUESTION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "documents = [\"natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf\"]\n",
    "user_query = \"What is the impact of AI on UK jobs?\"\n",
    "# user_query = 'Who is Putin?'\n",
    "# user_query = 'How to renew my passport?'\n",
    "redbox_query = get_query(uuid4(), prompts=[user_query], documents=documents, ai_setting=ai_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redbox_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "embedding_model = BedrockEmbeddings(region_name=\"eu-west-2\", model_id=\"amazon.titan-embed-text-v2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "\n",
    "_env = Settings()\n",
    "\n",
    "search_documents = build_search_documents_tool(\n",
    "    es_client=_env.elasticsearch_client(),\n",
    "    index_name=_env.elastic_chunk_alias,\n",
    "    embedding_model=embedding_model,\n",
    "    embedding_field_name=_env.embedding_document_field_name,  # not used\n",
    "    chunk_resolution=ChunkResolution.normal,\n",
    ")\n",
    "search_wikipedia = build_search_wikipedia_tool()\n",
    "search_govuk = build_govuk_search_tool()\n",
    "\n",
    "agent_tool_names = [\"_search_documents\", \"_search_wikipedia\", \"_search_govuk\"]\n",
    "\n",
    "tools = {\n",
    "    \"_search_documents\": search_documents,\n",
    "    \"_search_govuk\": search_govuk,\n",
    "    \"_search_wikipedia\": search_wikipedia,\n",
    "}\n",
    "agent_tools = [tools[tool_name] for tool_name in agent_tool_names]\n",
    "\n",
    "# agent_tools = [search_documents]\n",
    "# agent_tools = [search_govuk]\n",
    "\n",
    "\n",
    "# ToolNode will automatically take care of injecting state into tools\n",
    "tool_node = ToolNode(agent_tools)\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_backend = ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\")\n",
    "llm = get_chat_llm(chat_backend, tools=agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"es_client\": _env.elasticsearch_client(),\n",
    "    \"index_name\": _env.elastic_chunk_alias,\n",
    "    \"embedding_model\": embedding_model,\n",
    "    \"embedding_field_name\": _env.embedding_document_field_name,  # not used\n",
    "    \"chunk_resolution\": ChunkResolution.normal,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [{\"type\": \"user\", \"content\": user_query}],\n",
    "    \"request\": redbox_query,\n",
    "    \"config\": config,\n",
    "    \"is_last_step\": False,\n",
    "    \"remaining_steps\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized prompt to avoid hallucinationa\n",
    "AGENTIC_RETRIEVAL_SYSTEM_PROMPT = (\n",
    "    \"You are an advanced problem-solving assistant. Your primary goal is to carefully \"\n",
    "    \"analyse and work through complex questions or problems. You will receive a collection \"\n",
    "    \"of documents (all at once, without any information about their order or iteration) and \"\n",
    "    \"a list of tool calls that have already been made (also without order or iteration \"\n",
    "    \"information). Based on this data, you are expected to think critically about how to \"\n",
    "    \"proceed.\\n\"\n",
    "    \"\\n\"\n",
    "    \"Objective:\\n\"\n",
    "    \"1. Your task is to answer user queries.\"\n",
    "    \"2. Examine the available documents and tool calls:\\n\"\n",
    "    \"- Evaluate whether the current information is sufficient to answer the question.\\n\"\n",
    "    \"- Consider the success or failure of previous tool calls based on the data they returned.\\n\"\n",
    "    \"- Hypothesise whether new tool calls might bring more valuable information.\\n\"\n",
    "    \"\\n\"\n",
    "    \"3. Decide whether you can answer this question:\\n\"\n",
    "    \"- If additional tool calls are likely to yield useful information, make those calls.\\n\"\n",
    "    \"- Determine whether the available documents contain the answer to the question. If the available documents contain the answer to the question, provide an answer. You must provide the citations where you use the information to answer.\\n\"\n",
    "    \"- Determine whether the available documents contain the answer to the question. If the available documents do not contain the answer to the question, say I don't know. Do not make up an answer.\"\n",
    "    \"Your role is to think deeply before taking any action. Carefully weigh whether new \"\n",
    "    \"information is necessary or helpful. Only take action (call tools or providing and answer) after \"\n",
    "    \"thorough evaluation of the current documents and tool calls.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(\n",
    "    llm, tools=agent_tools, state_schema=MyRedboxState, messages_modifier=AGENTIC_RETRIEVAL_SYSTEM_PROMPT, debug=True\n",
    ")  # , checkpointer=checkpointer) #, checkpointer=checkpointer) #, state_modifier=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMITATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop criteria hasn't been implemented and might cause GraphRecursionError. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
