{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REACT AGENT: End-to-end example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook should be run in the /django-app directory, with venv compiled from poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:the parsed url is ParseResult(scheme='http', netloc='admin:Opensearch2024^@localhost:9200', path='', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor,  tool\n",
    "from langchain import hub\n",
    "from redbox.models.chain import AISettings \n",
    "from redbox.chains.components import  get_chat_llm\n",
    "from redbox.models.settings import ChatLLMBackend\n",
    "from langchain_core.tools import StructuredTool\n",
    "from redbox.models.settings import Settings\n",
    "from redbox.models.file import ChunkResolution\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langchain.chat_models import init_chat_model\n",
    "from uuid import uuid4\n",
    "from langgraph.managed import IsLastStep\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.managed.is_last_step import RemainingStepsManager\n",
    "from redbox.graph.nodes.tools import build_search_wikipedia_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redbox state and query - modified from chain.py\n",
    "#changing classes from Basemodel to Typeddict or AgentState\n",
    "\n",
    "from typing import TypedDict\n",
    "from pydantic import Field\n",
    "from uuid import UUID\n",
    "from typing import Literal\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChainChatMessage(TypedDict):\n",
    "    role: Literal[\"user\", \"ai\", \"system\"]\n",
    "    text: str\n",
    "\n",
    "class MyRedboxQuery(TypedDict):\n",
    "    question: str = Field(description=\"The last user chat message\")\n",
    "    s3_keys: list[str] = Field(description=\"List of files to process\", default_factory=list)\n",
    "    user_uuid: UUID = Field(description=\"User the chain in executing for\")\n",
    "    chat_history: list[ChainChatMessage] = Field(description=\"All previous messages in chat (excluding question)\")\n",
    "    ai_settings: AISettings = Field(description=\"User request AI settings\", default_factory=AISettings)\n",
    "    permitted_s3_keys: list[str] = Field(description=\"List of permitted files for response\", default_factory=list)\n",
    "\n",
    "class MyRedboxState(AgentState):\n",
    "#class MyRedboxState(BaseModel):\n",
    "    request: MyRedboxQuery\n",
    "    config: dict\n",
    "    #documents: Annotated[DocumentState, document_reducer] = DocumentState()\n",
    "    #route_name: str | None = None\n",
    "    #metadata: Annotated[RequestMetadata | None, metadata_reducer] = None\n",
    "    #citations: list[Citation] | None = None\n",
    "    #steps_left: Annotated[int | None, RemainingStepsManager] = None\n",
    "    messages: Annotated[list[AnyMessage], add_messages] = Field(default_factory=list)\n",
    "    #is_last_step: str\n",
    "\n",
    "    @property\n",
    "    def last_message(self) -> AnyMessage:\n",
    "        if not self.messages:\n",
    "            raise ValueError(\"No messages in the state\")\n",
    "        return self.messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tools - adjusting code in tools.py script\n",
    "#changes: accessing states like this: state[] since we are using TypedDict instead of  Basemodel\n",
    "\n",
    "from typing import Annotated, Any, Iterable, get_args, get_origin, get_type_hints, Union\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from opensearchpy import OpenSearch\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings.embeddings import Embeddings\n",
    "from langchain_core.messages import ToolCall\n",
    "from langchain_core.tools import Tool, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from redbox.api.format import format_documents\n",
    "from redbox.chains.components import get_embeddings\n",
    "from redbox.models.file import ChunkCreatorType, ChunkMetadata, ChunkResolution\n",
    "from redbox.models.settings import get_settings\n",
    "from redbox.retriever.queries import (\n",
    "    add_document_filter_scores_to_query,\n",
    "    build_document_query,\n",
    ")\n",
    "from redbox.retriever.retrievers import query_to_documents\n",
    "from redbox.transform import (\n",
    "    merge_documents,\n",
    "    sort_documents,\n",
    "    bedrock_tokeniser\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def build_search_documents_tool(\n",
    "    es_client: Union[Elasticsearch, OpenSearch],\n",
    "    index_name: str,\n",
    "    embedding_model: Embeddings,\n",
    "    embedding_field_name: str,\n",
    "    chunk_resolution: ChunkResolution | None\n",
    ") -> Tool:\n",
    "    \"\"\"Constructs a tool that searches the index and sets state.documents.\"\"\"\n",
    "    \n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def _search_documents(query: str, state: Annotated[MyRedboxState, InjectedState]) -> tuple[str, list[Document]]:\n",
    "        \"\"\"\n",
    "            Search for documents uploaded by the user based on a query string.\n",
    "\n",
    "            This function performs a search over the user's uploaded documents\n",
    "            and returns snippets from the documents ordered by relevance and\n",
    "            grouped by document.\n",
    "\n",
    "            Args:\n",
    "                query (str): The search query string used to match documents.\n",
    "                    This could be a keyword, phrase, question, or text from\n",
    "                    the documents.\n",
    "\n",
    "            Returns:\n",
    "                dict[str, Any]: A collection of document objects that match the query.\n",
    "        \"\"\"\n",
    "        query_vector = state[\"config\"][\"embedding_model\"].embed_query(query)\n",
    "        selected_files = state[\"request\"][\"s3_keys\"]\n",
    "        permitted_files = state[\"request\"][\"permitted_s3_keys\"]\n",
    "        ai_settings = state[\"request\"][\"ai_settings\"]\n",
    "\n",
    "            # Initial pass\n",
    "        initial_query = build_document_query(\n",
    "                query=query,\n",
    "                query_vector=query_vector,\n",
    "                selected_files=selected_files,\n",
    "                permitted_files=permitted_files,\n",
    "                embedding_field_name=state[\"config\"][\"embedding_field_name\"],\n",
    "                chunk_resolution=state[\"config\"][\"chunk_resolution\"],\n",
    "                ai_settings=ai_settings,\n",
    "            )\n",
    "        initial_documents = query_to_documents(es_client=state[\"config\"][\"es_client\"], index_name=state[\"config\"][\"index_name\"], query=initial_query)\n",
    "\n",
    "            # Handle nothing found (as when no files are permitted)\n",
    "        if not initial_documents:\n",
    "            return \"\", []\n",
    "\n",
    "            # Adjacent documents\n",
    "        with_adjacent_query = add_document_filter_scores_to_query(\n",
    "                elasticsearch_query=initial_query,\n",
    "                ai_settings=ai_settings,\n",
    "                centres=initial_documents,\n",
    "            )\n",
    "        adjacent_boosted = query_to_documents(es_client=state[\"config\"][\"es_client\"], index_name=state[\"config\"][\"index_name\"], query=with_adjacent_query)\n",
    "\n",
    "            # Merge and sort\n",
    "        merged_documents = merge_documents(initial=initial_documents, adjacent=adjacent_boosted)\n",
    "        sorted_documents = sort_documents(documents=merged_documents)\n",
    "\n",
    "            # Return as state update\n",
    "        return format_documents(sorted_documents), sorted_documents\n",
    "\n",
    "    return _search_documents\n",
    "\n",
    "def build_govuk_search_tool(filter=True) -> Tool:\n",
    "    \"\"\"Constructs a tool that searches gov.uk and sets state[\"documents\"].\"\"\"\n",
    "\n",
    "    tokeniser = bedrock_tokeniser\n",
    "\n",
    "    def recalculate_similarity(response, query, num_results):\n",
    "        embedding_model = get_embeddings(get_settings())\n",
    "        em_query = embedding_model.embed_query(query)\n",
    "        for r in response.get(\"results\"):\n",
    "            description = r.get(\"description\")\n",
    "            em_des = embedding_model.embed_query(description)\n",
    "            r[\"similarity\"] = cosine_similarity(np.array(em_query).reshape(1, -1), np.array(em_des).reshape(1, -1))[0][\n",
    "                0\n",
    "            ]\n",
    "        response[\"results\"] = sorted(response.get(\"results\"), key=lambda x: x[\"similarity\"], reverse=True)[:num_results]\n",
    "        return response\n",
    "\n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def _search_govuk(query: str, state: Annotated[MyRedboxState, InjectedState]) -> tuple[str, list[Document]]:\n",
    "        \"\"\"\n",
    "        Search for documents on gov.uk based on a query string.\n",
    "        This endpoint is used to search for documents on gov.uk. There are many types of documents on gov.uk.\n",
    "        Types include:\n",
    "        - guidance\n",
    "        - policy\n",
    "        - legislation\n",
    "        - news\n",
    "        - travel advice\n",
    "        - departmental reports\n",
    "        - statistics\n",
    "        - consultations\n",
    "        - appeals\n",
    "        \"\"\"\n",
    "\n",
    "        url_base = \"https://www.gov.uk\"\n",
    "        required_fields = [\n",
    "            \"format\",\n",
    "            \"title\",\n",
    "            \"description\",\n",
    "            \"indexable_content\",\n",
    "            \"link\",\n",
    "        ]\n",
    "        ai_settings = state[\"request\"][\"ai_settings\"]\n",
    "        response = requests.get(\n",
    "            f\"{url_base}/api/search.json\",\n",
    "            params={\n",
    "                \"q\": query,\n",
    "                \"count\": (\n",
    "                    ai_settings.tool_govuk_retrieved_results if filter else ai_settings.tool_govuk_returned_results\n",
    "                ),\n",
    "                \"fields\": required_fields,\n",
    "            },\n",
    "            headers={\"Accept\": \"application/json\"},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "\n",
    "        if filter:\n",
    "            response = recalculate_similarity(response, query, ai_settings.tool_govuk_returned_results)\n",
    "\n",
    "        mapped_documents = []\n",
    "        for i, doc in enumerate(response[\"results\"]):\n",
    "            if any(field not in doc for field in required_fields):\n",
    "                continue\n",
    "\n",
    "            mapped_documents.append(\n",
    "                Document(\n",
    "                    page_content=doc[\"indexable_content\"],\n",
    "                    metadata=ChunkMetadata(\n",
    "                        index=i,\n",
    "                        uri=f\"{url_base}{doc['link']}\",\n",
    "                        token_count=tokeniser(doc[\"indexable_content\"]),\n",
    "                        creator_type=ChunkCreatorType.gov_uk,\n",
    "                    ).model_dump(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return format_documents(mapped_documents), mapped_documents\n",
    "\n",
    "    return _search_govuk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(user_uuid, prompts, documents, ai_setting):\n",
    "    redbox_query = MyRedboxQuery(\n",
    "        question=f\"{prompts[-1]}\",\n",
    "        s3_keys=documents,\n",
    "        user_uuid=user_uuid,\n",
    "        chat_history=prompts[:-1],\n",
    "        ai_settings=ai_setting,\n",
    "        permitted_s3_keys=documents,\n",
    "    )\n",
    "    return redbox_query\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD YOU DOCUMENTS AND QUESTION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_setting = AISettings(chat_backend=ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\"))\n",
    "documents = ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf']\n",
    "user_query = 'What is the impact of AI on UK jobs?'\n",
    "#user_query = 'Who is Putin?'\n",
    "#user_query = 'How to renew my passport?'\n",
    "redbox_query = get_query(uuid4(), prompts = [user_query ], documents = documents, ai_setting = ai_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the impact of AI on UK jobs?',\n",
       " 's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
       " 'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1'),\n",
       " 'chat_history': [],\n",
       " 'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
       " 'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redbox_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/9spqdryx4gsgs4bs9dw_5xw40000gq/T/ipykernel_91889/2677606543.py:2: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockEmbeddings``.\n",
      "  embedding_model = BedrockEmbeddings(region_name='eu-west-2', model_id=\"amazon.titan-embed-text-v2:0\")\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "embedding_model = BedrockEmbeddings(region_name='eu-west-2', model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing OpenSearch is definitely being used\n",
      "INFO:opensearch:HEAD http://localhost:9200/_alias/redbox-data-integration-chunk-current [status:200 request:0.034s]\n",
      "INFO:opensearch:HEAD http://localhost:9200/redbox-data-integration-chat-mesage-log [status:200 request:0.038s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    " # Tools\n",
    "\n",
    "_env = Settings()\n",
    "\n",
    "search_documents = build_search_documents_tool(\n",
    "            es_client=_env.elasticsearch_client(),\n",
    "            index_name=_env.elastic_chunk_alias,\n",
    "            embedding_model=embedding_model,\n",
    "            embedding_field_name=_env.embedding_document_field_name, #not used\n",
    "            chunk_resolution=ChunkResolution.normal\n",
    "        )\n",
    "search_wikipedia = build_search_wikipedia_tool()\n",
    "search_govuk = build_govuk_search_tool()\n",
    "        \n",
    "agent_tool_names = [\"_search_documents\", \"_search_wikipedia\", \"_search_govuk\"]\n",
    "\n",
    "tools =  {\n",
    "            \"_search_documents\": search_documents,\n",
    "            \"_search_govuk\": search_govuk,\n",
    "            \"_search_wikipedia\": search_wikipedia,\n",
    "        }\n",
    "agent_tools = [tools[tool_name] for tool_name in agent_tool_names]\n",
    "\n",
    "#agent_tools = [search_documents]\n",
    "#agent_tools = [search_govuk]\n",
    "\n",
    "\n",
    "# ToolNode will automatically take care of injecting state into tools\n",
    "tool_node = ToolNode(agent_tools)\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='_search_documents', description=\"Search for documents uploaded by the user based on a query string.\\n\\nThis function performs a search over the user's uploaded documents\\nand returns snippets from the documents ordered by relevance and\\ngrouped by document.\\n\\nArgs:\\n    query (str): The search query string used to match documents.\\n        This could be a keyword, phrase, question, or text from\\n        the documents.\\n\\nReturns:\\n    dict[str, Any]: A collection of document objects that match the query.\", args_schema=<class 'langchain_core.utils.pydantic._search_documents'>, response_format='content_and_artifact', func=<function build_search_documents_tool.<locals>._search_documents at 0x16a47d4e0>),\n",
       " StructuredTool(name='_search_wikipedia', description='Search Wikipedia for information about the queried entity.\\nUseful for when you need to answer general questions about people, places, objects, companies, facts, historical events, or other subjects.\\nInput should be a search query.\\n\\nArgs:\\n    query (str): The search query string used to find pages.\\n        This could be a keyword, phrase, or name\\n\\nReturns:\\n    response (str): The content of the relevant Wikipedia page', args_schema=<class 'langchain_core.utils.pydantic._search_wikipedia'>, response_format='content_and_artifact', func=<function build_search_wikipedia_tool.<locals>._search_wikipedia at 0x16acf6ac0>),\n",
       " StructuredTool(name='_search_govuk', description='Search for documents on gov.uk based on a query string.\\nThis endpoint is used to search for documents on gov.uk. There are many types of documents on gov.uk.\\nTypes include:\\n- guidance\\n- policy\\n- legislation\\n- news\\n- travel advice\\n- departmental reports\\n- statistics\\n- consultations\\n- appeals', args_schema=<class 'langchain_core.utils.pydantic._search_govuk'>, response_format='content_and_artifact', func=<function build_govuk_search_tool.<locals>._search_govuk at 0x16acf7d80>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_backend = ChatLLMBackend(name=\"anthropic.claude-3-sonnet-20240229-v1:0\", provider=\"bedrock\")\n",
    "llm = get_chat_llm(chat_backend, tools=agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing OpenSearch is definitely being used\n",
      "INFO:opensearch:HEAD http://localhost:9200/_alias/redbox-data-integration-chunk-current [status:200 request:0.011s]\n",
      "INFO:opensearch:HEAD http://localhost:9200/redbox-data-integration-chat-mesage-log [status:200 request:0.005s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"es_client\":_env.elasticsearch_client(),\n",
    "            \"index_name\":_env.elastic_chunk_alias,\n",
    "            \"embedding_model\":embedding_model,\n",
    "            \"embedding_field_name\":_env.embedding_document_field_name, #not used\n",
    "            \"chunk_resolution\":ChunkResolution.normal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [{\"type\": \"user\", \"content\": user_query}],\n",
    "    \"request\": redbox_query,\n",
    "    \"config\": config,\n",
    "    \"is_last_step\":False,\n",
    "    \"remaining_steps\":1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'type': 'user',\n",
       "   'content': 'What is the impact of AI on UK jobs?'}],\n",
       " 'request': {'question': 'What is the impact of AI on UK jobs?',\n",
       "  's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
       "  'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1'),\n",
       "  'chat_history': [],\n",
       "  'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
       "  'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf']},\n",
       " 'config': {'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
       "  'index_name': 'redbox-data-integration-chunk-current',\n",
       "  'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
       "  'embedding_field_name': 'embedding',\n",
       "  'chunk_resolution': <ChunkResolution.normal: 'normal'>},\n",
       " 'is_last_step': False,\n",
       " 'remaining_steps': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimized prompt to avoid hallucinationa\n",
    "AGENTIC_RETRIEVAL_SYSTEM_PROMPT = (\n",
    "    \"You are an advanced problem-solving assistant. Your primary goal is to carefully \"\n",
    "    \"analyse and work through complex questions or problems. You will receive a collection \"\n",
    "    \"of documents (all at once, without any information about their order or iteration) and \"\n",
    "    \"a list of tool calls that have already been made (also without order or iteration \"\n",
    "    \"information). Based on this data, you are expected to think critically about how to \"\n",
    "    \"proceed.\\n\"\n",
    "    \"\\n\"\n",
    "    \"Objective:\\n\"\n",
    "    \"1. Your task is to answer user queries.\"\n",
    "    \"2. Examine the available documents and tool calls:\\n\"\n",
    "    \"- Evaluate whether the current information is sufficient to answer the question.\\n\"\n",
    "    \"- Consider the success or failure of previous tool calls based on the data they returned.\\n\"\n",
    "    \"- Hypothesise whether new tool calls might bring more valuable information.\\n\"\n",
    "    \"\\n\"\n",
    "    \"3. Decide whether you can answer this question:\\n\"\n",
    "    \"- If additional tool calls are likely to yield useful information, make those calls.\\n\"\n",
    "    \"- Determine whether the available documents contain the answer to the question. If the available documents contain the answer to the question, provide an answer. You must provide the citations where you use the information to answer.\\n\"\n",
    "    \"- Determine whether the available documents contain the answer to the question. If the available documents do not contain the answer to the question, say I don't know. Do not make up an answer.\"\n",
    "    \"Your role is to think deeply before taking any action. Carefully weigh whether new \"\n",
    "    \"information is necessary or helpful. Only take action (call tools or providing and answer) after \"\n",
    "    \"thorough evaluation of the current documents and tool calls.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/9spqdryx4gsgs4bs9dw_5xw40000gq/T/ipykernel_91889/3321282512.py:1: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.3.0. Use 'state_modifier' parameter instead.\n",
      "  graph = create_react_agent(llm, tools=agent_tools, state_schema=MyRedboxState,  messages_modifier=AGENTIC_RETRIEVAL_SYSTEM_PROMPT, debug=True) #, checkpointer=checkpointer) #, checkpointer=checkpointer) #, state_modifier=prompt)\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "graph = create_react_agent(llm, tools=agent_tools, state_schema=MyRedboxState,  messages_modifier=AGENTIC_RETRIEVAL_SYSTEM_PROMPT, debug=True) #, checkpointer=checkpointer) #, checkpointer=checkpointer) #, state_modifier=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [{'content': 'What is the impact of AI on UK jobs?',\n",
      "               'type': 'user'}],\n",
      " 'remaining_steps': 1,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 3 channels:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [{'content': 'What is the impact of AI on UK jobs?', 'type': 'user'}]\n",
      "- \u001b[33;1m\u001b[1;3mrequest\u001b[0m -> {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      " 'chat_history': [],\n",
      " 'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      " 'question': 'What is the impact of AI on UK jobs?',\n",
      " 's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      " 'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}\n",
      "- \u001b[33;1m\u001b[1;3mconfig\u001b[0m -> {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      " 'embedding_field_name': 'embedding',\n",
      " 'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      " 'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      " 'index_name': 'redbox-data-integration-chunk-current'}\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2')],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2')],\n",
      " 'remaining_steps': 24,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the impact of AI on UK jobs?\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034})]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034})],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034})],\n",
      " 'remaining_steps': 23,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  _search_wikipedia (toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW)\n",
      " Call ID: toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW\n",
      "  Args:\n",
      "    query: AI impact on jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')])]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')])],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')])],\n",
      " 'remaining_steps': 22,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: _search_wikipedia\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>Wikipedia</SourceType>\n",
      "\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\n",
      "\t<Content>\n",
      "An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\n",
      "\n",
      "\n",
      "== Types ==\n",
      "\n",
      "\n",
      "=== Automation of the economy ===\n",
      "\n",
      "The traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\n",
      "\n",
      "\n",
      "==== Technologies that may displace workers ====\n",
      "AI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI's ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\n",
      "\n",
      "\n",
      "==== Computer-integrated manufacturing ====\n",
      "\n",
      "Computer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\n",
      "\n",
      "\n",
      "==== White-collar machines ====\n",
      "\n",
      "The 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\n",
      "\n",
      "\n",
      "==== Autonomous cars ====\n",
      "An autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment's notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\n",
      "\n",
      "\n",
      "==== AI-generated content ====\n",
      "\n",
      "The use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy's Chocolate Experience in Glasgow, Scotland was an infamous children's event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\n",
      "\n",
      "\n",
      "=== Eradication ===\n",
      "\n",
      "Scientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine's plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world's resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\n",
      "\n",
      "\n",
      "== In fiction ==\n",
      "\n",
      "AI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek's R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley's Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster's request and makes him a wife, they would reproduce and their kind would destroy humanity.\n",
      "According to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\n",
      "The word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\n",
      "\n",
      "\n",
      "== Contributing factors ==\n",
      "\n",
      "\n",
      "=== Advantages of superhuman intelligence over humans ===\n",
      "Nick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\n",
      "\n",
      "Technology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\n",
      "Strategizing: A superintelligence might be able to simply outwit human opposition\n",
      "Social manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\n",
      "Economic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\n",
      "Hacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\n",
      "\n",
      "\n",
      "==== Sources of AI advantage ====\n",
      "According to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain's algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\n",
      "A network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\n",
      "More broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies' source code to attempt to further improve its algorithms.\n",
      "\n",
      "\n",
      "=== Possibility of unfriendly AI preceding friendly AI ===\n",
      "\n",
      "\n",
      "==== Is strong AI inherently dangerous? ====\n",
      "\n",
      "A significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\n",
      "\t</Content>\n",
      "</Document>\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588})]\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')]),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588})],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[4:tasks]\u001b[0m \u001b[1mStarting 1 task for step 4:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')]),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588})],\n",
      " 'remaining_steps': 21,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  _search_govuk (toolu_bdrk_0144wz715JgXh6ME6S9QLKff)\n",
      " Call ID: toolu_bdrk_0144wz715JgXh6ME6S9QLKff\n",
      "  Args:\n",
      "    query: AI impact on UK jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[4:writes]\u001b[0m \u001b[1mFinished step 4 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\\n\\t<Content>\\nThis report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\\n\\t<Content>\\nThis research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\\n\\t<Content>\\nArtificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\\n\\t<Content>\\nIn 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\\n\\t<Content>\\nThe AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people\\'s everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\\n\\t</Content>\\n</Document>', name='_search_govuk', tool_call_id='toolu_bdrk_0144wz715JgXh6ME6S9QLKff', artifact=[Document(metadata={'uuid': UUID('239877a5-162c-4be8-b97a-7a3d87bf7167'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training', 'token_count': 61}, page_content='This report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.'), Document(metadata={'uuid': UUID('44cc8f58-8a97-4cad-9c54-4634f15db9b0'), 'index': 1, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023', 'token_count': 17549}, page_content='This research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩'), Document(metadata={'uuid': UUID('800d2310-9697-4019-ad77-73c5de6b7280'), 'index': 2, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/national-ai-strategy', 'token_count': 25566}, page_content='Artificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩'), Document(metadata={'uuid': UUID('c2f9fe84-c665-4606-ad6d-7a2d0faaecc9'), 'index': 3, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk', 'token_count': 537}, page_content='In 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk'), Document(metadata={'uuid': UUID('10d3b18c-d902-4628-a5a0-bd7e84b5c118'), 'index': 4, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/ai-opportunities-action-plan', 'token_count': 10317}, page_content=\"The AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\")])]\n",
      "\u001b[36;1m\u001b[1;3m[4:checkpoint]\u001b[0m \u001b[1mState at the end of step 4:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')]),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\\n\\t<Content>\\nThis report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\\n\\t<Content>\\nThis research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\\n\\t<Content>\\nArtificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\\n\\t<Content>\\nIn 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\\n\\t<Content>\\nThe AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people\\'s everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\\n\\t</Content>\\n</Document>', name='_search_govuk', id='bfc221ce-051c-48cb-b1b4-63fac26c5ee7', tool_call_id='toolu_bdrk_0144wz715JgXh6ME6S9QLKff', artifact=[Document(metadata={'uuid': UUID('239877a5-162c-4be8-b97a-7a3d87bf7167'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training', 'token_count': 61}, page_content='This report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.'), Document(metadata={'uuid': UUID('44cc8f58-8a97-4cad-9c54-4634f15db9b0'), 'index': 1, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023', 'token_count': 17549}, page_content='This research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩'), Document(metadata={'uuid': UUID('800d2310-9697-4019-ad77-73c5de6b7280'), 'index': 2, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/national-ai-strategy', 'token_count': 25566}, page_content='Artificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩'), Document(metadata={'uuid': UUID('c2f9fe84-c665-4606-ad6d-7a2d0faaecc9'), 'index': 3, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk', 'token_count': 537}, page_content='In 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk'), Document(metadata={'uuid': UUID('10d3b18c-d902-4628-a5a0-bd7e84b5c118'), 'index': 4, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/ai-opportunities-action-plan', 'token_count': 10317}, page_content=\"The AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\")])],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "\u001b[36;1m\u001b[1;3m[5:tasks]\u001b[0m \u001b[1mStarting 1 task for step 5:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')]),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\\n\\t<Content>\\nThis report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\\n\\t<Content>\\nThis research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\\n\\t<Content>\\nArtificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\\n\\t<Content>\\nIn 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\\n\\t<Content>\\nThe AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people\\'s everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\\n\\t</Content>\\n</Document>', name='_search_govuk', id='bfc221ce-051c-48cb-b1b4-63fac26c5ee7', tool_call_id='toolu_bdrk_0144wz715JgXh6ME6S9QLKff', artifact=[Document(metadata={'uuid': UUID('239877a5-162c-4be8-b97a-7a3d87bf7167'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training', 'token_count': 61}, page_content='This report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.'), Document(metadata={'uuid': UUID('44cc8f58-8a97-4cad-9c54-4634f15db9b0'), 'index': 1, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023', 'token_count': 17549}, page_content='This research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩'), Document(metadata={'uuid': UUID('800d2310-9697-4019-ad77-73c5de6b7280'), 'index': 2, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/national-ai-strategy', 'token_count': 25566}, page_content='Artificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩'), Document(metadata={'uuid': UUID('c2f9fe84-c665-4606-ad6d-7a2d0faaecc9'), 'index': 3, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk', 'token_count': 537}, page_content='In 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk'), Document(metadata={'uuid': UUID('10d3b18c-d902-4628-a5a0-bd7e84b5c118'), 'index': 4, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/ai-opportunities-action-plan', 'token_count': 10317}, page_content=\"The AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\")])],\n",
      " 'remaining_steps': 20,\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: _search_govuk\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>GOV.UK</SourceType>\n",
      "\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\n",
      "\t<Content>\n",
      "This report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\n",
      "\t</Content>\n",
      "</Document>\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>GOV.UK</SourceType>\n",
      "\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\n",
      "\t<Content>\n",
      "This research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s  AI  sector contribute to the UK economy? Is investment enabling growth, development, innovation and  R&D  for  AI  startups? What products and services does the  AI  sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the  AI  market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in  2022 , the study was produced for the  DSIT  by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources­ This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data­ Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements­ The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\n",
      "\t</Content>\n",
      "</Document>\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>GOV.UK</SourceType>\n",
      "\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\n",
      "\t<Content>\n",
      "Artificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK's overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world's most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\n",
      "\t</Content>\n",
      "</Document>\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>GOV.UK</SourceType>\n",
      "\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\n",
      "\t<Content>\n",
      "In 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\n",
      "\t</Content>\n",
      "</Document>\n",
      "\n",
      "<Document>\n",
      "\t<SourceType>GOV.UK</SourceType>\n",
      "\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\n",
      "\t<Content>\n",
      "The AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\n",
      "\t</Content>\n",
      "</Document>\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:StateModifier] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:StateModifier] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatBedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Your task is to answer user queries.2. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n3. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- Determine whether the available documents contain the answer to the question. If the available documents contain the answer to the question, provide an answer. You must provide the citations where you use the information to answer.\\n- Determine whether the available documents contain the answer to the question. If the available documents do not contain the answer to the question, say I don't know. Do not make up an answer.Your role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.\\nHuman: What is the impact of AI on UK jobs?\\nAI: \\nTool: <Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI's ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment's notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy's Chocolate Experience in Glasgow, Scotland was an infamous children's event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \\\"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\\\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine's plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world's resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek's R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley's Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster's request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \\\"robot\\\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \\\"robots\\\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \\\"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\\\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain's algorithms, could still become a \\\"speed superintelligence\\\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \\\"collective superintelligence\\\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \\\"quality superintelligence\\\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>\\nAI: \\nTool: <Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\\n\\t<Content>\\nThis report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\\n\\t<Content>\\nThis research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s  AI  sector contribute to the UK economy? Is investment enabling growth, development, innovation and  R&D  for  AI  startups? What products and services does the  AI  sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the  AI  market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in  2022 , the study was produced for the  DSIT  by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources­ This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data­ Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements­ The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\\n\\t<Content>\\nArtificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK's overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world's most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \\\"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\\\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \\\"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\\\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \\\"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\\\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\\n\\t<Content>\\nIn 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\\n\\t<Content>\\nThe AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\\n\\t</Content>\\n</Document>\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatBedrock] [41.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"<search_quality_reflection>\\nThe documents provided give a good overview of the UK government's perspective and efforts around promoting AI development and adoption. The National AI Strategy lays out a comprehensive vision and plan across areas like research, skills, data, compute infrastructure, governance, and sector adoption. The other reports and publications provide additional details and examples of specific initiatives, challenges, and opportunities.\\n\\nHowever, the information is focused primarily on the government's policies, strategies and programs. To fully assess the impact of AI on UK jobs, I would need more data and analysis from other sources as well, such as:\\n\\n- Economic/labor market studies quantifying the actual impact of AI on employment levels, job loss/creation across different sectors and occupations, wage impacts, etc. The government reports touch on anticipated impacts but lack concrete data.\\n\\n- Business surveys or case studies looking at how UK companies across industries are actually adopting and being impacted by AI in areas like automation, productivity, workforce needs, etc.\\n\\n- Research on how AI is changing required workforce skills and how well the education/training system is adapting to produce workers with AI/data science capabilities.\\n\\n- Analysis of differential impacts across demographics, skill levels, geographies, etc. And how policies may need to address inequities.\\n\\n- Projections and scenarios for how more advanced/general AI systems could reshape labor markets in the future as the technology matures.\\n\\nSo in summary, the provided information gives good insight into the government's perspective and efforts, but does not comprehensively cover and quantify the actual realized impacts of AI on UK jobs and workforce to date. Additional third-party research and data would be needed to fully assess that topic.\\n</search_quality_reflection>\\n\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nThe UK government recognizes the potentially transformative impact of AI on the economy and workforce, and has developed a comprehensive National AI Strategy to shape that transition. Key elements of the strategy related to jobs and labor markets include:\\n\\nSkills and Talent Development:\\n- Increasing the number of AI graduates through support for university AI programs and conversion courses. Goal of training tens of thousands of new AI professionals by 2030.\\n- Promoting diversity and alternative education pathways like apprenticeships into AI fields.\\n- Ensuring the skills system can adapt to provide AI and data literacy for the broader workforce as roles are augmented by AI.\\n- Attracting top global AI talent to the UK through programs like a flagship AI scholarship program and enhanced visa routes.\\n\\nSupporting AI Adoption Across the Economy:\\n- Helping businesses across sectors identify high-impact AI use cases and overcome barriers to adoption through interventions like regulatory sandboxes.\\n- Central government itself scaling up adoption of AI technologies to improve public services and operations.\\n- Public procurement used as a lever to drive AI adoption by purchasing from innovative AI suppliers.\\n\\nGrowing the UK AI Industry:\\n- Enabling sufficient AI research and compute infrastructure to drive innovation.\\n- Improving access to data assets and responsible data sharing to fuel AI development.\\n- Regulatory approaches like the AI Assurance ecosystem to build trust in AI systems.\\n- New initiatives like the UK Sovereign AI unit to partner with the private sector and maximize the UK's stake in frontier/transformative AI capabilities.\\n\\nHowever, the reports do not provide comprehensive data on the actual impacts realized so far on UK employment levels, job turnover, wage impacts, etc. While acknowledging AI's potential to augment and displace jobs, the strategy focuses more on proactive positioning than reacting to current effects.\\n\\nAdditional third-party research would be needed to quantify realized impacts across sectors, skill levels, demographics, and geographies to date. The strategy aims to steer the UK into a leading position in an AI-enabled economy, but the effects on jobs and workforce adaptation will require ongoing study as AI capabilities advance.\\n</result>\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"<search_quality_reflection>\\nThe documents provided give a good overview of the UK government's perspective and efforts around promoting AI development and adoption. The National AI Strategy lays out a comprehensive vision and plan across areas like research, skills, data, compute infrastructure, governance, and sector adoption. The other reports and publications provide additional details and examples of specific initiatives, challenges, and opportunities.\\n\\nHowever, the information is focused primarily on the government's policies, strategies and programs. To fully assess the impact of AI on UK jobs, I would need more data and analysis from other sources as well, such as:\\n\\n- Economic/labor market studies quantifying the actual impact of AI on employment levels, job loss/creation across different sectors and occupations, wage impacts, etc. The government reports touch on anticipated impacts but lack concrete data.\\n\\n- Business surveys or case studies looking at how UK companies across industries are actually adopting and being impacted by AI in areas like automation, productivity, workforce needs, etc.\\n\\n- Research on how AI is changing required workforce skills and how well the education/training system is adapting to produce workers with AI/data science capabilities.\\n\\n- Analysis of differential impacts across demographics, skill levels, geographies, etc. And how policies may need to address inequities.\\n\\n- Projections and scenarios for how more advanced/general AI systems could reshape labor markets in the future as the technology matures.\\n\\nSo in summary, the provided information gives good insight into the government's perspective and efforts, but does not comprehensively cover and quantify the actual realized impacts of AI on UK jobs and workforce to date. Additional third-party research and data would be needed to fully assess that topic.\\n</search_quality_reflection>\\n\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nThe UK government recognizes the potentially transformative impact of AI on the economy and workforce, and has developed a comprehensive National AI Strategy to shape that transition. Key elements of the strategy related to jobs and labor markets include:\\n\\nSkills and Talent Development:\\n- Increasing the number of AI graduates through support for university AI programs and conversion courses. Goal of training tens of thousands of new AI professionals by 2030.\\n- Promoting diversity and alternative education pathways like apprenticeships into AI fields.\\n- Ensuring the skills system can adapt to provide AI and data literacy for the broader workforce as roles are augmented by AI.\\n- Attracting top global AI talent to the UK through programs like a flagship AI scholarship program and enhanced visa routes.\\n\\nSupporting AI Adoption Across the Economy:\\n- Helping businesses across sectors identify high-impact AI use cases and overcome barriers to adoption through interventions like regulatory sandboxes.\\n- Central government itself scaling up adoption of AI technologies to improve public services and operations.\\n- Public procurement used as a lever to drive AI adoption by purchasing from innovative AI suppliers.\\n\\nGrowing the UK AI Industry:\\n- Enabling sufficient AI research and compute infrastructure to drive innovation.\\n- Improving access to data assets and responsible data sharing to fuel AI development.\\n- Regulatory approaches like the AI Assurance ecosystem to build trust in AI systems.\\n- New initiatives like the UK Sovereign AI unit to partner with the private sector and maximize the UK's stake in frontier/transformative AI capabilities.\\n\\nHowever, the reports do not provide comprehensive data on the actual impacts realized so far on UK employment levels, job turnover, wage impacts, etc. While acknowledging AI's potential to augment and displace jobs, the strategy focuses more on proactive positioning than reacting to current effects.\\n\\nAdditional third-party research would be needed to quantify realized impacts across sectors, skill levels, demographics, and geographies to date. The strategy aims to steer the UK into a leading position in an AI-enabled economy, but the effects on jobs and workforce adaptation will require ongoing study as AI capabilities advance.\\n</result>\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 62109,\n",
      "                \"completion_tokens\": 831,\n",
      "                \"total_tokens\": 62940\n",
      "              },\n",
      "              \"stop_reason\": \"end_turn\",\n",
      "              \"model_id\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 62109,\n",
      "                \"completion_tokens\": 831,\n",
      "                \"total_tokens\": 62940\n",
      "              },\n",
      "              \"stop_reason\": \"end_turn\",\n",
      "              \"model_id\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-daf32ea9-4e40-4636-848c-5669b2f29f2d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 62109,\n",
      "              \"output_tokens\": 831,\n",
      "              \"total_tokens\": 62940\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 62109,\n",
      "      \"completion_tokens\": 831,\n",
      "      \"total_tokens\": 62940\n",
      "    },\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"model_id\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [41.54s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[5:writes]\u001b[0m \u001b[1mFinished step 5 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content=\"<search_quality_reflection>\\nThe documents provided give a good overview of the UK government's perspective and efforts around promoting AI development and adoption. The National AI Strategy lays out a comprehensive vision and plan across areas like research, skills, data, compute infrastructure, governance, and sector adoption. The other reports and publications provide additional details and examples of specific initiatives, challenges, and opportunities.\\n\\nHowever, the information is focused primarily on the government's policies, strategies and programs. To fully assess the impact of AI on UK jobs, I would need more data and analysis from other sources as well, such as:\\n\\n- Economic/labor market studies quantifying the actual impact of AI on employment levels, job loss/creation across different sectors and occupations, wage impacts, etc. The government reports touch on anticipated impacts but lack concrete data.\\n\\n- Business surveys or case studies looking at how UK companies across industries are actually adopting and being impacted by AI in areas like automation, productivity, workforce needs, etc.\\n\\n- Research on how AI is changing required workforce skills and how well the education/training system is adapting to produce workers with AI/data science capabilities.\\n\\n- Analysis of differential impacts across demographics, skill levels, geographies, etc. And how policies may need to address inequities.\\n\\n- Projections and scenarios for how more advanced/general AI systems could reshape labor markets in the future as the technology matures.\\n\\nSo in summary, the provided information gives good insight into the government's perspective and efforts, but does not comprehensively cover and quantify the actual realized impacts of AI on UK jobs and workforce to date. Additional third-party research and data would be needed to fully assess that topic.\\n</search_quality_reflection>\\n\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nThe UK government recognizes the potentially transformative impact of AI on the economy and workforce, and has developed a comprehensive National AI Strategy to shape that transition. Key elements of the strategy related to jobs and labor markets include:\\n\\nSkills and Talent Development:\\n- Increasing the number of AI graduates through support for university AI programs and conversion courses. Goal of training tens of thousands of new AI professionals by 2030.\\n- Promoting diversity and alternative education pathways like apprenticeships into AI fields.\\n- Ensuring the skills system can adapt to provide AI and data literacy for the broader workforce as roles are augmented by AI.\\n- Attracting top global AI talent to the UK through programs like a flagship AI scholarship program and enhanced visa routes.\\n\\nSupporting AI Adoption Across the Economy:\\n- Helping businesses across sectors identify high-impact AI use cases and overcome barriers to adoption through interventions like regulatory sandboxes.\\n- Central government itself scaling up adoption of AI technologies to improve public services and operations.\\n- Public procurement used as a lever to drive AI adoption by purchasing from innovative AI suppliers.\\n\\nGrowing the UK AI Industry:\\n- Enabling sufficient AI research and compute infrastructure to drive innovation.\\n- Improving access to data assets and responsible data sharing to fuel AI development.\\n- Regulatory approaches like the AI Assurance ecosystem to build trust in AI systems.\\n- New initiatives like the UK Sovereign AI unit to partner with the private sector and maximize the UK's stake in frontier/transformative AI capabilities.\\n\\nHowever, the reports do not provide comprehensive data on the actual impacts realized so far on UK employment levels, job turnover, wage impacts, etc. While acknowledging AI's potential to augment and displace jobs, the strategy focuses more on proactive positioning than reacting to current effects.\\n\\nAdditional third-party research would be needed to quantify realized impacts across sectors, skill levels, demographics, and geographies to date. The strategy aims to steer the UK into a leading position in an AI-enabled economy, but the effects on jobs and workforce adaptation will require ongoing study as AI capabilities advance.\\n</result>\", additional_kwargs={'usage': {'prompt_tokens': 62109, 'completion_tokens': 831, 'total_tokens': 62940}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 62109, 'completion_tokens': 831, 'total_tokens': 62940}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-daf32ea9-4e40-4636-848c-5669b2f29f2d-0', usage_metadata={'input_tokens': 62109, 'output_tokens': 831, 'total_tokens': 62940})]\n",
      "\u001b[36;1m\u001b[1;3m[5:checkpoint]\u001b[0m \u001b[1mState at the end of step 5:\n",
      "\u001b[0m{'config': {'chunk_resolution': <ChunkResolution.normal: 'normal'>,\n",
      "            'embedding_field_name': 'embedding',\n",
      "            'embedding_model': BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x16a43a0f0>, region_name='eu-west-2', credentials_profile_name=None, model_id='amazon.titan-embed-text-v2:0', model_kwargs=None, endpoint_url=None, normalize=False),\n",
      "            'es_client': <OpenSearch([{'host': 'localhost', 'port': '9200'}])>,\n",
      "            'index_name': 'redbox-data-integration-chunk-current'},\n",
      " 'messages': [HumanMessage(content='What is the impact of AI on UK jobs?', additional_kwargs={}, response_metadata={}, id='abf80d12-8b0c-4aaa-9bbd-f40abc3297c2'),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 930, 'completion_tokens': 104, 'total_tokens': 1034}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfbd51a6-e599-496f-a23c-d21305ce419f-0', tool_calls=[{'name': '_search_wikipedia', 'args': {'query': 'AI impact on jobs'}, 'id': 'toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 930, 'output_tokens': 104, 'total_tokens': 1034}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>Wikipedia</SourceType>\\n\\t<Source>https://en.wikipedia.org/wiki/AI_takeover</Source>\\n\\t<Content>\\nAn AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co\\n\\t</Content>\\n</Document>', name='_search_wikipedia', id='dc3cce91-bfa6-4d41-b7a4-9785bec2907e', tool_call_id='toolu_bdrk_01DVz5MMxSCoPo8V5svKb6RW', artifact=[Document(metadata={'uuid': UUID('daec7110-d83b-47d5-b158-a60b66b0b2a5'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.wikipedia: 'Wikipedia'>, 'uri': 'https://en.wikipedia.org/wiki/AI_takeover', 'token_count': 2210}, page_content='An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.\\n\\n\\n== Types ==\\n\\n\\n=== Automation of the economy ===\\n\\nThe traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving people in various sectors without jobs to earn a living, leading to an economic crisis. Many small and medium size businesses may also be driven out of business if they cannot afford or licence the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology.\\n\\n\\n==== Technologies that may displace workers ====\\nAI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI takeover include transportation, retail, and military. AI military technologies, for example, allow soldiers to work remotely without risk of injury. A study in 2024 highlights AI\\'s ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable.\\n\\n\\n==== Computer-integrated manufacturing ====\\n\\nComputer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries.\\n\\n\\n==== White-collar machines ====\\n\\nThe 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, have also begun to be performed by robots.\\n\\n\\n==== Autonomous cars ====\\nAn autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are being developed, but as of May 2017, automated cars permitted on public roads are not yet fully autonomous. They all require a human driver at the wheel who at a moment\\'s notice can take control of the vehicle. Among the obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving-related jobs in the road transport industry. On March 18, 2018, the first human was killed by an autonomous vehicle in Tempe, Arizona by an Uber self-driving car.\\n\\n\\n==== AI-generated content ====\\n\\nThe use of automated content has become relevant since the technological advancements in artificial intelligence models such as ChatGPT, DALL-E, and Stable Diffusion. In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts and these AI models have been integrated into other creative programs. Artists are threatened by displacement from AI-generated content due to these models sampling from other creative works, producing results sometimes indiscernible to those of man-made content. This complication has become widespread enough to where other artists and programmers are creating software and utility programs to retaliate against these text-to-image models from giving accurate outputs. While some industries in the economy benefit from artificial intelligence through new jobs, this issue does not create new jobs and threatens replacement entirely. It has made public headlines in the media recently: In February 2024, Willy\\'s Chocolate Experience in Glasgow, Scotland was an infamous children\\'s event in which the imagery and scripts were created using artificial intelligence models to the dismay of children, parents, and actors involved. There is an ongoing lawsuit placed against OpenAI from The New York Times where it is claimed that there is copyright infringement due to the sampling methods their artificial intelligence models use for their outputs.\\n\\n\\n=== Eradication ===\\n\\nScientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". Scholars like Nick Bostrom debate how far off superhuman intelligence is, and whether it poses a risk to mankind. According to Bostrom, a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine\\'s plans. As an oversimplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world\\'s resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips.\\n\\n\\n== In fiction ==\\n\\nAI takeover is a common theme in science fiction. Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans, as opposed to the researchers\\' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. The idea is seen in Karel Čapek\\'s R.U.R., which introduced the word robot in 1921, and can be glimpsed in Mary Shelley\\'s Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster\\'s request and makes him a wife, they would reproduce and their kind would destroy humanity.\\nAccording to Toby Ord, the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with an access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate.\\nThe word \"robot\" from R.U.R. comes from the Czech word, robota, meaning laborer or serf. The 1920 play was a protest against the rapid growth of technology, featuring manufactured \"robots\" with increasing capabilities who eventually revolt. HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture.\\n\\n\\n== Contributing factors ==\\n\\n\\n=== Advantages of superhuman intelligence over humans ===\\nNick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", and enumerates some advantages a superintelligence would have if it chose to compete against humans:\\n\\nTechnology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology\\nStrategizing: A superintelligence might be able to simply outwit human opposition\\nSocial manipulation: A superintelligence might be able to recruit human support, or covertly incite a war between humans\\nEconomic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems\\nHacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans\\n\\n\\n==== Sources of AI advantage ====\\nAccording to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain\\'s algorithms, could still become a \"speed superintelligence\" if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2,000,000,000 Hz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light.\\nA network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a \"collective superintelligence\".\\nMore broadly, any number of qualitative improvements to a human-level AGI could result in a \"quality superintelligence\", perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory, and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who evolved no specialized mental modules to specifically deal with those domains. Unlike humans, an AGI can spawn copies of itself and tinker with its copies\\' source code to attempt to further improve its algorithms.\\n\\n\\n=== Possibility of unfriendly AI preceding friendly AI ===\\n\\n\\n==== Is strong AI inherently dangerous? ====\\n\\nA significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI co')]),\n",
      "              AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 3459, 'completion_tokens': 129, 'total_tokens': 3588}, 'stop_reason': 'tool_use', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b709ce2c-37f0-4821-9c51-d13762c33a66-0', tool_calls=[{'name': '_search_govuk', 'args': {'query': 'AI impact on UK jobs'}, 'id': 'toolu_bdrk_0144wz715JgXh6ME6S9QLKff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3459, 'output_tokens': 129, 'total_tokens': 3588}),\n",
      "              ToolMessage(content='<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training</Source>\\n\\t<Content>\\nThis report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023</Source>\\n\\t<Content>\\nThis research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/national-ai-strategy</Source>\\n\\t<Content>\\nArtificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk</Source>\\n\\t<Content>\\nIn 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk\\n\\t</Content>\\n</Document>\\n\\n<Document>\\n\\t<SourceType>GOV.UK</SourceType>\\n\\t<Source>https://www.gov.uk/government/publications/ai-opportunities-action-plan</Source>\\n\\t<Content>\\nThe AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people\\'s everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\\n\\t</Content>\\n</Document>', name='_search_govuk', id='bfc221ce-051c-48cb-b1b4-63fac26c5ee7', tool_call_id='toolu_bdrk_0144wz715JgXh6ME6S9QLKff', artifact=[Document(metadata={'uuid': UUID('239877a5-162c-4be8-b97a-7a3d87bf7167'), 'index': 0, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/the-impact-of-ai-on-uk-jobs-and-training', 'token_count': 61}, page_content='This report covers the UK labour market and how it is expected to be impacted by AI and large language models (LLMs), focusing on: occupations sectors geographic areas It also shows the qualifications and training routes that most commonly lead to highly impacted jobs. Annex 1 contains data sources to support the main report.'), Document(metadata={'uuid': UUID('44cc8f58-8a97-4cad-9c54-4634f15db9b0'), 'index': 1, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/artificial-intelligence-sector-study-2023', 'token_count': 17549}, page_content='This research allows Department for Science, Innovation and Technology ( DSIT ) to deepen its understanding of the AI sector, monitor developments over time, and evaluate interventions to best support sector growth. The research aims to answer important questions on the AI sector, such as: How much does the UK’s\\xa0 AI \\xa0sector contribute to the UK economy? Is investment enabling growth, development, innovation and\\xa0 R&D \\xa0for\\xa0 AI \\xa0startups? What products and services does the\\xa0 AI \\xa0sector produce and offer and which sub-sectors does it mostly serve? What are the market dynamics of the\\xa0 AI \\xa0market and do they lend themselves to innovation, growth, and global competition and cooperation? In 2023, as in\\xa0 2022 , the study was produced for the\\xa0 DSIT \\xa0by Perspective Economics, Ipsos and Glass.ai. Ministerial foreword AI has the potential to transform our economy and benefit our daily lives. Harnessing its potential could help us tackle some of the biggest challenges we face, from climate change to healthcare. AI advancements are driving innovation and scientific advancements, economic growth and efficiency. Adopting and developing AI makes our businesses more competitive on the global stage, and able to provide the highest quality goods and services to citizens. That is why the UK is taking a leading role in advancing the development and adoption of artificial intelligence (AI) globally. The opportunities from AI are significant. The new objectives of the Department for Science, Innovation and Technology (DSIT) are designed to align closely with our missions, focusing on enhancing the UK’s scientific and technological capabilities to drive economic growth and societal progress. These objectives include fostering innovation, improving digital infrastructure, and promoting sustainable development, to drive towards delivery on the governments core missions. Artificial Intelligence (AI) plays a crucial role in achieving all of these objectives, from enabling more efficient data analysis, to automating routine tasks, and providing insights that can inform policy decisions. AI can enhance the delivery of public services, making them more responsive and personalised to the needs of citizens AI is advancing rapidly, and we are committed to sustaining the UK’s position as a global leader. The Secretary of State tasked Matt Clifford with developing an action plan to identify how AI can drive economic growth and deliver better outcomes for people across the country. The Action Plan will set out how the UK can build an AI sector that can scale and compete on the global stage. The Plan will also outline how we can boost the uptake of the technology across all parts of the economy and consider the necessary infrastructure, talent, and data access required to drive adoption by the public and private sectors. This is alongside our commitment, announced in the Kings Speech, to regulate the most powerful AI frontier models, driving trust in and adoption of the safe AI. A detailed understanding of the AI sector in the UK is critical to developing this policy agenda. This AI sector study was first commissioned in 2022 to provide a better understanding of the UK’s AI Sector as it rapidly developed. As large language models became part of everyday life, we commissioned it again in 2023, so that we could assess the rapid changes that have occurred. We now know that there are more than 3,000 AI companies in the UK, generating more than £10 billion in revenues, employing more than 60,000 people in AI related roles, and contributing £5.8 billion in Gross Value Added (GVA). Through subsequent iterations of this analysis, we will continue to monitor developments in the sector, ensuring that our decision-making is grounded in a thorough understanding of the challenges and opportunities facing AI companies in the UK. Minister Clark Parliamentary Under-Secretary of State for AI and Digital Government Executive summary A consortium led by Perspective Economics was commissioned in early 2024 to undertake research into the profile of AI activity in the UK, and its contribution to the UK economy[footnote 1]. Based on analysis of secondary data and qualitative research including responses from 297 AI companies and 45 in-depth interviews with AI businesses and strategic stakeholders, this report provides key findings regarding the size and scale of the UK’s AI sector. Figure I.1 – AI Sector Study Headline Metrics (2022 – 2023) 1.2 Key findings Compared to the 2022 study, aggregate numbers of AI companies, revenues, employment and GVA are all higher in 2023. Total AI company numbers increased by 17% (+543). Total AI-related revenues increased by 34% (+£3.6 billion). Total AI-related employment increased by 29% (+14,500). Total AI-related GVA increased by almost 57% (+£2.1 billion). Revenue and employment growth have been driven by diversified AI companies. Diversified AI-related revenues have increased by 80% (+£4.3 billion). Diversified AI-related employment has increased by 44% (+10,600) Diversified AI-related GVA has increased by 70% (+£1.9 billion). Dedicated AI companies have also seen increases in both employment and GVA. Dedicated AI-related employment has increased by 15% (3,900). Dedicated AI-related GVA has increased by 20% (+£0.2 billion). The regional profile of AI companies remains largely unchanged, centred on London, the South East and the East of England. 73% of all office addresses are located in London, the South East or the East of England, including 75% of registered addresses and 72% of all trading addresses. AI activity within certain sectors is better represented in regions outside of London and the South East, including Automotive and Transportation, Energy and Utilities, Manufacturing and Agriculture and Food (43%, 41%, 38% and 35% of registered company addresses outside London, the South East and the East of England respectively). An online survey was conducted which obtained responses from 297 AI focused businesses. When asked about the future drivers of growth and demand for AI within their business, 74% of survey respondents pointed to developing AI products as a key future growth driver, while 53% of respondents identified access to equity as a major barrier to growth. 1. Introduction Perspective Economics, in collaboration with Beauhurst, Ipsos, glass.ai, and Professors Rob Procter (University of Warwick) and Roger Woods (Queen’s University Belfast) were commissioned in February 2024 to deliver an assessment of the UK’s artificial intelligence (AI) sector in 2023. The aim of the study is to continue building a better understanding of the scale, profile and economic contribution of UK’s AI Sector by updating baseline data compiled in 2022 to support government’s ongoing development and monitoring of key AI policies. The emergence of consumer-facing generative AI tools in late 2022 and early 2023 radically shifted public conversation regarding the power and potential of AI. Since then, businesses across economic sectors are increasingly recognising the opportunities that AI could provide[footnote 2]. However, since the 2022 AI sector study a range of important considerations regarding the future development and application of AI technologies have also come to the fore, including risk and safety, regulation and international cooperation. In addition to providing updated economic data, this report offers insights from UK AI businesses and stakeholders regarding the opportunities, challenges, enablers and barriers to the continued growth of AI activity in the UK. 1.1 Methodology and sources\\xad This study will form part of the broader DSIT evidence base on AI, building on a similar study conducted in 2021/2022. The study has several overarching requirements as follows: Identify and document UK AI companies using a broad range of comprehensive data sources. Conduct qualitative research to understand a range of issues including UK AI company collaboration, sector challenges, growth opportunities and enablers. Produce market demographics and economic estimates and present them in straight-forward and user-friendly outputs including a report and dashboard. Conduct a new thematic analysis focussed specifically on UK market dynamics and competition. Produce future macroeconomic scenarios[footnote 3] based on findings regarding UK market dynamics and competition and their implications for UK AI economic activity. 1.2 Approach The study uses a mixed methods approach, combining desk-based review, qualitative and quantitative research and analysis (Figure 1.1). Figure 1.1 – AI Sector Study 2023 method overview A total of 45 stakeholder interviews were completed and 297 responses to the online survey were received. The 2022 company dataset was reviewed and updated using multiple sources to provide sector estimates for revenue, employment and GVA in 2023. Key data sources used in the 2023 study are summarised in Table 1.1. Table 1.1 – summary of key data sources Purpose Sources Company identification Glass.ai (web) Bureau van Dijk Beauhurst Lightcast UK Research and Innovation(UKRI) Gateway to Research Financial Times FDI Markets Revenue employment, GVA Bureau van Dijk Glass.ai (web) Investment Beauhurst 1.3 Interpretation of data\\xad Artificial Intelligence activity in the UK is not defined by a formal Standard Industrial Classification (SIC) code[footnote 4]. This study therefore uses experimental methods to identify and quantify AI activity across traditional economic sectors. The approach and methodology are consistent with those employed to deliver analyses of the UK cyber security sector annually since 2018, and with the method used to create baseline evidence regarding the AI sector in 2022[footnote 5]. The data used to inform the study includes: Identification of AI firms according to an agreed taxonomy using multiple sources, including AI driven language models applied across websites, news, social media, academic and official sources. Enrichment of web data using open and proprietary data sources including Companies House (company name, registration number, locations, incorporation date), Bureau van Dijk FAME (revenue, employment, profitability, remuneration, R&D spend) and Beauhurst (external grants, fundraisings, accelerator attendance, mergers and acquisitions (M&A) activity). 1.3.1. Comparison to previous study This 2023 study builds on the previous AI sectoral analysis. It uses the same approach and methodology to identify AI companies and produce headlines sector estimates of revenue, employment and GVA. However, as the sector continues to evolve, so to do the analytical parameters used to produce lower-level analyses of the sector. The study team worked with DSIT representatives and external experts to update the taxonomy used to categorise the sector. The main changes in the 2023 taxonomy are inclusion of model development as a new capability, segmentation of strategy, consultancy and training (2022) into two separate capabilities – AI strategy and consulting and AI skills and training, segmentation of the broader machine learning capability into different application areas, and updating of the ethics, trust and fairness capability to AI assurance. Similarly, the analytical tools used to classify companies have also evolved considerably within the past 18 months. The 2023 study therefore uses new, Large Language Model-enabled classification techniques to create capability tags based on more comprehensive descriptive information. Given these adjustments, while headline estimates can be considered entirely comparable to the 2022 study, lower level analyses regarding products, services and capabilities may not be entirely comparable because new methods have been used in 2023. 1.4 Acknowledgements\\xad The authors would like to thank members of the Department for Science, Innovation and Technology (DSIT) team for their input throughout the study. DSIT and the report authors would also like to thank all those who contributed to the research, including those who took part in in-depth strategic stakeholder interviews, responded to the business survey, or otherwise offered evidence and insights to the study. 2. UK artificial intelligence sector profile According to the Organisation for Economic Co-operation and Development (OECD), artificial intelligence (AI) is “a transformative technology capable of tasks that typically require human-like intelligence, such as understanding language, recognising patterns and making decisions”. In the UK, artificial intelligence is used by innovative companies across sectors to solve problems and improve processes that affect millions of lives every day, for example: Google Deepmind is an AI research and development company that uses advanced machine learning capabilities to solve problems in healthcare, scientific research, digital transformation and more. Darktrace is a cybersecurity company that uses AI for real-time threat detection and response by recognising abnormal network patterns. It provides a proactive approach to cyber resilience that helps keep data, networks and systems safe. Tractable uses computer vision and machine learning techniques to quickly and accurately assess damage in everything from road accidents to natural disasters, helping to make insurance claim processes faster and more accurate. Limejump uses AI and machine learning across several key areas of energy management, including distributed network management, grid balancing and demand response, helping to support the transition to a more sustainable and efficient energy system. This section explains how AI is defined for the purposes of the sectoral analysis, before providing key statistics regarding the profile of the AI sector in the UK. Key takeaways Globally strategic AI companies including Amazon and Microsoft have increased their UK footprint relative to other large, diversified AI companies. Since 2022, large professional services strategy and consulting firms have been increasing the size of their AI teams, contributing to notable uplifts in AI headcounts among larger diversified companies. Within the last year many new micro enterprises have entered the UK AI sector. The share of large AI companies has remained constant, but the number of small and medium sized companies has declined, pointing to potential scaling challenges. 2.1 Defining the UK Artificial Intelligence Sector Given that Standard Industrial Classification (SIC) codes do not yet include a specific ‘artificial intelligence’ classification, the analyses contained in this report are based on a business-focussed taxonomy that can better reflect AI activity in the UK. The taxonomy used to describe AI activity in this study is illustrated in Figure 2.1. Figure 2.1 – UK AI taxonomy Source: Perspective Economics Salient points regarding the sector taxonomy include: Dedicated vs Diversified AI companies: at the highest level, the taxonomy segments the business population according to whether they are a dedicated AI company, or whether AI activity makes up a smaller proportion of a much broader commercial business offering. Dedicated AI companies are considered to be businesses that provide a proprietary AI technical service, product, platform or hardware as their primary revenue source. AI Business Model: at a lower level the taxonomy segments between creators of strategic AI infrastructure[footnote 6], developers of AI products[footnote 7] and AI service providers[footnote 8]. Adopters of AI products or services developed by others are considered to be outside the scope of this study. AI Capabilities: capabilities apply across business models (denoted in Figure 2.1 by dashed braces), and an AI business may have more than one capability. Core capabilities have been updated following a taxonomy workshop comprising industry and academic experts and policy representatives. Changes include: removal of data mining as a stand-alone capability (deemed to be captured within other capabilities); separate categorisation of AI assurance, AI governance and AI safety; inclusion of model development as a new capability; and segmentation of AI strategy, consultancy and training (2022) into two capabilities – AI strategy and consulting and AI skills and training. Table 2.1 provides an illustration of some of the most prominent dedicated and diversified AI companies identified. Globally strategic diversified companies including Amazon and Microsoft have increased the size of their UK AI teams relative to other major diversified companies. Major strategy and consulting firms such as EY and Capgemini now feature as some of the most prominent AI employers, a trend spurred by OpenAI’s launch of ChatGPT Enterprise in August 2023[footnote 9]. Table 2.1 – Key AI Sector Contributors – Dedicated & Diversified (AI Employment) Dedicated position Business Model Diversified position Business Model 1 DeepMind no change in position strategic infrastructure 2 Amazon rise in position strategic infrastructure 2 Builder rise in position products 2 Microsoft rise in position strategic infrastructure 3 Databricks rise in position products 3 Deloitte rise in position services 4 Faculty rise in position strategic infrastructure 4 Google no change in position strategic infrastructure 5 Exscientia rise in position products 5 BT rise in position products 6 Lendable no change in position products 6 IBM drop in position strategic infrastructure 7 Oxbotica rise in position products 7 Accenture drop in position products 8 Graphcore rise in position strategic infrastructure 8 Capgemini rise in position services 9 Featurespace rise in position products 9 Cognizant no change in position services 10 Improbable drop in position products 10 EY rise in position services Source: Glass.ai, Perspective Economics In addition, each in-scope company has been classified into industry sectors using a bespoke text classification model. These businesses may identify with these sectors as they provide AI solutions specific to these areas. A total of 22 sectors are included in the 2023 study including: Aerospace and Defense Agriculture and Food Automotive and Transportation Construction and Real Estate Consumer Goods Education and Training Energy and Utilities Entertainment and Media Environmental and Sustainability Financial Services Healthcare and Wellness Information Technology Life Sciences and Biotech Logistics and Supply Chain Manufacturing Marketing and Advertising Professional Services Research and Development Retail and E-commerce Security and Investigations Telecommunications Travel and Hospitality 2.2. Number of UK AI companies Based on a combination of AI driven web intelligence, and collation of company data from numerous open and proprietary sources set out in Section 1.1, we estimate that there are currently 3,713 active UK companies providing AI products and services. 2.2.1 Registered Companies by Size Ninety-six percent of the companies identified are SMEs (small and medium-sized enterprises); 63% are micro businesses (Figure 2.2). Figure 2.2 – Size profile of UK AI companies Source: Glass.ai, Perspective Economics (n=3,713) Consultation with strategic stakeholders from across industry, academia and policy spheres pointed to the presence of a significant number of large technology firms as a key strength of the UK’s AI ecosystem, deemed to be at least in part due to the UK’s reputation for high quality scientific research and innovation. This assertion is supported by a comparison of the size of companies in the AI sector vis-à-vis the broader UK business population[footnote 10] (Table 2.2). Comparison with the 2022 study shows that the size profile of the sector has remained relatively constant. However, as discussed in subsequent Sections, in-depth interviews and employment data suggest that the sector may be experiencing scale-up challenges. Table 2.2 – AI size profile comparison Size UK business population estimates (2023) percentage (%) number of AI firms (change on 2022) Percentage of AI firms (percentage point (ppt) change on 2022) Large (250+ employees) 7,960 <1% 159 (+27) 4% (-) Medium (50-249) 36,905 3% 357 (+95) 10% (+1 ppt) Small (10-49) 222,785 15% 1,047 (-) 28% (-) Micro (1-9) 1,177,335 82% 2,150 (+261) 58% (-2 ppt) All businesses with at least 1 employee 1,444,985 100% 3,713 (+543) 100% Source: ONS, Glass.ai 2.3 Dedicated and diversified AI companies Of the 3,713 active companies identified through the study 59% are dedicated AI businesses and 41% are diversified (i.e., have AI activity as part of a broader diversified product or service offer, Figure 2.3). Figure 2.3 – Dedicated and diversified AI companies In comparison to other similar studies the proportion of diversified companies within the AI sector is higher than the proportion within the cyber security sector (29%) and slightly lower than the proportion of diversified companies within the Managed Service Provider (MSP) market (47%). This is indicative of the comparatively broad scope for AI technology applications across sectors. When combined with increases in AI related employment, it also points to a strong focus on development of AI products and services among both dedicated companies (e.g., DeepMind, Improbable, Benevolent AI) and established, diversified technology companies with much broader service offers (e.g., Amazon, Google, Microsoft, IBM)[footnote 11]. Figure 2.4 shows that most large AI companies are diversified (87%, n=139), whereas the majority of micro-AI companies are dedicated, meaning that AI is core to their business model (66%, n=1,562). Figure 2.4 – AI company size 2.4. AI company registrations In 2022, analysis of incorporation dates across the population of AI companies showed significant growth in AI company registrations since 2011. On average, 269 new AI companies had been registered each year since 2011, with a peak in new company registrations in the same year as the AI Sector Deal (2018). The 2022 report showed smaller numbers of new company registrations since 2018. A total of 329 companies within the 2023 company dataset have been incorporated since January 2022 (Figure 2.5). Just under two thirds of these companies were incorporated in 2022 (65%, n=213). At the time of writing, more than 100 new AI companies were registered in the UK in 2023[footnote 12]. However, analysis of survey data suggests that other factors may also be creating a more challenging start-up environment. For example, when asked about AI input requirements, 70% of respondents pointed to the need for increased computing power, 68% highlighted increased need for software and development tools and just under three fifths (58%) pointed to an increased need for training data. When asked about barriers to growth within the next 12 months, survey respondents saw access to equity investment and other forms of external finance as notable short-term barriers to growth: 53% (n=157) and 32% (n=94) respectively. Depth qualitative interviews highlighted similar challenges, including access to compute by Small and medium-sized enterprises (SMEs), and the expense of developing AI products and services. Figure 2.5 – AI company registrations Source: Companies House (2011 – 2023 | n=3,024 companies incorporated since 2013) 2.5 AI business model Figure 2.6 below shows the number of companies involved primarily in providing either AI products, or AI related services across business model categories in 2022 and 2023. Figure 2.6 – AI business models (dedicated companies only) Source: Perspective Economics In the 2022 study, a greater proportion of dedicated AI companies primarily produced AI related products. In 2023 most dedicated AI companies remain focussed on developing AI products (69%, n=1,516), however the share of dedicated companies now offering AI related services has increased by more than 10 percentage points, from 18% in 2022 to 31% in 2023. For the 2023 analysis, a new group of 25 strategic infrastructure providers has been created. This group includes companies such as Microsoft, Google, Meta, OpenAI and Anthropic, and accounts for 20% of employment, 38% of revenues, and 42% of GVA. Creating this new group of companies will allow future iterations of the sectoral analysis to more closely track the contribution of these companies to the UK AI sector. 2.6 AI capabilities Tailored LLM scripts were used to predict the core capabilities of each company identified in the 2023 dataset. Across 3,713 companies a total of almost 7,500 capability tags were applied[footnote 13]. Outputs of the analysis are presented in Figure 2.7 below and suggest that the highest share of employment (30%) is within companies that offer AI strategy and consulting. Computer vision and image processing accounts for the highest share of companies, suggesting high levels of UK AI activity in this space. Since 2022, both the number of AI Assurance[footnote 14] firms and their share of employment has increased, by 3 and 5 percentage points respectively. Figure 2.7 – AI capabilities Source: Perspective Economics (N.B. companies are tagged as having multiple capabilities and therefore percentages sum to more than 100%) While the method used to assign capabilities to each company has evolved since the 2022 study (see Section 1.3.1) it is possible to draw some illustrative comparisons between changes in market structure between 2022 and 2023 where capability tags have remained similar across both years. Acknowledging this caveat, 2023 data indicates that the number of companies involved in AI assurance activity has almost doubled since the 2022 study (from 25 to 47). Companies primarily involved in autonomous systems account for 8% of all firms in 2023, compared to 6% in 2022. The proportion of companies offering machine learning driven products and services across sectors has increased from 21% in 2022 to 35% in 2023, and the proportion of strategy and consultancy firms with AI activity has increased from 10% in 2022 to 13% in 2023. 2.7. AI growth drivers When asked about the future drivers of growth and demand for AI within their business, survey respondents pointed to developing and / or improving AI products as key future growth drivers (74% and 61% of respondents respectively). The top five drivers of growth remain consistent across companies of different sizes and business models, with some limited variation in order. Almost two fifths (39%) of survey respondents indicated that AI is the main driver of business products and services. A further third of respondents indicated that they had AI products or services already in market or as part of ‘business as usual’ and 18% suggested that they had AI products or services in production but not yet in market. 2.7. - growth drivers Growth driver % Developing new AI product(s) 74% Improving an existing product using AI 61% Improving an existing AI product 55% Improving an existing service using AI 53% Expanding use of AI to existing AI-driven services 47% Starting to use and develop AI services 41% Expanding use of AI for internal efficiencies 37% Starting to use AI for internal efficiencies 33% None of these 2% Source: Ipsos (n=251, multi-response) 2.7.1. Barriers to AI growth The survey also asked respondents to identify issues that had significantly affected their ability to meet business goals over the last 12 months. Fifty-three percent of respondents identified access to equity investment as a major barrier. Subsequent analysis of investment data (Section 5) suggests that investment is skewed towards London. However, survey responses indicate that, even within London, access to investment is a challenge. Almost half of businesses reporting that access to equity investment was a barrier to growth were London-based[footnote 15]. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. More than one quarter of respondents also indicated that a lack of technical skills has affected their ability to meet their business goals (26%, n=77). Within qualitative responses, several survey participants pointed to the highly competitive market for AI talent as a key contributor to technical skills gaps. 2.8 AI inputs Respondents were also asked how their requirement for certain inputs to their AI product and service offer has changed over the past 12 months. Seventy-five percent of respondents highlighted modest or significant increases in their requirements for training data, 71% cited a need for increased security measures and 71% highlighted a need for more local storage capacity (Figure 2.8). Figure 2.8– AI input requirements (modest or significant increase) Source: Ipsos (n=297) Note: Respondents could select more than one response and therefore percentages will not sum to 100. 2.9 Development and adoption Strategic stakeholder interviews pointed to rapid development and adoption of AI across certain sectors, including financial services, professional services, life sciences, and research and development. Qualitative perspectives on development and adoption are largely mirrored by secondary data, which suggests higher instance of AI companies in financial services, professional services, health and life sciences (Figure 2.9). Figure 2.9 – Instance of AI companies across sectors Source: Glass.ai, Perspective Economics 3. Location of UK AI companies Understanding the location of AI activity helps to identify and better understand notable clusters and regional strengths to inform policy making. This section presents findings regarding the location of AI companies identified in the 2023 study and draws comparisons with regional data from 2022. Key takeaways The concentration of AI companies in the UK remains heavily skewed towards London, the South East, and the East of England, accounting for 75% of registered office locations and 72% of trading locations. However, there is growing AI activity outside these areas, with Scotland and the North West jointly holding the fourth largest share of AI companies in 2023. There is a notable regional variation in AI sector focus. While London, the South East, and East of England dominate in financial services, R&D, marketing, and entertainment AI, other regions show more activity in automotive, transportation, manufacturing, energy, utilities, and agricultural technology AI applications. The UK AI sector has a strong international presence, with 65% of surveyed companies engaging in exports (up 14 percentage points from the 2022 study). Of these, 60% generate at least 40% of their revenues from exports, and 75% expect their exports to increase in the next 12-18 months. The US plays a significant role, accounting for over half of the UK’s internationally headquartered AI companies and more than three-quarters of AI-related employment, revenue, and GVA generated by international companies. 3.1 AI activity by UK region The 2022 study suggested high concentrations of AI companies in London, the South East and the East of England. Unlike other sectoral analyses, the concentration within these three regions did not change significantly when trading addresses were included in the location analysis. In 2023 the regional profile of registered offices remains largely unchanged. London, the South East and the East of England still account for 75% of registered office locations and 72% of trading locations. Figure 3.1 – AI registered office locations Source: Glass.ai, Bureau van Dijk The concentration of AI companies in the south and east of England is likely due to several factors that have influenced UK AI sector development to date including, for example, prominent UK AI sectors (e.g., within financial and wider professional services) and the significant role of Venture Capital (VC) and Private Equity (PE) funding, believed to be more accessible in London. Survey findings support the assertion that access to investment is more of a barrier outside of London. Weighted survey responses suggest that companies in the North East, Wales, the North West and Yorkshire and the Humber see access to equity investment as a barrier to growth[footnote 16]. In-depth interviews also pointed to market-driven regional disparities in the AI sector, with London and a few other hubs perceived to be focal points for the sector. “The danger is that we are largely concentrated in London and the South East (…) We need more resilience and breadth of activity.” Academic stakeholder Nevertheless, 2023 location data does also point to growth in AI activity outside of London and the South East. Scotland, the South West and the North West each account for between 4% – 5% of AI companies in 2023. Between 2022 and 2023 11% of new company incorporations have been in the North West and 10% have been in the West Midlands (n=13 and 11 respectively). This includes companies such as Mycardium AI (precision cardiac diagnostics), Mindguard (AI assurance)[footnote 17], Wondle (computer vision & image processing) and Provenir (machine learning for finance and professional services). Healthcare, strategy and consulting and computer vision and image processing account for over half of these new company incorporations outside of London. One fifth of AI companies incorporated in 2023 are located outside of London, the South East and the East of England. 3.2 Regional AI activity by sector Previous analysis of company sector classifications suggested that outside of London, the South East and East of England, there is more regional activity in automotive and transportation, manufacturing, energy and utilities and agricultural technology. Corresponding analysis for 2023 shows a similar breakdown of sectoral activity across regions, with energy and utilities, automotive and transportation, manufacturing and agriculture among the most prominent AI sectors in other regions. London, the South East and the East of England account for 84% of financial services AI companies and for approximately 80% of AI companies involved in R&D, marketing and advertising, and entertainment and media. Figure 3.2 – AI sectoral activity across regions Source: Glass.ai, Perspective Economics 3.3 International activity Approximately 9% of companies identified in the 2023 study were internationally headquartered (n=316) – a similar share of companies as in the 2022 study (also 9%). As in 2022, the US accounts for the largest share of internationally headquartered companies (53%, n=168), followed by India, Germany, France and Canada which each account for between 11 and 13 companies (~4%). US companies play a significant role in the UK AI sector. As well as accounting for over half of all internationally headquartered companies, US firms account for more than three quarters of all AI related employment, revenue and GVA generated by international companies. Further analysis regarding the economic contribution of international companies is provided in Section 6 – Market Dynamics. 3.3.1 AI exports Sixty-five percent of survey respondents indicated that they exported – an increase of 14 percentage points compared to responses in 2022[footnote 18]. Of those, approximately 60% of respondents generate at least 40% of company revenues from export activity and 75% of respondents think their exports will increase in the next 12-18 months. Of those who indicated that they do not export (35% of respondents, n=85), 58% have plans to start exporting in the next 12-18 months. Export trade data compiled for a sample of the largest dedicated AI companies also points to increased levels of AI export activity[footnote 19]. Since 2018 this sample of companies has increased export activity by 63%[footnote 20]. Data processing units, electrical machinery and equipment (e.g., printed circuits) and precision instruments have been among the most frequently exported commodities. Figure 3.3 – Instance of exporting among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics When asked about barriers to exporting, of the 65% (n=155) of survey respondents who indicated that they had some experience of exporting, 32% pointed to competition with exports from other countries, 30% cited lack of knowledge or networks for international markets, 25% cited regulatory barriers and a similar proportion highlighted lack of finance or insurance for exporting (23%). The top four barriers to exporting remain consistent across the different types of companies, i.e., those focused on AI products and services. 3.3.2. AI imports Using HMRC UK Trade Info data for the same subset of larger dedicated AI companies also points to increased import activity, particularly imports of processing units, electrical machinery and equipment and optical measuring instruments[footnote 21]. Companies involved in automation, R&D and life sciences – such as Oxbotica, Wayve and Exscientia AI – account for much of the recent increase in import activity among this subset of companies. Figure 3.4 – Instance of importing among dedicated AI companies (2018 – 2023) Source: HMRC UK Trade Info, Perspective Economics 4. Economic contribution of UK AI companies This section presents updated estimates of the economic profile and contribution of AI companies to the UK economy in 2023. Findings are based on modelling using reported company data (where available) and survey responses. Key takeaways AI companies generated over £14 billion in revenues in 2023, with diversified companies accounting for 68% (£9.7 billion) and dedicated AI companies accounting for 32% (£4.5 billion). Notably, 80% of all UK AI revenues (£11.4 billion) were generated by large firms, which make up only 4% of all companies identified. An estimated 64,500 Full Time Equivalents are employed in AI-related activity, an increase of approximately 29% from 2022 to 2023. Findings suggest a potential trend towards polarisation in the industry, with large companies and micro companies increasing their share of employment, while small and medium-sized firms may be facing a squeeze. The Gross Value Added (GVA) of dedicated AI companies increased by 20% from 2022 to 2023, reaching £1.2 billion. However, 30% of companies with known GVA coverage reported negative GVA in 2023, indicating that a notable portion of dedicated AI companies may be operating at a loss. On average, dedicated AI companies employ 14 people, generate £2 million in revenues and contribute £550,000 in GVA. The average diversified AI company employs 23 people, generates £6 million in revenue and contributes £3 million in GVA. 4.1 Estimated revenue Estimates produced for this 2023 study indicate that UK AI companies generated a total of more than £14 billion in revenues. While revenues among dedicated AI companies are down slightly, from £5.2 billion in 2022 to £4.5 billion in 2023, AI-related revenues among diversified companies are notably higher at (£9.7 billion compared to £5.4 billion in 2022)[footnote 22]. Six of the top 20 dedicated companies have lower estimated revenues in 2023 than they did in 2022. Table 4.1 – revenue estimates #Type Estimated AI related revenue (2022) Estimated AI related revenue (2023) Dedicated £5.2 billion (49%) £4.5 billion (32%) Diversified £5.4 billion (51%) £9.7 billion (68%) Total £10.6 billion £14.2 billion Source: Bureau van Dijk, Perspective Economics 4.1.1. Revenue by company size Estimates suggest that 80% of all UK AI revenues (£11.4 billion) are generated by large firms which make up 4% of all companies identified. This share is not significantly higher than the share of revenues generated by large cyber security firms (74%). Small and medium sized companies account for a smaller share of revenues in 2023 (18%, £2.7 billion) than they did in 2022 (26%, £2.8 billion). Figure 4.1 – Revenue estimates by firm size Source: Perspective Economics, Base: £14.2 billion 4.2 Estimated employment In 2022, a total of 50,040 Full Time Equivalents (FTEs) were employed across both dedicated and diversified AI companies[footnote 23]. In 2023, total AI-related employment has increased by ~29% to 64,539 (+14,499). Approximately 47% of employees are within dedicated AI companies and 53% are within diversified companies (n=30,247 and 34,292 respectively). For diversified companies, figures are estimates of AI-related employment, and suggest that the share of employment within diversified AI companies is 3% higher in 2023. In 2023 AI companies at either end of the size spectrum (large and micro firms) have grown their share of total employment, by 6 percentage points and 4 percentage points respectively. The share of employment within small and medium sized companies has fallen in 2023, pointing to a potential squeeze on small and medium sized firms. Figure 4.2 – Employment by company size (2022 – 2023) Source: Glass.ai, Perspective Economics Table 4.2 provides a summary of firm counts, estimated AI employment and revenue by core capability. Table 4.2 – Headline Metrics by Capability[footnote 24] Capabilities dedicated-diversified firm count AI employment AI GVA (m) Model Development dedicated 227 4,700 £1,141 Model Development diversified 112 6,000 £1,465 total 339 10,700 £2,606 Strategy and Consulting dedicated 233 3,300 £75 Strategy and Consulting diversified 260 14,300 £1,722 total 493 17,600 £1,797 Machine Learning (financial services) dedicated 304 4,800 £143 Machine Learning (financial services) diversified 219 3,300 £590 total 523 8,100 £732 Autonomous Systems dedicated 168 3,000 -£3 Autonomous Systems diversified 136 2,200 £354 total 304 5,200 £351 Computer Vision and Image Processing dedicated 508 5,300 -£14 Computer Vision and Image Processing diversified 331 4,700 £231 total 839 10,000 £217 AI Assurance dedicated 29 400 £11 AI Assurance diversified 20 400 £57 total 49 800 £68 Machine Learning (Retail) dedicated 27 300 £17 Machine Learning (Retail) diversified 21 300 £22 total 48 600 £38 Natural Language Processing dedicated 232 2,100 £15 Natural Language Processing diversified 89 500 £19 total 321 2,700 £33 Machine Learning (Logistics and Supply Chain) dedicated 29 300 £3 Machine Learning (Logistics and Supply Chain) diversified 24 500 £24 total 53 700 £27 Speech and Audio Processing dedicated 39 500 £2 Speech and Audio Processing diversified 18 100 £5 total 57 600 £7 Skills and Training dedicated 14 300 £3 Skills and Training diversified 12 20 -£0.048 total 26 320 £3 Machine Learning (Energy) dedicated 27 300 -£1 Machine Learning (Energy) diversified 27 100 £0.7 total 54 500 £2 Machine Learning (Education) dedicated 28 200 -£0.4 Machine Learning (Education) diversified 29 100 £0.9 total 57 300 £0.5 Machine Learning (Healthcare) dedicated 339 4,700 -£177 Machine Learning (Healthcare) diversified 211 1,800 £68 total 550 6,400 £109 4.3 Estimated Gross Value Added Modelled data for 2,204 dedicated AI companies suggests that aggregate GVA has increased from £1.0 billion in 2022 to £1.2 billion (+20%, £0.2 billion). Figure 4.3 provides a summary of 2023 estimates of revenue and GVA for companies of different sizes. Figure 4.3 – Revenue and GVA by company size Source: Perspective Economics Of the 235 companies with known GVA coverage[footnote 25], 70 have negative GVA in 2023 compared to 67 in the 2022 study (2% of dedicated companies in 2023 compared to 3.5% in 2022). AI companies may have negative GVA when they are, for example, using external investment to support development of new technologies and research resulting in operational losses that are greater than the positive GVA attributable to wages and salaries. 4.4 Summary of economic contribution Revenue Estimates suggest that UK AI companies generated more than £14 billion in revenues, with 68% of this generated by diversified companies and 32% by dedicated AI companies. Approximately 80% (£11.4 billion) of UK AI revenue is generated by large firms, despite them making up 4% of the identified companies. The estimates also indicate that small and medium sized companies account for an 8% lower share of revenues in 2023 than they did in 2022. Employment In 2023, a total of 64,539 FTEs were employed across both dedicated and diversified AI companies, rising by ~29% since 2022. Approximately 47% of these employees are in dedicated AI companies and 53% are in diversified companies. Employment figures by company size point to polarisation of AI activity at either end of the size spectrum, with large AI companies accounting for 53% of employment (6% higher than in 2022) and micro AI companies accounting for 14% of employment (4% higher than in 2022). The data may also suggest that there is a potential squeeze on small and medium-sized AI firms with their share of employment falling between 2022 and 2023. GVA Modelled data for the dedicated AI companies suggests that aggregate GVA has increased by 20% between 2022 and 2023, however, of 2% of the dedicated companies with known GVA coverage have negative GVA. 5. Investment in UK AI companies This section provides findings from analysis of the investment raising activity of UK AI companies included in the study. It draws on investment data from the Beauhurst platform, which tracks announced and unannounced investments in high-growth UK companies, together with findings from qualitative interviews with AI investors and relevant AI survey business responses[footnote 26]. Key takeaways In 2023 the value of investment in AI companies fell by half (53%) reflecting the overall drop in investment across the wider high-growth ecosystem. However, the volume of deals remained relatively stable (-4%) potentially denoting better value for investors. The average deal size for AI companies in 2023 aligned with pre-pandemic investment levels, again consistent with the wider high-growth ecosystem following what are deemed to be exceptional annual totals in 2021 and 2022. Investment in AI companies is heavily concentrated in London, which secured more than 70% (£822 million) of total equity investment in 2023. 5.1 Investment to date AI companies raised £2.4 billion in equity investment in 2022, with an average deal size of £4.6 million (527 deals). Record highs in 2022 were driven by several large deals, including a £210 million deal raised by peer-to-peer lending platform Lendable in March – the largest single equity deal raised by an AI company between 2021 and 2023. Companies at the growth stage accounted for eight of the top 10 fundraisings in 2022. Among them, Improbable, a London-based virtual software company, raised a total of £203 million via one £115 million fundraising in April and a £88.1 million fundraising in October 2022. According to investment data provider Beauhurst, the boost in investment in 2022 is likely due to several factors. The introduction of government stimulus measures targeted at supporting businesses led to increased investment across the high-growth ecosystem. This assertion was supported within qualitative interviews with strategic stakeholders and businesses who were keen to see initiatives such as the British Business Bank’s Seed Enterprise Investment Scheme (SEIS) and Enterprise Investment Scheme (EIS) sustained and expanded to ensure that strong levels of early-stage AI investments are maintained. In addition, advancement of technology and AI over the years has increased popularity and demand among individuals and businesses – evident in investment raising activity within sectors such as application software, Software as a Service (SaaS), and data analytics. In 2022, companies within these sectors participated in 403, 233, and 203 fundraising deals respectively. These sectors were also the most prominent areas for international investment (foreign investors contributed to 70% of deals in application software) and were also highlighted as areas of focus in qualitative interviews with investors. “Through our experience of investing, we often look at three specific themes: AI in the enterprise, AI for security applications, and how AI is shaping the world of emerging technologies.” AI investor interviewee In 2023 the value of investment in AI companies fell by 50% to £1.2 billion, yet the volume of deals remained relatively stable (-1%) potentially denoting better value for investors. The average deal size for AI companies decreased from £4.6 million in 2022 to £2.3 million in 2023, aligning with pre-pandemic investment levels. This decrease reflects the overall drop in investment across the wider high-growth ecosystem and marks a return to pre-pandemic investment levels, following what are deemed to be exceptional annual totals in 2021 and 2022. An increase in interest rates and over deployment in 2021 and 2022 contributed to a more cautious fundraising landscape in 2023. Figure 5.1 – Equity fundraising timeseries Source: Beauhurst However, between January and July 2024 AI companies raised £1.5bn in equity investment via 150 fundraising deals – already surpassing the total raised in 2023 and indicating that although AI companies may not reach the highs of 2022, investment in this area remains strong. Investor interviews confirmed that positive sentiment was returning to segments of the investment market. “Private Equity (PE) is beginning to pick up, and fundraising has freed up a bit – Limited Partners (LPs) are back writing cheques again. [However], there are a lot of zombie VC backed businesses doing down rounds[footnote 27] and looking for exits. PE isn’t coming to the rescue unless [the business] can show a very quick path to profitability.” AI investor interviewee 5.2 Investment profile Businesses seeking investment can be classified into stages based on their growth and development: seed, venture, growth, and established. Seed-stage companies are generally newly formed start-ups with few employees and low valuations, often seeking their initial investment round. Venture-stage companies have typically spent years honing their business models and technologies, building an established reputation, and securing investment and valuation in the millions. Companies in the growth stage have been active for over five years, have regulatory approval, and are likely to bring in significant revenue and investment. Established companies have been trading for over 15 years and have a track record of profitability or significant annual turnover after more than five years. Changes in the proportion of firms at different stages of evolution between 2022 and 2023 support qualitative views of a relatively strong start-up landscape (+7% of firms in 2023) experiencing scale-up challenges (lower Venture and Growth percentages in 2023), and with less scope for exit in 2023 (-2% of firms in 2023). Figure 5.2 – Dedicated AI company stage of evolution (vs 2022)[footnote 28] Source: Beauhurst Changes in the percentage of firms at different stages between 2022 and 2023 are reflective of findings from qualitative interviews. These highlighted a well-established ecosystem for early-stage AI investment via VCs and government-backed initiatives, but also pointed to a critical gap in growth-stage financing (Series B and beyond). Investors interviewed to inform that study felt that the gap in growth-stage financing forces promising UK start-ups to seek investment in the US or other markets, leading to a potential talent drain and loss of innovative capacity. “A £2 million round in the UK is probably the same sort of risk and time to completion as a $10 million round in the US. Because they have more money, they are more relaxed about what they invest in, and how many hoops the founders would have to jump through. We have an early-stage company in our portfolio – they didn’t have massive traction. We did a small fundraise with them, and then the founder went to San Francisco for two weeks and essentially raised $10 million in the space of 2 months.” AI investor interviewee Analysis of fundraisings by stage of evolution shows that the share of investment in Growth stage companies fell from around half in 2022 to less than a third in 2023 (Figure 5.3). Figure 5.3 – Share of fundraising by stage of evolution (Dedicated Only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) “The [early-stage] funding is there, but for growth, companies need Series A funds capable of investing £2 million to £3 million in businesses with significant market share, proven success, and half a million to a million in annual recurring revenue (ARR), primarily in the UK market. American investors tend to value revenue generated in the UK less than that in the States, discounting it by 50% to 75% as they seek signals of scalability in the US market. Revenue from the US is considered a stronger indicator of potential success.” AI investor interviewee 5.3 Investment by sector Companies operating in the information technology and financial & professional services sectors have consistently secured the highest proportion of fundraising, typically raising more than have of total investments each year. Companies involved in automotive & aerospace and health & life sciences have typically secured between a fifth and one third of total investments, with companies in other sectors securing much lower shares of investment, including for example agriculture, construction, manufacturing and environment & sustainability. Figure 5.4 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) 5.4. Investment by region Investment in AI companies is largely concentrated in the southern regions. AI companies headquartered in London secured £822 million (72%) in total equity investment in 2023, highlighting the city’s popularity amongst AI companies and underscoring the capital’s position as a leading investment hub. The South East and East of England secured 10% and 7% of total funding respectively. Figure 5.5 – Share of fundraising by region (dedicated only | 2016 – 2023) Source: Beauhurst (17,450 fundraisings) According to investment data provider Beauhurst, London’s dense cluster of AI companies, robust financial networks, population density, and access to talent are key contributors to its popularity among startups and investors. In contrast, businesses based in the East Midlands (0.14%) and Northern Ireland (0.01%) received the lowest proportion of investment in 2023. These figures are symptomatic of the limited presence of AI companies outside the capital and access to fewer funding opportunities. As mentioned in Section 3, survey findings and in-depth interviews also suggest that companies outside London are more likely to see access to equity investment as a barrier to growth. Within qualitative interviews, investors were keen to see policy supports that could help UK AI businesses (particularly SMEs) offer globally competitive compensation packages. They felt this could take the form of better coordination, awareness raising and / or targeting of existing supports available at regional or local levels. 6. AI market dynamics This 2023 study seeks to provide deeper insight into a series of questions that explore the dynamics of the market for AI products and services in the UK. Specifically, this section uses data on revenue, employment, location, mergers and acquisitions and investment, together with survey data to respond to the following questions: What are the levels of market concentration in the provision of AI products, services and infrastructure? To what extent does the AI sector reflect oligopolistic or monopolistic competition dynamics? How might this change in the future? What are the barriers and / or enablers to competition in the UK AI sector? Does the AI sector see significant vertical integration and what impact does this have on competition? Are larger AI providers enacting predatory merger and acquisition practices that discourage growth in smaller or newer AI companies? Are UK AI businesses able to compete effectively in the global market? Are there areas where the UK has a comparative advantage? To what extent are key AI supply chains reliant on imports and global investment? What does the future of the AI sector look like? Is this likely to be positive or negative for the UK economy and consumers? Key takeaways Despite accounting for only 9% of AI companies in the UK, internationally headquartered firms account for 47% of AI-related revenues and 33% of AI employment. This suggests international companies play an outsized role in the UK’s AI sector. The top 10 AI companies in the UK account for 62% of the sector’s total Gross Value Added (GVA), indicating a high degree of concentration among a small number of large players. Despite risks regarding international dependencies and market concentration, the outlook for AI in the UK is positive given notable growth in AI related revenues and employment over the past 18 months, and a vibrant ecosystem of partnerships between leading dedicated AI companies, UK academic institutions, UK government and other publicly funded UK organisations. 6.1. UK AI market structure Companies operating within the AI market in the UK can be grouped into three main segments as follows: Strategic Infrastructure Providers: a small number of strategically significant AI companies (<1% of all companies identified), most of which add considerable value to the UK economy through their AI activities relative to other market segments (42% of total GVA). Example companies include Google, Microsoft, Deepmind and Meta. This segment also includes other strategic infrastructure providers such as OpenAI and Anthropic, although the current scale of UK operations (and therefore GVA) is smaller. AI Product Developers: a majority (65%) of companies, almost 86% of which are small or micro, involved mainly in computer vision and image processing and / or broader machine learning within the health and professional services sectors. Contributing just over 25% of sector GVA. AI Service Providers: just over one third of companies identified, 89% of which are small or micro, involved mainly in provision of strategy and consulting or machine learning enabled services across sectors. Contributing just under one third of sector GVA. Across all three segments, a small number of companies account for a majority of GVA (Figure 6.1). However, whereas large companies make up less than 4% of the total in the product and service provider segments, they account for more than 80% of strategic infrastructure providers. As such, strategic infrastructure providers make a disproportionate contribution to UK AI sector value added and therefore to the future performance of the sector in the UK. Figure 6.1 – UK AI GVA contributions Source: Perspective Economics (GVA depicted on X and Y axis) Further analysis of descriptive information illustrates the significant role that the UK’s science base plays within the AI sector. A total of 238 dedicated AI companies are described as having some involvement in research. This equates to over 10% of all dedicated AI companies and these companies account for 42% of total GVA generated by dedicated AI companies (£0.5 billion). 6.2 Market concentration Globally the AI market has seen substantive levels of integration between 2022 and 2023. In January 2023 Microsoft deepened its partnership with OpenAI in a multi-year, $10 billion investment that would secure a 49% stake in the company. According to Microsoft, it’s investment would “accelerate AI breakthroughs to ensure these benefits are broadly shared with the world”[footnote 29]. However, according to the UK Competition and Markets Authority (CMA), “misuse of AI and other algorithmic systems, whether intentionally or not, can create risks to competition by exacerbating or taking advantage of existing problems and weaknesses in markets”[footnote 30]. For example, recommendation systems could distort competition by giving undue prominence to one market participant over another, AI systems could enable price-setting based on tacit collusion, or market incumbents could use AI to heighten barriers to market entry. In the US, regulators (the Department of Justice and Federal Trade Commission) recently agreed an approach to an antitrust investigation into Microsoft, OpenAI and AI chipmaker Nvidia given concerns over their dominance of the AI space[footnote 31]. Across different segments of the market (dedicated, diversified and total market) analysis of revenue and employment data consistently returns Herfindahl-Hirschman Index (HHI) figures that are reflective of a competitive market in the UK[footnote 32]. While the presence of larger companies such as Microsoft, Google and Meta points to marginally greater concentration within the diversified segment of the sector, HHI calculations overall suggest good levels of competition. Table 6.1 – HHI calculations AI market segment HHI (revenue) HHI (employment) result Dedicated 364.6 45.5 competitive Diversified 551.5 195.8 competitive All 252.0 65.3 competitive Source: Perspective Economics However, HHI calculations are recognised as offering a relatively narrow view of market concentration. With respect to this analysis, HHI calculations are also limited because they are based on estimated UK revenues and may not therefore reflect the totality of revenues attributable to the UK. Given these limitations, the study has also considered a range of other metrics to understand the extent to which the UK AI market shows potential for reduced competition in future. 6.2.1. Alternative measures of concentration Analysis of shares of AI related revenues, employment and GVA among the top 10 companies shows that these companies account for almost half of total UK market revenues, one fifth of total AI related employment and almost two thirds of GVA. Value added is the most concentrated measure, particularly within the dedicated segment where the top 10 companies account for 81% of GVA (Table 6.2). Table 6.2 – alternative measures of concentration Metrics and segment Total (£) Top 10 (£) Top 10 (%) AI revenues - dedicated £4.5 billion £2.2 billion 48% AI revenues - diversified £9.7 billion £4.5 billion 47% AI revenues - all £14.2 billion £6.7 billion 47% AI employment - dedicated £30,200 £3,000 10% AI employment - diversified £34,300 £10,200 30% AI employment - all 64,500 £13,200 20% GVA - dedicated £1.6 billion £1.3 billion 81% GVA - diversified £4.6 billion £2.5 billion 55% GVA - all £6.2 billion £3.8 billion 62% Source: Perspective Economics (figures may not sum due to rounding) In contrast, the top 10 dedicated companies account for just 10% of AI employment, pointing to high levels of competition for workers among dedicated UK AI companies. 6.2.2. AI Infrastructure concentration Web intelligence emphasises the extent to which just a few prominent US providers dominate the AI infrastructure landscape. For example, between one fifth and one quarter of companies for which web intelligence was available (n=1,313) use AWS, OpenAI and / or Azure (Figure 6.2). Figure 6.2 – AI infrastructure mentions Source: Glass.ai (n=1,313) 6.3 Finance and investment dynamics Levels of investment into the development of market-leading AI companies in recent years have been extremely high, to the extent that only a handful of global corporates have the means to fund leading-edge development efforts. Microsoft invested $10bn in OpenAI in early 2023[footnote 33], Google and Amazon invested $6.5bn in Anthropic in mid-2023[footnote 34] and most recently Meta announced that it would increase capital expenditure, incur higher infrastructure operating costs and expect higher payroll costs due to more, higher-cost technical roles[footnote 35]. While these are well documented high-profile examples, business survey responses show that AI development investment requirements are relative. A significant proportion of business survey respondents highlighted access to investment or other forms of external finance as a barrier to growth (53% and 32% respectively, n=297). Qualitative interviews also provided evidence that investment in the UK represents a potential barrier to AI sector growth. “We don’t have enough capital from UK pensions to support innovation technology and that’s a big challenge. Again, the government has acknowledged that it’s a challenge. Mansion House reform is designed to do that. But there’s a great level of urgency needed. If we don’t act quickly, the UK will quickly be left behind in terms of development, and we don’t want to have a brain drain of technical talent leave because the resources, at least in terms of the capital, are not there.” AI investor interviewee 6.3.1. Cost of AI infrastructure and operations High development costs are easy to understand considering the level of computing power and investment of high-cost employee time required to develop AI products and services. Data captured by the EPOCH research institute[footnote 36] highlights the exponential growth in computing power required to train the most sophisticated AI models (Figure 6.3). Figure 6.3 – computing power for AI-system development Source: EPOCH Research Institute (Notable Models) Since the start of 2022, 196 new AI models have been developed – almost one quarter of the total number of models developed since 1950 – and 103 new AI models were developed in 2023 alone. The scale, cost and pace of AI development are also seen as challenges to growth and competition among UK AI companies. One fifth of survey respondents cited AI procurement and operation costs as having significantly affected the company’s ability to meet its business goals over the past 12 months. Of those indicating that procurement costs were a barrier, 93% described themselves as AI product developers. Over three quarters (76%) reported needing more training data, 72% have needed better security measures, and more than three fifths have required better network infrastructure and / or more local storage capacity (71% and 60% respectively). Across the AI business and stakeholder qualitative interviews, a lack of AI infrastructure was commonly raised as a potential barrier to future sector growth. Specifically, this included the cost of, and access to compute resources, availability of and access to data centres and supercomputers, energy costs, and access to training data. “People talk about AI like it’s one big thing, but it’s powered by data and cloud computing, it needs a lot of silicon and energy – if you’re bad at any of these, you’re bad at AI.” AI business interviewee One of the main issues identified was the cost and limited access to compute resources, particularly for universities and smaller businesses. These resources were important for AI developers to be able to process and analyse large datasets. There was a sense that these organisations lacked the financial resources to invest in expensive hardware and software required for AI development and deployment. A lack of access to data centres and supercomputers was specifically mentioned in this context. Some of the AI business interviewees explained that this made them heavily reliant on other countries for resources and data, with the US being commonly mentioned. “[There are] so many products coming out of the US and they have such better funding. They can move at much faster speeds. Also, the products that we rely on to develop our own services are backed by AI components that are from the US.” AI business interviewee Smaller businesses also reported that a lack of compute resources hindered their ability to compete with larger businesses and limited their potential for innovation. “There are tons of really important stuff happening, but working in this space is expensive, thus out of reach for small companies.” AI business interviewee 6.3.2. Role of international investment Beauhurst data suggests that UK AI companies have some dependency on international investment. While UK funders make most investments in UK AI companies, international funders, including Microsoft, Nvidia, Softbank and Andreessen Horowitz account for 60% of value among the top 20 fundraisings. Example investments made by these international funders are provided in Table 6.3 below, and suggest that the focus of international investment is not concentrated in any one sector or type of AI company. Table 6.3 – example international investments Funder and UK Company (top 3 investments) Sector M12 (Microsoft) - Wayve Automotive and Transportation M12 (Microsoft) - Graphcore Information and Technology M12 (Microsoft) - Hazy Financial Services Nvidia - Wayve Automotive and Transportation Nvidia - Synthesia Education and Training Nvidia - Charm Therapeutics Life Science and Biotech Softbank - Improbable Entertainment and Media Softbank - Exscientia Life Science and Biotech Softbank - Peak Information and Technology Source: Beauhurst 6.4 Significance of international companies Across both dedicated and diversified segments, nine percent of companies are internationally headquartered. Despite accounting for a relatively small share of the total number of companies, internationally owned companies account for almost half of AI related revenues (47%) and one third of AI employment (Table 6.4). Diversified, typically larger, international companies account for a notable share of AI employment, suggesting that these companies are both an important source of AI employment, while also putting upward pressure on the cost of AI talent. Table 6.4 - Significance of internationally owned companies Total (£) International headquarters (£) International headquarters (%) Dedicated firms £2,204 £162 7% Diversified firms £1,509 £154 10% All firms £3,713 £316 9% Dedicated AI Revenues £4.5 billion £0.4 billion 9% Diversified AI Revenues £9.7 billion £6.3 billion 65% Total AI Revenues £14.2 billion £6.7 billion 47% Dedicated AI Employment £30,247 £3,003 10% Diversified AI Employment £34,292 £18,364 54% Total AI employment £64,539 £21,367 33% Source: Perspective Economics Within the past three years (2020 – 2023) several internationally significant AI companies have established a UK presence. Examples include OpenAI, ElevenLabs, Anthropic, X.ai and Helsing (Figure 6.4)[footnote 37]. The current scale of these companies in the UK varies, from micro to medium sized[footnote 38], and the scale and purpose of their UK operations is continuing to evolve. Job post data suggests that development of AI assurance and safety functions is a focus of UK-based operations. For example, OpenAI recently recruited for a European AI Safety Policy Lead in London, Anthropic has recruited for Risk Management and Compliance roles, Meta has recruited for ‘Integrity Operations Project Managers’ and Google has recruited for senior safety and risk management roles. While the scale of globally strategic AI companies’ operations in the UK will vary, with appropriate policy interventions, the focus of their UK operations could be a lever to support the growth of UK niches such as AI assurance. Figure 6.4 – International UK incorporations Source: Perspective Economics Data on inward investment into the UK shows that there were almost 200 AI-related investments between 2019 and 2023. Half of these investments have been by information technology companies (n=96) and of those, almost one fifth (19%, n=18) were made in 2023. Significant inward investment projects include Microsoft (£2.5 billion investment into new datacentres and AI safety and research activities)[footnote 39], C3.ai (relocation of EMEA headquarters to London)[footnote 40] and Lambda Automatica (expansion of R&D and new products)[footnote 41]. 6.5 Mergers and acquisitions Analysis by investment data provided Beauhurst, produced to inform this study, shows that UK AI companies have participated in an increasing number of mergers and acquisitions since 2018, with a total of 58 acquisitions occurring between 2018 and 2023. M&A activity peaked in 2022 (22 acquisitions), driven by the potential that AI technology has to improve businesses operations across sectors (horizontal acquisitions). The total value of M&A deals has also continued to grow, peaking at £362 million in 2023 including, most notably, BioNTech’s acquisition of InstaDeep. M&A deal values in 2023 were 68% higher compared to 2022. Between 2018 and 2023, just under 80% of M&A deals were horizontal (i.e., between companies at similar stages of production and / or operating within different supply chains). At the time of writing, data does not show high volumes of vertical deals in which larger UK AI companies are acquiring smaller firms. Most AI acquisitions have occurred at seed or venture stage, likely to be partly due to the nascent character of the sector, but also driven by the desire to take ownership of intellectual property (IP). Examples of horizontal AI sector deals include: 2021 Nottingham-based company Ideagen, which specialises in compliance software, acquired Ai XPRT for £2.00 million. Ai XPRT has developed a platform that has automated the auditing of financial disclosure reports, compliance checks documents and reviews for due diligence. Ideagen plans to use Ai XPRT to accelerate its product development and implement it within its cloud service architecture to enhance its AI capabilities. Northamptonshire-based Rahko was acquired by US biotechnology company Odyssey Therapeutics. Rahko uses its quantum machine learning platform to discover drugs quicker and more cost-effectively. Odyssey will add Ranko’s drug discovery platform to its own to enable faster and more efficient drug discovery. 2022 Spotify acquired Sonantic for £78.1 million in 2022. Sonatic develops software that utilises machine learning to create artificial voices. This will help Spotify to create new user experiences, such as giving users context about upcoming recommendations when they aren’t looking at their screens. 2023 German pharmaceutical and biotechnology firm Bayer acquired Edinburgh-based Blackford Analysis. Blackford Analysis has developed an AI imaging platform that can analyse large sets of images. Bayer plans to use this platform to implement AI technology into its radiology offerings, which will aid in diagnosis and increase the volume of examinations carried out. BioNTech completed its acquisition of InstaDeep to enhance its AI-driven drug discovery and development capabilities. InstaDeep, now a London-based subsidiary of BioNTech, continued to serve global clients across various industries while adding 290 professionals to BioNTech’s team. The transaction, valued at around €500 million, supported BioNTech’s strategic growth in AI and ML for next-gen immunotherapies and vaccines. The upward trend in AI M&A activity looks set to continue into 2024. 6.6 Access to talent One quarter of AI business survey respondents indicated that a lack of technical skills posed a significant barrier to future growth. Decisions by globally strategic AI companies to locate in the UK suggests that the UK is an attractive place for accessing AI talent, yet competition for talent is intense and regionally disparate. Qualitative research indicated that the AI sector faced similar challenges to other technology sectors in the UK, including similar skills gaps and shortages, high salary demands, and access to international talent. Stakeholders from industry and academia, as well as some of the interviewed businesses, noted that the UK’s education system was not keeping pace with skills demands from industry. This was considered a more acute challenge for AI businesses than other technology businesses, given the rapid pace of change of AI technologies. Smaller AI businesses reported finding salary demands for AI talent particularly difficult and felt that they were frequently being outcompeted on salary by dominant big tech firms, whether headquartered in the UK or abroad. “We need to support the movement of people between university and industry in ways we haven’t seen before … not just losing them to big tech. We need a closer working relationship.” Public Sector Stakeholder “A lot of people gain experience and skills in UK AI sector then leave for other countries. More and more people are returning back home. It has become a significantly more prominent issue over the last 5 years. Other countries are trying to get their best AI talent back home.” AI Business Some businesses that relied on bringing in talent and skills from abroad noted that this had become more difficult following the UK leaving the EU, and the COVID-19 pandemic, with subsequent changes to visa requirements and increased waiting times to access talent from abroad. “Since Brexit and COVID-19, it’s been harder to recruit people, so productivity has been hit.” AI business Smaller businesses highlighted apprenticeships as having an especially important role in the AI sector. The main benefits noted for apprenticeships in this context was that they were that they were more affordable, allowed people to enter the AI labour market at a younger age (rather than waiting for them to go through a higher education route), and allowed people to develop practical skills on the job, thereby ensuring their skills matched the employer’s or industry’s needs. AI job post data shows that over half of the AI roles advertised in 2023 were London-based. Manchester, Bristol and Cambridge are the next most common locations for AI roles. Together these locations account for more than two thirds of all unique jobs posted in 2023. The concentration of demand in London is consistent with Beauhurst findings regarding the concentration of AI investment, which is also London-centric. According to labour market analytics platform Lightcast, the median advertised salary for an Artificial Intelligence Engineer in London is £87.500 – 17% above the UK figure. In turn, the median UK-wide salary for AI Engineers in 2023 (£75,000) was approximately double the overall median salary (~£35,000). There are clearly strong market incentives for AI companies to build their operations in London, meaning that stronger policy supports may be required if economic benefits of AI are to be more evenly realised across UK regions. 6.7 AI collaboration Web data on partnerships among leading dedicated AI companies points to a vibrant AI ecosystem – 27 of the largest dedicated AI companies have collaborated with ~130 partners spanning a range of organisations including academic institutions (e.g., Universities of Cambridge, Oxford, Bristol, Warwick, Essex and UCL), corporates (e.g., HSBC, Merk, Sanofi, Bristol Myers Squibb, Asda, Ocado, AIG, Bupa), government departments and other publicly funded organisations (e.g., the NHS, Transport for London and the BBC). Figure 6.5 – AI ecosystem partnerships (illustrative) Source: Perspective Economics Consortium members included glass.ai, Beauhurst, glass.ai, Ipsos and academic experts (Professors Rob Proctor and Roger Woods). ↩ MIT Technology Review (2023), The great acceleration: CIO perspectives on generative AI”, MIT, 2023 ↩ Provided as a stand-alone output accompanying this main report for internal purposes. ↩ Standard Industrial Classification (SIC) codes are the current system of classifying business establishments and other statistical units by type of economic activity in which they are engaged. ↩ DSIT (2022) Cyber Security Sectoral Analysis 2022, accessible at https://www.gov.uk/government/publications/cyber-security-sectoral-analysis-2022 ↩ Including hardware, frameworks, software, libraries and platforms. ↩ Companies producing bespoke, value adding AI solutions marketed and sold as products. ↩ Companies offering skills and expertise to support the adoption of AI products. ↩ https://openai.com/index/introducing-chatgpt-enterprise/ ↩ UK Business Population Estimates (2022): Available at: https://www.gov.uk/government/statistics/business-population-estimates-2022 ↩ It is worth noting here that, given the breadth and varying scale of AI activity, it is not possible to delineate dedicated and diversified AI firms solely on the basis of the proportion of AI related revenue or employment within companies. Companies with relatively small AI teams can be dedicated AI companies and by the same token, companies with large AI teams can be diversified. Therefore instead, the study used a combination of data on AI related employment and a detailed manual review of company descriptions as the basis of final decisions on whether or not a company falls into the dedicated or diversified category. ↩ It is worth noting that the 2023 figure may be an underestimate due to a lag between start-up and registration dates. ↩ The LLM script assigned a score of between 1 and 10 to each company according to whether descriptive information gathered by the research team indicates that the company has the corresponding capability. Based on manual review of a sample of 50 results, a score of 7 or more was deemed to provide a credible reflection of company capabilities. Scores of less than 7 were disregarded and scores of 7 or more were converted to counts to produce the analysis. Results suggest that each company scored highly against two capability areas on average. ↩ Termed ‘Ethics, Trust & Fairness’ in the 2022 study ↩ 49% (n=135), weighted average = 40% ↩ Weighted survey proportions of 7%, 6%, 6% and 5% respectively. London = 3%. ↩ Mindguard is a spinout from the University of Lancaster. It has changed its registered office address to London since data was collected. ↩ Where 51% of all survey respondents indicated that they exported. ↩ A UK Trade Info trader search for each of the top 50 dedicated AI companies (by revenue) returned trade data for 12 companies. ↩ Figure reflects the increase in instance of exporting i.e., a count of each time a company exports items under specified commodity codes in any given month. HS2 commodity code descriptions include: Electrical machinery and equipment and parts thereof; sound recorders and reproducers, television image and sound recorders and reproducers, and parts and accessories of such articles; Miscellaneous chemical products; Nuclear reactors, boilers, machinery and mechanical appliances; parts thereof; Optical, photographic, cinematographic, measuring, checking, precision, medical or surgical instruments and apparatus; parts and accessories thereof; Organic chemicals; Pharmaceutical products. Publicly accessible trade data does not allow for analysis of trade quantities or values by trader given commercial sensitivities. ↩ Survey questions in 2022 and 2023 focussed intentionally on export activity and did not include similar import-related questions. As such, equivalent analysis of company perspectives on importing cannot be produced. ↩ Note: AI revenue for diversified companies is estimated based on the proportion of AI-related activity within the companies. These proportions are based on survey data and AI employment estimates. ↩ Estimates assume that 100% of employment within dedicated AI companies is AI-related and therefore included. Estimates of AI-related employment within diversified AI companies are calculated using a combination of web-intelligence and survey responses. ↩ Employment rounded to nearest 100 and GVA rounded to nearest million – totals may not sum. ↩ 235 companies within the 2023 dataset reported full accounts including figures for operating profit, remuneration, amortization and depreciation. This data was used together with survey data to produce estimates of AI related revenue for every company in the 2023 dataset. ↩ Beauhurst algorithms collect information from Companies House, business websites and news articles. Data is also provided via data partnerships with granting bodies, investors, advisors and universities. Data is manually verified by Beauhurst staff members. ↩ Where the value of a business at a time of investment is below the value of that same business during a previous funding round. ↩ Note: percentages do not sum to 100% because proportions for ‘Dead’ and ‘Zombie’ companies are not shown. ↩ https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership ↩ CMA AI Strategic Update (2024) ↩ https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html ↩ Revenue shares were used to calculate HHI figures for dedicated, diversified and total AI market segments (n=365, 552 and 252 respectively). HHI figures of less than 1,500 are indicative of a competitive market. ↩ https://www.forbes.com/sites/qai/2023/01/27/microsoft-confirms-its-10-billion-investment-into-chatgpt-changing-how-microsoft-competes-with-google-apple-and-other-tech-giants/ ↩ https://www.forbes.com/sites/qai/2023/10/31/google-invests-in-anthropic-for-2-billion-as-ai-race-heats-up/ ↩ https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Fourth-Quarter-and-Full-Year-2023-Results-Initiates-Quarterly-Dividend/default.aspx ↩ https://epochai.org/ ↩ X.ai is not shown in Figure 6.4 because while the company does have a UK office it is not yet registered in the UK. ↩ X.ai (7), Anthropic (40), OpenAI (77), Helsing (89), ElevenLabs (115) ↩ Boost for UK AI as Microsoft unveils £2.5 billion investment ↩ https://c3.ai/c3-ai-relocates-emea-headquarters-to-central-london/ ↩ https://marathon.vc/blog/lambda-automata-raises-eur6-million-to-defend-western-democracies ↩'), Document(metadata={'uuid': UUID('800d2310-9697-4019-ad77-73c5de6b7280'), 'index': 2, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/national-ai-strategy', 'token_count': 25566}, page_content='Artificial Intelligence (AI) is the fastest growing deep technology in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. Our ten-year plan to make Britain a global AI superpower Over the next ten years, the impact of AI on businesses across the UK and the wider world will be profound - and UK universities and startups are already leading the world in building the tools for the new economy. New discoveries and methods for harnessing the capacity of machines to learn, aid and assist us in new ways emerge every day from our universities and businesses. AI gives us new opportunities to grow and transform businesses of all sizes, and capture the benefits of innovation right across the UK. As we build back better from the challenges of the global pandemic, and prepare for new challenges ahead, we are presented with the opportunity to supercharge our already admirable starting position on AI and to make these technologies central to our development as a global science and innovation superpower. With the help of our thriving AI ecosystem and world leading R&D system, this National AI Strategy will translate the tremendous potential of AI into better growth, prosperity and social benefits for the UK, and to lead the charge in applying AI to the greatest challenges of the 21st Century. The Rt Hon Kwasi Kwarteng MP Secretary of State for Business, Energy and Industrial Strategy This is the age of artificial intelligence. Whether we know it or not, we all interact with AI every day - whether it’s in our social media feeds and smart speakers, or on our online banking. AI, and the data that fuels our algorithms, help protect us from fraud and diagnose serious illness. And this technology is evolving every day. We’ve got to make sure we keep up with the pace of change. The UK is already a world leader in AI, as the home of trailblazing pioneers like Alan Turing and Ada Lovelace and with our strong history of research excellence. This Strategy outlines our vision for how the UK can maintain and build on its position as other countries also race to deliver their own economic and technological transformations. The challenge now for the UK is to fully unlock the power of AI and data-driven technologies, to build on our early leadership and legacy, and to look forward to the opportunities of this coming decade. This National AI Strategy will signal to the world our intention to build the most pro-innovation regulatory environment in the world; to drive prosperity across the UK and ensure everyone can benefit from AI; and to apply AI to help solve global challenges like climate change. AI will be central to how we drive growth and enrich lives, and the vision set out in our strategy will help us achieve both of those vital goals. Nadine Dorries MP Secretary of State for Digital, Culture, Media and Sport Executive summary Artificial Intelligence (AI) is the fastest growing deep technology[footnote 1] in the world, with huge potential to rewrite the rules of entire industries, drive substantial economic growth and transform all areas of life. The UK is a global superpower in AI and is well placed to lead the world over the next decade as a genuine research and innovation powerhouse, a hive of global talent and a progressive regulatory and business environment. Many of the UK’s successes in AI were supported by the 2017 Industrial Strategy, which set out the government’s vision to make the UK a global centre for AI innovation. In April 2018, the government and the UK’s AI ecosystem agreed a near £1 billion AI Sector Deal to boost the UK’s global position as a leader in developing AI technologies. This new National AI Strategy builds on the UK’s strengths but also represents the start of a step-change for AI in the UK, recognising the power of AI to increase resilience, productivity, growth and innovation across the private and public sectors. This is how we will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. The UK’s National AI Strategy therefore aims to: Invest and plan for the long-term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. Summary of key actions Investing in the long-term needs of the AI ecosystem Ensuring AI benefits all sectors and regions Governing AI effectively Short term (next 3 months): • Publish a framework for government’s role in enabling better data availability in the wider economy • Consult on the role and options for a National Cyber-Physical Infrastructure Framework • Support the development of AI, data science and digital skills through the Department for Education’s Skills Bootcamps • Begin engagement on the Draft National Strategy for AI-driven technologies in Health and Social Care, through the NHS AI Lab • Publish the Defence AI Strategy, through the Ministry of Defence • Launch a consultation on copyright and patents for AI through the IPO • Publish the CDEI assurance roadmap • Determine the role of data protection in wider AI governance following the Data: A new direction consultation • Publish details of the approaches the Ministry of Defence will use when adopting and using AI • Develop an all-of-government approach to international AI activity Medium term (next 6-12 months): • Publish research into what skills are needed to enable employees to use AI in a business setting and identify how national skills provision can meet those needs • Evaluate the private funding needs and challenges of AI scaleups • Support the National Centre for Computing Education to ensure AI programmes for schools are accessible • Support a broader range of people to enter AI-related jobs by ensuring career pathways highlight opportunities to work with or develop AI • Implement the US UK Declaration on Cooperation in AI R&D • Publish a review into the UK’s compute capacity needs to support AI innovation, commercialisation and deployment • Roll out new visa regimes to attract the world’s best AI talent to the UK • Publish research into opportunities to encourage diffusion of AI across the economy • Consider how Innovation Missions include AI capabilities, such as in energy • Extend UK aid to support local innovation in developing countries • Build an open repository of AI challenges with real-world applications • Publish White Paper on a pro-innovation national position on governing and regulating AI • Complete an in-depth analysis on algorithmic transparency, with a view to develop a cross-government standard • Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally • Establish medium and long term horizon scanning functions to increase government’s awareness of AI safety Long term (next 12 months and beyond): • Undertake a review of our international and domestic approach to semiconductor supply chains • Consider what open and machine-readable government datasets can be published for AI models • Launch a new National AI Research and Innovation Programme that will align funding programmes across UKRI and support the wider ecosystem • Back diversity in AI by continuing existing interventions across top talent, PhDs, AI and Data Science Conversion Courses and Industrial Funded Masters • Monitor and use National Security and Investment Act to protect national security while keeping the UK open for business • Include trade deal provisions in emerging technologies, including AI • Launch joint Office for AI / UKRI programme to stimulate the development and adoption of AI technologies in high potential, lower-AI-maturity sectors • Continue supporting the development of capabilities around trustworthiness, adoptability, and transparency of AI technologies through the National AI Research and Innovation Programme • Join up across government to identify where using AI can provide a catalytic contribution to strategic challenges • Explore with stakeholders the development of an AI technical standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape • Work with global partners on shared R&D challenges, leveraging Overseas Development Assistance to put AI at the heart of partnerships worldwide • Work with The Alan Turing Institute to update guidance on AI ethics and safety in the public sector • Work with national security, defence, and leading researchers to understand what public sector actions can safely advance AI and mitigate catastrophic risks Introduction Artificial Intelligence technologies (AI) offer the potential to transform the UK’s economic landscape and improve people’s lives across the country, transforming industries and delivering first-class public services. AI may be one of the most important innovations in human history, and the government believes it is critical to both our economic and national security that the UK prepares for the opportunities AI brings, and that the country is at the forefront of solving the complex challenges posed by an increased use of AI. This country has a long and exceptional history in AI – from Alan Turing’s early work through to DeepMind’s recent pioneering discoveries. In terms of AI startups and scaleups, private capital invested and conference papers submitted, the UK sits in the top tier of AI nations globally. The UK ranked third in the world for private investment into AI companies in 2020, behind only the USA and China. The National AI Strategy builds on the UK’s current strengths and represents the start of a step-change for AI in the UK, recognising that maximising the potential of AI will increase resilience, productivity, growth and innovation across the private and public sectors. Building on our strengths in AI will take a whole-of-society effort that will span the next decade. This is a top-level economic, security, health and wellbeing priority. The UK government sees being competitive in AI as vital to our national ambitions on regional prosperity and for shared global challenges such as net zero, health resilience and environmental sustainability. AI capability is therefore vital for the UK’s international influence as a global science superpower. The National AI Strategy for the United Kingdom will prepare the UK for the next ten years, and is built on three assumptions about the coming decade: The key drivers of progress, discovery and strategic advantage in AI are access to people, data, compute and finance – all of which face huge global competition; AI will become mainstream in much of the economy and action will be required to ensure every sector and region of the UK benefit from this transition; Our governance and regulatory regimes will need to keep pace with the fast-changing demands of AI, maximising growth and competition, driving UK excellence in innovation, and protecting the safety, security, choices and rights of our citizens. This document sets out the UK’s strategic intent at a level intended to guide action over the next ten years, recognising that AI is a fast moving and dynamic area. Detailed and measurable plans for the execution of the first stage of this strategy will be published later this year. The UK’s National Artificial Intelligence Strategy will: Invest and plan for the long term needs of the AI ecosystem to continue our leadership as a science and AI superpower; Support the transition to an AI-enabled economy, capturing the benefits of innovation in the UK, and ensuring AI benefits all sectors and regions; Ensure the UK gets the national and international governance of AI technologies right to encourage innovation, investment, and protect the public and our fundamental values. This will be best achieved through broad public trust and support, and by the involvement of the diverse talents and views of society. 10-Year Vision Over the next decade, as transformative technologies continue to reshape our economy and society, the world is likely to see a shift in the nature and distribution of global power. We are seeing how, in the case of AI, rapid technological change seeks to rebalance the science and technology dominance of existing superpowers like the US and China, and wider transnational challenges demand greater collective action in the face of continued global security and prosperity. With this in mind, the UK has an opportunity over the next ten years to position itself as the best place to live and work with AI; with clear rules, applied ethical principles and a pro-innovation regulatory environment. With the right ingredients in place, we will be both a genuine innovation powerhouse and the most supportive business environment in the world, where we cooperate on using AI for good, advocate for international standards that reflect our values, and defend against the malign use of AI. Whether it is making the decision to study AI, work at the cutting edge of research or spin up an AI business, our investments in skills, data and infrastructure will make it easier than ever to succeed. Our world-leading R&D system will step up its support of innovators at every step of their journey, from deep research to building and shipping products. If you are a talented AI researcher from abroad, coming to the UK will be easier than ever through the array of visa routes which are available. If you run a business – whether it is a startup, SME or a large corporate – the government wants you to have access to the people, knowledge and infrastructure you need to get your business ahead of the transformational change AI will bring, making the UK a globally-competitive, AI-first economy which benefits every region and sector. By leading with our democratic values, the UK will work with partners around the world to make sure international agreements embed our ethical values, making clear that progress in AI must be achieved responsibly, according to democratic norms and the rule of law. And by increasing the number and diversity of people working with and developing AI, by putting clear rules of the road in place and by investing across the entire country, we will ensure the real-world benefits of AI are felt by every member of society. Whether that is more accurate AI-enabled diagnostics in the NHS, the promise of driverless cars to make our roads safer and smarter, or the hundreds of unforeseen benefits that AI could bring to improve everyday life. The goals of this Strategy are that the UK: Experiences a significant growth in both the number and type of discoveries that happen in the UK, and are commercialised and exploited here; Benefits from the highest amount of economic and productivity growth due to AI; and Establishes the most trusted and pro-innovation system for AI governance in the world. This vision can be achieved if we build on three pillars fundamental to the development of AI: Investing in the needs of the ecosystem to see more people working with AI, more access to data and compute resources to train and deliver AI systems, and access to finance and customers to grow sectors; Supporting the diffusion of AI across the whole economy to ensure all regions, nations, businesses and sectors can benefit from AI; and Developing a pro-innovation regulatory and governance framework that protects the public. The National AI Strategy does not stand alone. It purposefully supports and amplifies the other, interconnected work of government including: The Plan for Growth and recent Innovation Strategy, which recognise the need to develop a diverse and inclusive pipeline of AI professionals with the capacity to supercharge innovation; The Integrated Review , to find new paths for UK excellence in AI to deliver prosperity and security at home and abroad, and shape the open international order of the future; The National Data Strategy, published in September 2020, sets out our vision to harness the power of responsible data use to boost productivity, create new businesses and jobs, improve public services, support a fairer society, and drive scientific discovery, positioning the UK as the forerunner of the next wave of innovation; The Plan for Digital Regulation , which sets out our pro-innovation approach to regulating digital technologies in a way that drives prosperity and builds trust in their use; The upcoming National Cyber Strategy to continue the drive for securing emerging technologies, including building security into the development of AI; The forthcoming Digital Strategy, which will build on DCMS’s Ten Tech Priorities to further set out the government’s ambitions in the digital sector; A new Defence AI centre as a keystone piece of the modernisation of Defence; The National Security Technology Innovation exchange (NSTIx), a data science & AI co-creation space that brings together National Security stakeholders, industry and academic partners to build better national security capabilities; and The upcoming National Resilience Strategy, which will in part focus on how the UK will stay on top of technological threats. The government’s AI Council has played a central role in gathering evidence to inform the development of this strategy, including through its roadmap published at the beginning of the year, which represents a valuable set of recommendations reflecting much of the wider AI community in the UK. The wider ecosystem also fed in through a survey run by the AI Council in collaboration with The Alan Turing Institute. The government remains grateful to the AI Council for its continued leadership of the AI ecosystem, and would like to thank those from across the United Kingdom who shared their views during the course of developing this strategy. The AI Council The AI Council was established in 2019 to provide expert advice to the government and high-level leadership of the AI ecosystem. The AI Council demonstrates a key commitment made in the AI Sector Deal, bringing together respected leaders in their fields from across industry, academia and the public sector. Members meet quarterly to advise the Office for AI and broader government on its current priorities, opportunities and challenges for AI policy. In January 2021, the AI Council published its ‘AI Roadmap’ providing 16 recommendations to the government on the strategic direction for AI. Its central call was for the government to develop a National AI Strategy, building on the success of investments made through the AI Sector Deal whilst remaining adaptable to future technological disruption. Since then, the Council has led a programme of engagement with the wider AI community to inform the development of the National AI Strategy. To guide the delivery and implementation of this strategy the government will renew and strengthen the role of the AI Council, ensuring it continues to provide expert advice to government and high-level leadership of the AI ecosystem. AI presents unique opportunities and challenges ‘Artificial Intelligence’ as a term can mean a lot of things, and the government recognises that no single definition is going to be suitable for every scenario. In general, the following definition is sufficient for our purposes: “Machines that perform tasks normally performed by human intelligence, especially when the machines learn from data how to do those tasks.” The UK government has also set out a legal definition of AI in the National Security and Investment Act.[footnote 2] Much like James Watt’s 1776 steam engine, AI is a ‘general purpose technology’ (or more accurately, technologies) that have many possible applications, and we expect them to have a transformational impact on the whole economy. Already, AI is used in everyday contexts like email spam filtering, media recommendation systems, navigation apps, payment transaction validation and verification, and many more. AI technologies will impact the whole economy, all of society and us as individuals. Many of the themes in AI policy are similar to tech and digital policy more widely: the commercialisation journeys; the reliance on internationally mobile talent; the importance of data; and consolidation of economic functions onto platforms. However there are some key examples of differences derived from the above definition which differentiate AI and require a unique policy response from the government. In regulatory matters, a system’s autonomy raises unique questions around liability, assurance, and fairness as well as risk and safety - and even ownership of creative content[footnote 3] - in a way which is distinct to AI, and these questions increase with the relative complexity of the algorithm. There are also questions of transparency and bias which arise from decisions made by AI systems. There are often greater infrastructure requirements for AI services than in cloud/Software as a Service systems. In building and deploying some models, access to expensive high performance computing and/or large data sets is needed. Multiple skills are required to develop, validate and deploy AI systems, and the commercialisation and product journey can be longer and more expensive because so much starts with fundamental R&D. Reflecting and protecting society AI makes predictions and decisions, and fulfils tasks normally undertaken by humans. While diverse opinions, skills, backgrounds and experience are hugely important in designing any service – digital or otherwise – it is particularly important in AI because of the executive function of the systems. As AI increasingly becomes an enabler for transforming the economy and our personal lives, there are at least three reasons we should care about diversity in our AI ecosystem: Moral: As AI becomes an organising principle which creates new opportunities and changes the shape of industries and the dynamics of competition across the economy, there is a moral imperative to ensure people from all backgrounds and parts of the UK are able to participate and thrive in this new AI economy. Social: AI systems make decisions based on the data they have been trained on. If that data – or the system it is embedded in – is not representative, it risks perpetuating or even cementing new forms of bias in society. It is therefore important that people from diverse backgrounds are included in the development and deployment of AI systems. Economic: There are big economic benefits to a diverse AI ecosystem. These include increasing the UK’s human capital from a diverse labour supply, creating a wider range of AI services that stimulate demand, and ensuring the best talent is discovered from the most diverse talent pool. The longer term Making specific predictions about the future impact of a technology – as opposed to the needs of those developing and using it today – has a long history in AI. Since the 1950s various hype cycles have given way to so-called ‘AI winters’ as the promises made have perpetually remained ‘about 20 years away’. While the emergence of Artificial General Intelligence (AGI) may seem like a science fiction concept, concern about AI safety and non-human-aligned systems[footnote 4] is by no means restricted to the fringes of the field.[footnote 5] The government’s first focus is on the economic and social outcomes of autonomous and adaptive systems that exist today. However, we take the firm stance that it is critical to watch the evolution of the technology, to take seriously the possibility of AGI and ‘more general AI’, and to actively direct the technology in a peaceful, human-aligned direction.[footnote 6] The emergence of full AGI would have a transformational impact on almost every aspect of life, but there are many challenges which could be presented by AI which could emerge much sooner than this. As a general purpose technology AI will have economic and social impacts comparable to the combustion engine, the car, the computer and the internet. As each of these has disrupted and changed the shape of the world we live in - so too could AI, long before any system ‘wakes up.’ The choices that are made in the here and now to develop AI will shape the future of humanity and the course of international affairs. For example, whether AI is used to enhance peace, or a cause for war; whether AI is used to strengthen our democracies, or embolden authoritarian regimes. As such we have a responsibility to not only look at the extreme risks that could be made real with AGI, but also to consider the dual-use threats we are already faced with today. From Sector Deal to AI Strategy The UK is an AI superpower, with particular strengths in research, investment and innovation. The UK’s academic and commercial institutions are well known for conducting world-leading AI research, and the UK ranks 3rd in the world for AI publication citations per capita.[footnote 7] This research strength was most recently demonstrated in November 2020 when DeepMind, a UK-based AI company, used AlphaFold to find a solution to a 50-year-old grand challenge in biology.[footnote 8] The UK has the 3rd highest number of AI companies in the world after the US and China. Alongside DeepMind, the UK is home to Graphcore, a Bristol-based machine learning semiconductor company; Darktrace, a world-leading AI company for cybersecurity; and BenevolentAI, a company changing the way we treat disease. The UK also attracts some of the best AI talent from around the world[footnote 9] - the UK was the second most likely global destination for mobile AI researchers after the USA. AlphaFold and AlphaFold 2 In November 2020, London-based DeepMind announced that they had solved one of the longest running modern challenges in biology: predicting how proteins - the building blocks of life which underpin every biological process in every living thing - take shape, or ‘fold’. Improvements in the median accuracy of predictions in the free modelling category for the best team in each CASP, measured as best-of-5 GDT. Source: DeepMind AlphaFold, DeepMind’s deep learning AI system, broke all previous accuracy levels dating back over 50 years, and in July 2021 the organisation open sourced the code for AlphaFold together with over 350,000 protein structure predictions, including the entire human proteome, via the AlphaFold database in partnership with EMBL-EBI. DeepMind’s decision to share this knowledge openly with the world, demonstrates both the opportunity that AI presents, as well as what this strategy seeks to support: bleeding-edge research happening in the UK and with partners around the world, solving big global challenges. AlphaFold opens up a multitude of new avenues in research – helping to further our understanding of biology and the nature of the world around us. It also has a multitude of potential real-world applications, such as deepening our understanding of how bacteria and viruses attack the body in order to develop more effective prevention and treatment, or support the identification of proteins and enzymes that can break down industrial or plastic waste. The government has invested more than £2.3 billion into Artificial Intelligence across a range of initiatives since 2014.[footnote 10] This portfolio of investment includes, but is not limited to: £250 million to develop the NHS AI Lab at NHSX to accelerate the safe adoption of Artificial Intelligence in health and care; £250 million into Connected and Autonomous Mobility (CAM) technology through the Centre for Connected and Autonomous Vehicles (CCAV) to develop the future of mobility in the UK; 16 new AI Centres for Doctoral Training at universities across the country, backed by up to £100 million and delivering 1,000 new PhDs over five years; A new industry-funded AI Masters programme and up to 2,500 places for AI and data science conversion courses. This includes up to 1,000 government-funded scholarships; Investment into The Alan Turing Institute and over £46 million to support the Turing AI Fellowships to develop the next generation of top AI talent; Over £372 million of investment into UK AI companies through the British Business Bank for the growing AI sector; £172 million of investment through the UKRI into the Hartree National Centre for Digital Innovation, leveraging an additional £38 million of private investment into High Performance Computing. Further investments have been made into the Tech Nation Applied AI programme – now in its third iteration; establishing the Office for National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK. As part of the AI Sector Deal, the government established the AI Council to bring together respected leaders to strengthen the conversation between academia, industry, and the public sector. The Office for Artificial Intelligence was created as a new team within government to take responsibility for overarching AI policy across government and to be a focal point for the AI ecosystem through its secretariat of the AI Council. The Centre for Data Ethics and Innovation (CDEI) was established as a government expert body focused on the trustworthy use of data and AI in the public and private sector. This strategy builds on the recent history of government support for AI and considers the next key steps to harness its potential in the UK for the coming decade. In doing so, the National AI Strategy leads on from the ambitions outlined in the government’s Innovation Strategy to enable UK businesses and innovators to respond to economic opportunities and real-world problems through our national innovation prowess. AI was identified in the Innovation Strategy as one of the seven technology families where the UK has a globally competitive R&D and industrial strength[footnote 11] and has been widely cited as a set of technologies in which the UK must maintain a leading edge to guarantee our continued security and prosperity in an intensifying geopolitical landscape. Pillar 1: Investing in the long-term needs of the AI ecosystem Investing in and planning for the long term needs of the AI ecosystem to remain a science and AI superpower To maintain the UK’s position amongst the global AI superpowers and ensure the UK continues to lead in the research, development, commercialisation and deployment of AI, we need to invest in, plan for, secure and unlock the critical inputs that underpin AI innovation. Government’s aim is to greatly increase the type, frequency and scale of AI discoveries which are developed and exploited in the UK. This will be achieved by: Making sure the UK’s research, development and innovation system continues to be world leading, providing the support to allow researchers and entrepreneurs to forge new frontiers in AI; Guaranteeing that the UK has access to a diverse range of people with the skills needed to develop the AI of the future and to deploy it to meet the demands of the new economy; Ensuring innovators have access to the data and computing resources necessary to develop and deliver the systems that will drive the UK economy for the next decade; Supporting growth for AI through a pro-innovation business environment and capital market, and attracting the best people and firms to set up shop in the UK; Ensuring UK AI developers can access markets around the world. Increasing diversity and closing the skills gap through postgraduate conversion courses in data science and artificial Autumn 2020 student admissions data shows a diverse range of students have enrolled on AI and data science postgraduate conversion courses funded by the Office for Students. The data shows that 40% of the total students are women, one quarter are Black students and 15% are students that are disabled. Source: Office for Students As a result of the growing skills gap in AI and data science, 2,500 new Masters conversion courses in AI and data science are now being delivered across universities in England. The conversion course programme included up to 1,000 scholarships to increase the number of people from underrepresented groups and to encourage graduates from diverse backgrounds to consider a future in AI and Data Science. In the first year over 1,200 students enrolled, with 22% awarded scholarships. Over 40% of the total students are women, one quarter are black students and 15% of students are disabled. 70% of the total students are studying on courses based outside of London and the South East. These conversion courses are providing the opportunity to develop new digital skills or retrain to help find new employment in the UK’s cutting-edge AI and data science sectors, ensuring that industry and the public sector can access the greatest supply of talent across the whole country. Skills and talent Continuing to develop, attract and train the best people to build and use AI is at the core of maintaining the UK’s world-leading position. By inspiring all with the possibilities AI presents, the UK will continue to develop the brightest, most diverse workforce. Building a tech-savvy nation by supporting skills for the future is one of the government’s ten tech priorities. The gap between demand and supply of AI skills remains significant and growing,[footnote 12],[footnote 13] despite a number of new AI skills initiatives since the 2018 AI Sector Deal. In order to meet demand, the UK needs a larger workforce with AI expertise. Last year there was a 16% increase for online AI and Data Science job vacancies and research found that 69% of vacancies were hard to fill.[footnote 14] Data from an ecosystem survey conducted by the AI Council and The Alan Turing Institute showed that 81% of respondents agreed there were significant barriers in recruiting and retaining top AI talent in their domain within the UK. Research into the AI Labour Market showed that technical AI skill gaps are a concern for many firms, with 35% of firms revealing that a lack of technical AI skills from existing employees had prevented them from meeting their business goals, and 49% saying that a lack of required AI skills from job applicants also affected their business outcomes.[footnote 15] To support the adoption of AI we need to ensure that non-technical employees understand the opportunities, limitations and ethics of using AI in a business setting, rather than these being the exclusive domain of technical practitioners. Understanding the UK AI Labour Market research In 2021, the Office for AI published research to investigate Artificial Intelligence and Data science skills in the UK labour market in 2020. Some key findings from the research: Half of surveyed firms’ business plans had been impacted by a lack of suitable candidates with the appropriate AI knowledge and skills. Two thirds of firms (67%) expected that the demand for AI skills in their organisation was likely to increase in the next 12 months. Diversity in the AI sector was generally low. Over half of firms (53%) said none of their AI employees were female, and 40% said none were from ethnic minority backgrounds. There were over 110,000 UK job vacancies in 2020 for AI and Data Science roles. The findings from this research will help the Office for AI address the AI skills challenge and ensure UK businesses can take advantage of the potential of AI and Data Science. We need to inspire a diverse set of people across the UK to ensure the AI that is built and used in the UK reflects the needs and make-up of society. To close the skills gap, the government will focus on three areas to attract and train the best people: those who build AI, those who use AI, and those we want to be inspired by AI. Build: Train and attract the brightest and best people at developing AI To meet the demand seen in industry and academia, the government will continue supporting existing interventions across top talent, PhDs and Masters levels. This includes Turing Fellowships, Centres for Doctoral Training and Postgraduate Industrial-Funded Masters and AI Conversion Courses. Government will seek to build upon the £46 million Turing AI Fellowships investment to attract, recruit, and retain a substantial cohort of leading researchers and innovators at all career stages. Our approach will enable Fellows to work flexibly between academia and other sectors, creating an environment for them to discover and develop cutting edge AI technologies and drive the use of AI to address societal, economic and environmental challenges in the UK. We note that recently, research breakthroughs in the field of AI have been disproportionately driven by a small number of luminary talents and their trainees. In line with the Innovation Strategy, the government affirms our commitment to empowering distinguished academics. Research[footnote 16] and industry engagement has demonstrated the need for graduates with business experience, indicating a need to continue supporting industry/academic partnerships to ensure graduates leave education with business-ready experience. Our particular focus will be on software engineers, data scientists, data engineers, machine learning engineers and scientists, product managers, and related roles. We recognise that global AI talent is scarce, and the topic of fierce competition internationally. As announced in the Innovation Strategy, the government is revitalising and introducing new visa routes that encourage innovators and entrepreneurs to the UK. Support for diverse and inclusive researchers and innovators across sectors, and new environments for collaboratively developing AI, will be key to ensuring the UK’s success in developing AI and investing in the long term health of our AI ecosystem. Attracting the best AI talent from around the world The UK is already the top global destination for AI graduates in the United States and we punch above our weight globally in attracting talent. The UK nearly leads the world in its proportion of top-skilled AI researchers. Government wants to take this to the next level and make the UK the global home for AI researchers, entrepreneurs, businesses and investors. As well as ensuring the UK produces the next generation of AI talent we need, the government is broadening the routes that talented AI researchers and individuals can work in the UK, through the recently announced Innovation Strategy. The Global Talent visa route is open to those who are leaders or potential leaders in AI - and those who have won prestigious global prizes automatically qualify. Government is currently looking at how to broaden this list of prizes. A new High Potential Individual route will make it as simple as possible for internationally mobile individuals who demonstrate high potential to come to the UK. Eligibility will be open to applicants who have graduated from a top global university, with no job offer requirement. This gives individuals the flexibility to work, switch jobs or employers – keeping pace with the UK’s fast-moving AI sector. A new scale-up route will support UK scale-ups by allowing talented individuals with a high-skilled job offer from a qualifying scale-up at the required salary level to come to the UK. Scaleups will be able to apply through a fast-track verification process to use the route, so long as they can demonstrate an annual average revenue or employment growth rate over a three-year period greater than 20%, and a minimum of 10 employees at the start of the three-year period. A revitalised Innovator route will allow talented innovators and entrepreneurs from overseas to start and operate a business in the UK that is venture-backed or harnesses innovative technologies, creating jobs for UK workers and boosting growth. We have reviewed the Innovator route to make it even more open to: Simplifying and streamlining the business eligibility criteria. Applicants will need to demonstrate that their business venture has a high potential to grow and add value to the UK and is innovative. Fast-tracking applications. The UK government is exploring a fast-track, lighter touch endorsement process for applicants whose business ideas are particularly advanced to match the best-in-class international offers. Applicants that have been accepted on to the government’s Global Entrepreneur Programme will be automatically eligible. Building flexibility. Applicants will no longer be required to have at least £50,000 in investment funds to apply for an Innovator visa, provided that the endorsing body is satisfied the applicant has sufficient funds to grow their business. We will also remove the restriction on doing work outside of the applicant’s primary business. The new Global Business Mobility visa will also allow overseas AI businesses greater flexibility in transferring workers to the UK, in order to establish and expand their business here. These reforms will sit alongside the UK government’s Global Entrepreneur Programme (GEP) which has a track record of success in attracting high skilled migrant tech founders with IP-rich businesses to the UK. The programme will focus on attracting more international talent to support the growth of technology clusters including through working with academic institutions from overseas to access innovative spinouts and overseas talent. Through the Graduate Route we are also granting international students with UK degrees 2 years, 3 years for those with PhDs, to work in the UK post-graduation. This will help ensure that we can attract the best and brightest from across the world while also giving students time to work on the most challenging AI problems. These are all in addition to our existing skills visa schemes for those with UK job offers. Use: Empower employers and employees to upskill and understand the opportunities for using AI in a business setting The AI Council ecosystem survey found that only 18% agreed there was sufficient provision of training and development in AI skills available to the current UK workforce. As the possibilities to develop and use AI grow, so will people’s need to understand and apply AI in their jobs. This will range from people working adjacent to the technical aspects such as product managers and compliance, through to those who are applying AI within their business, such as in advertising and HR. Below degree level, there is a need to clearly articulate the skills employers and employees need to use AI effectively in the workplace. For example, industries have expressed their willingness to fund employees to undertake training but have not found training that suits their needs: including training that is business-focused, modular and flexible. Skills for Jobs White Paper The Skills for Jobs: Lifelong Learning for Opportunity and Growth White Paper was published in January 2021 and is focused on giving people the skills they need, in a way that suits them, so they can get great jobs in sectors the economy needs and boost the country’s productivity. These reforms aim to ensure that people can access training and learning flexibly throughout their lives and that they are well-informed about what is on offer, including opportunities in valuable growth sectors. This will also involve reconfiguring the skills system to give employers a leading role in delivering the reforms and influencing the system to generate the skills they need to grow. To more effectively use AI in a business setting, employees, including those who would not have traditionally engaged with AI, will require a clear articulation of the different skills required, so they can identify what training already exists and understand if there is still a gap. Using the Skills Value Chain approach piloted by the Department for Education,[footnote 17] the government will help industry and providers to identify what skills are needed. Lessons learned from this pilot will support this work to help businesses adopt the skills needed to get the best from AI. The Office for AI will then work with the Department for Education to explore how these needs can be met and mainstreamed through national skills provision. The government will also support people to develop skills in AI, machine learning, data science and digital through the Department for Education’s Skills Bootcamps. The Bootcamps are free, flexible courses of up to 16 weeks, giving adults aged 19 and over the opportunity to build up in-demand, sector-specific skills and fast-track to an interview with a local employer; improving their job prospects and supporting the economy. Inspire: Support all to be excited by the possibilities of AI The AI Council’s Roadmap makes clear that inspiring those who are not currently using AI, and allowing children to explore and be amazed by the potential of AI, will be integral to ensuring we continue to have a growing and diverse AI-literate workforce. Through supporting the National Centre for Computing Education(NCCE) the government will continue to ensure programmes that engage children with AI concepts are accessible and reach the widest demographic. The Office for AI will also work with the Department for Education to ensure career pathways for those working with or developing AI are clearly articulated on career guidance platforms, including the National Careers Service, demonstrating role models and opportunities to those exploring AI. This will support a broader range of people to consider careers in AI. The government will ensure that leaders within the National AI Research and Innovation Programme will play a key role in engaging with the public and inspiring the leaders of the future. Research, development and innovation Our vision is that the UK builds on our excellence in research and innovation in the next generation of AI technologies. The UK has been a leader in AI research since it developed as a field, thanks to our strengths in computational and mathematical sciences.[footnote 18] The UK’s AI base has been built upon this foundation,[footnote 19] and the recently announced Advanced Research and Invention Agency (ARIA) will complement our efforts to cement our status as a global science superpower. The UK also has globally recognised institutes such as The Alan Turing Institute and the high-performing universities which are core to research in AI.[footnote 20] Currently, AI research undertaken in the UK is world class, and investments in AI R&D contribute to the Government’s target of increasing overall public and private sector R&D expenditure to 2.4% of GDP by 2027. But generating economic and societal impact through adoption and diffusion of AI technologies is behind where it could be.[footnote 21] There is a real opportunity to build on our existing strengths in fundamental AI research to ensure they translate into productive processes throughout the economy. At the same time, the field of AI is advancing rapidly, with breakthrough innovations being generated by a diverse set of institutions and countries. The past decade has seen the rise of deep learning, compute-intensive models, routine deployment of vision, speech, and language modelling in the real world, the emergence of responsible AI and AI safety, among other advances. These are being developed by new types of research labs in private companies and public institutions around the world. We expect that the next decade will bring equally transformative breakthroughs. Our goal is to make the UK the starting point for a large proportion of them, and to be the fastest at turning them into benefits for all. To do this, UKRI will support the transformation of the UK’s capability in AI by launching a National AI Research and Innovation (R&I) Programme. The programme will shift us from a rich but siloed and discipline-focused national AI landscape to an inclusive, interconnected, collaborative, and interdisciplinary research and innovation ecosystem. It will work across all the Councils of UKRI and will be fully-joined up with business of all sizes and government departments. It will translate fundamental scientific discoveries into real-world AI applications, address some limitations in the ability of current AI to be effectively used in numerous real world contexts, such as tackling complex and undefined problems, and explore using legacy data such as non-digital public records. The National AI Research and Innovation (R&I) Programme has five main aims: Discovering and developing transformative new AI technologies, leading the world in the development of frontier AI and the key technical capabilities to develop responsible and trustworthy AI.The programme will support: foundational research to develop novel next generation AI technologies and approaches which could address current limitations of AI, focusing on low power and sustainable AI, and AI which can work differently with a diverse range of challenging data sets, human-AI interaction, reasoning, and the maths underpinning the theoretical foundations of AI. technical and socio-technical capability development to overcome current limitations around the responsible trustworthy nature of AI. Maximising the creativity and adventure of researchers and innovators, building on UK strengths and developing strategic advantage through a diverse range of AI technologies. The programme will support: specific routes to enable the exploration of high-risk ideas in the development and application of AI; follow-on funding to maximise the impact of the ideas with the most potential. Building new research and innovation capacity to deliver the ideas, technologies, and workforce of the future, recruiting and retaining AI leaders, supporting the development of new collaborative AI ecosystems, and developing collaborative, multidisciplinary, multi-partner teams. The programme will support: the recruitment, retention, training and development of current and future leaders in AI, and flexible working across sectoral and organisational interfaces using tools such as fellowships, and building on the success of the Turing AI Fellowships scheme; enhanced UK capacity in key AI professional skills for research and innovation, such as data scientists and software engineers. Connecting across the UK AI Research and Innovation ecosystem, building on the success of The Alan Turing Institute as the National Centre for AI and Data Science, and building collaborative partnerships nationally and regionally between and across sectors, diverse AI research and innovation stakeholders. The programme will support: the development of a number of nationally distributed AI ecosystems which enable researchers and innovators to collaborate in new environments and integrate basic research through application and innovation. These ecosystems will be networked into a national AI effort with the Alan Turing Institute as its hub, convening and coordinating the national research and innovation programme and enabling business and government departments to access the UK’s AI expertise and skills capability e.g. the catapult network and compute capability. Supporting the UK’s AI Sector and the adoption of AI, connecting research and innovation and supporting AI adoption and innovation in the private sector. The programme will support: challenge-driven AI research and innovation programmes in key UK priorities, such as health and the transition to net zero; collaborative work with the public sector and government organisations to facilitate leading researchers and innovators engaging with the AI transformation of the public sector; innovation activities in the private sector, both in terms of supporting the development of the UK’s burgeoning AI sector and the adoption of AI across sectors. International collaboration on research and innovation As well as better coordination at home, the UK will work with friends and partners around the world on shared challenges in research and development and lead the global conversation on AI. The UK will participate in Horizon Europe, enabling collaboration with other European researchers, and will build a strong and varied network of international science and technology partnerships to support R&I collaboration. By shaping the responsible use of technology, we will put science and technology, including AI, at the heart of our alliances and partnerships worldwide. We will continue to use Official Development Assistance to support R&D partnerships with developing countries. We are also deepening our collaboration with the United States, implementing the US UK Declaration on Cooperation in AI Research and Development. This declaration outlines a shared vision for driving technological breakthroughs in AI between the US and the UK. As we build materially on this partnership, we will seek to enable UK partnership with other key global actors in AI, to grow influential R&I collaborations. Access to data The National Data Strategy sets out the government’s approach to unlocking the power of data. Access to good quality, representative data from which AI can learn is critical to the development and application of robust and effective AI systems. The AI Sector Deal recognised this and since then the government has established evidence on which to make policies to harness the positive economic and social benefit of increased availability of data. This includes the Open Data Institute’s original research into data trusts as a model of data stewardship to realise the value of data for AI. The research established a repeatable model for data trusts which others have begun to apply. Mission 1 of the National Data Strategy seeks to unlock the value of data across the economy, and is a vital enabler for AI. This mission explores how the government can apply six evidenced levers to tackle barriers to data availability. The government will publish a policy framework in Autumn 2021 informed by the outcomes of Mission 1, setting out its role in enabling better data availability in the wider economy. The policy framework includes supporting the activities of intermediaries, including data trusts, and providing stewardship services between those sharing and accessing data. The AI Council and the Ada Lovelace Institute recently explored three legal mechanisms that could help facilitate responsible data stewardship – data trusts, data cooperatives and corporate and contractual mechanisms. The ongoing Data: A new direction consultation asks what role the government should have in enabling and engendering confidence in responsible data intermediary activity. The government is also exploring how privacy enhancing technologies can remove barriers to data sharing by more effectively managing the risks associated with sharing commercially sensitive and personal data. Data foundations and use in AI systems Data foundations refer to various characteristics of data that contribute to its overall condition, whether it is fit for purpose, recorded in standardised formats on modern, future-proof systems and held in a condition that means it is findable, accessible, interoperable and reusable (FAIR). A recent EY study delivered on behalf of DCMS has found that organisations that report higher AI adoption levels also have a higher level of data foundations. The government is considering how to improve data foundations in the private and third sectors. Through the National AI R&I Programme and ambitions to lead best practices in FAIR data, we will grow our capacity in professional AI, software and data skills, and support the development of key new data infrastructure capabilities. Technical professionals such as data engineers have a key role to play in opening up access to the most critical data and compute infrastructures on FAIR data principles, and in accelerating the pathway to using AI technologies to make best use of the UK’s healthy data ecosystem. Data foundations are crucial to the effective use of AI and it is estimated that, on average, 80% of the time spent on an AI project is cleaning, standardising and making the data fit for purpose. Furthermore, when the source data needed to power AI or machine learning is not fit for purpose, it leads to poor or inaccurate results, and to delays in realising the benefits of innovation.[footnote 22] Poor quality datasets can also be un-representative, especially when it comes to minority groups, and this can propagate existing biases and exclusions when they are used for AI. The government is looking to support action to mitigate the effects of quality issues and underrepresentation in AI systems. Subject to the outcomes of the Data: A new direction consultation, the government will more explicitly permit the collection and processing of sensitive and protected characteristics data to monitor and mitigate bias in AI systems. An important outcome for increasing access to data and improving data foundations is in how technology will be better able to use that data. Technological convergence – the tendency for technologies that were originally unrelated to become more closely integrated (or even unified) as they advance – means that AI will increasingly be deployed together with many other technologies of the future, unlocking new technological, economic and social opportunities. For example, AI is a necessary driver of the development of robotics and smart machines, and will be a crucial enabling technology for digital twins. These digital replicas of real-world assets, processes or systems, with a two-way link to sensors in the physical world, will help make sense of and create insights and value from vast quantities of data in increasingly sophisticated ways. And in the future, some types of AI will rely on the step-change in processing power that quantum computing is expected to unlock. Government will consult later this year on the potential value of and options for a UK capability in digital twinning and wider ‘cyber-physical infrastructure.’[footnote 23] This consultation will help identify how common, interoperable digital tools and platforms, as well as physical testing and innovation spaces can be brought together to form a digital and physical shared infrastructure for innovators (e.g. digital twins, test beds and living labs). Supporting and enabling this shared infrastructure will help remove time, cost and risk from the process of bringing innovation to market, enabling accelerated AI development and applications. Public sector data Work is underway within the government to fix its own data foundations as part of Mission 3 of the National Data Strategy, which focuses on transforming the government’s use of data to drive efficiency and improve public services. The Central Digital and Data Office (CDDO) has been created within the Cabinet Office to consolidate the core policy and strategy responsibilities for data foundations, and will work with expert cross-sector partners to improve government’s use and reuse of data to support data-driven innovation across the public sector. The CDDO also leads on the Open Government policy area, a wide-ranging and open engagement programme that entails ongoing work with Civil Society groups and government departments to target new kinds of data highlighted as having ‘high potential impact’ for release as open data. The UK’s ongoing investment in open data will serve to further bolster the use of AI and machine learning within government, the private sector, and the third sector. The application of standards and improvements to the quality of data collected, processed, and ultimately released publicly under the Open Government License will create further value when used by organisations looking to train and optimise AI systems utilising large amounts of information. The Office for National Statistics(ONS) is leading the Integrated Data Programme in collaboration with partners across government, providing real-time evidence, underpinning policy decisions and delivering better outcomes for citizens while maintaining privacy. The 2021 Declaration on Government Reform sets out a focus on strengthening data skills across government including senior leaders. We need to strengthen the way that public authorities can engage with private sector data providers to make better use of data through FAIR data and open standards, including making government data more easily available through application programming interfaces (APIs), and encouraging businesses to offer their data through APIs. Government will continue to publish authoritative open and machine-readable data on which AI models for both public and commercial benefit can depend. The Office for AI will also work with teams across government to consider what valuable datasets government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. Compute The total amount of compute shows two distinct eras of compute usage in training AI systems. A petaflop/s-day consists of performing 10615 neural net operations per second for one day, or a total of about 10620 operations. Starting from ~2012 we see a 3.4-month doubling time for the compute seen in historical results, compared to a ~2-year doubling time (Moore’s Law) before then. Shown on a logarithmic scale. Source: OpenAI Access to computing power is essential to the development and use of AI, and has been a dominant trend in AI breakthroughs of the past decade. The computing power underpinning AI in the UK comes from a range of sources. The government’s recent report on large-scale computing[footnote 24] recognises its importance in AI innovation, but suggests that the UK’s infrastructure is lagging behind other major economies around the world such as the US, China, Japan and Germany. We also recognise the growing compute gap between large-scale enterprises and researchers. Access to compute is both a competitiveness and a security issue. It is also not a one-size-fits-all approach - different AI technologies need different capabilities. Digital Catapult’s Machine Intelligence Garage For more than three years, Digital Catapult’s Machine Intelligence Garage (MI Garage) has helped startups accelerate the development of their industry-leading AI solutions by addressing their need for computational power. Some AI solutions being developed require greater computing capacity in the form of High Performance Computers (HPC) for unusually large workloads (such as weather simulation, protein folding and simulation of molecular interactions) or access to AI focussed hardware like Graphcore’s Intelligence Processing Unit (IPU), a new processor specifically designed for developing AI. MI Garage provides a channel through which startups can connect with HPC centres and access specialised hardware. HPC partners include the Hartree National Centre for Digital Innovation, the Edinburgh Parallel Computing Centre, and the Earlham Institute. MI Garage has also worked with NVIDIA, Graphcore and LightOn to facilitate access to special trials to lower the barrier to entry to AI specialised hardware. Sustained public and private investment in a range of facilities from cloud, laboratory and academic department scale, through to supercomputing, will be necessary to ensure that accessing computing power is not a barrier to future AI research and innovation, commercialisation and deployment of AI. In June 2021, the government announced joint funding with IBM for the Hartree National Centre for Digital Innovation to stimulate high performance computing enabled innovation in industry and make cutting-edge technologies like AI more accessible to businesses and public sector organisations. Understanding our domestic AI computing capacity needs and their relationship to energy use is increasingly important[footnote 25] if we are to achieve our ambitions. To better understand the UK’s future AI computing requirements, the Office for AI and UKRI will evaluate the UK’s computing capacity needs to support AI innovation, commercialisation and deployment. This study will look at the hardware and broader needs of researchers and organisations, large and small, developing AI technologies, alongside organisations adopting AI products and services. The study will also consider the possible wider impact of future computing requirements for AI as it relates to areas of proportional concern, such as the environment. The report will feed into UKRI’s wider work on Digital Research Infrastructure.[footnote 26] Alongside access to necessary compute capacity, the competitiveness of the AI hardware will be critical to the UK\\'s overall research and commercial competitiveness in the sector. The UK is a world leader in chip and systems design, underpinned by processor innovation hubs in Cambridge and Bristol. We have world-leading companies supporting both general purpose AI – Graphcore has built the world\\'s most complex AI chip,[footnote 27] and for specific applications – XMOS is a leader in AI for IOT. The government is currently undertaking a wider review of its international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. Finance and VC AI innovation is thriving in the UK, backed by our world-leading financial services industry. In 2020, UK firms that were adopting or creating AI-based technologies received £1.78bn in funding, compared to £525m raised by French companies and £386m raised in Germany.[footnote 28] More broadly, investment in UK deep tech companies has increased by 291% over the past five years, though deal sizes remain considerably smaller compared to the US.[footnote 29] The government will continue to evaluate the state of funding specifically for innovative firms developing AI technologies across every region of the UK. This work will explore if there are any significant investment gaps or barriers to accessing funding that AI innovative companies are facing that are not being addressed. Government commits to reporting on this work in Autumn 2022. Accessing the right finance at the right time is critical for AI innovators to be able to develop their idea into a commercially viable product and grow their business, but this is complicated by the long timelines often needed for AI research and development work.[footnote 30][footnote 31] The AI Council’s Roadmap suggests a funding gap at series B+, meaning that AI companies are struggling to scale and stay under UK ownership. Tech Nation Tech Nation is a predominantly government-funded programme, built to deliver its own initiatives that grow and support the UK’s burgeoning digital tech sector. This includes growth initiatives aiming to help businesses successfully navigate the transition from start-up to scale-up and beyond, network initiatives to connect the UK digital ecosystem, and the Tech Nation Visa scheme, which offers a route into the UK for exceptionally talented individuals from overseas. Recent growth programmes include Applied AI, their first to help the UK’s most promising founders who are applying AI in practical areas and creating real-world impact; Net Zero, a six-month free growth programme for tech companies that are creating a more sustainable future; and Libra, which is focused on supporting Black founders and addressing racial inequality in UK tech. While the UK’s funding ecosystem is robust, the government is committed to ensuring the system is easy for businesses and innovators to navigate, and that any existing gaps are addressed. The recent Innovation Strategy signalled the Government’s efforts to support innovators by bringing together effective private markets with well-targeted public investment. In it, the government set out plans to upskill lenders to assess risk when lending to innovative businesses and outlined work across Innovate UK and the British Business Bank to investigate how businesses interact with the public support landscape, to maximise accessibility for qualifying businesses. A good example of this is the Future Fund: Breakthrough, a new £375 million UK-wide programme launched in July 2021, will encourage private investors to co-invest with the government in high-growth innovative businesses to accelerate the deployment of breakthrough technologies. Our economy’s success and our citizens’ safety rely on the government’s ability to protect national security while keeping the UK open for business with the rest of the world. Within this context, we will ensure we protect the growth of welcome investment into the UK’s AI ecosystem. The government has introduced the National Security and Investment Act that will provide new powers to screen investments effectively and efficiently now and into the future. It will give businesses and investors the reassurance that the UK continues to welcome the right talent, investment and collaboration that underpins our wider economic security. Trade AI is a key part of the UK’s digital goods and services exports, which totalled £69.3bn in 2019.[footnote 32] Trade can support the UK’s objectives to sustain the mature, competitive and innovative AI developer base the UK needs to access customers around the world. As part of its free trade agenda, the government is committed to pursuing ambitious digital trade chapters to help place the UK as a global leader. As the UK secures new trade deals, the government will include provisions on emerging digital technologies, including AI, and champion international data flows, preventing unjustified barriers to data crossing borders while maintaining the UK’s high standards for personal data protection. In doing so, the UK aims to deliver digital trade chapters in agreements that: 1) provide legal certainty; 2) support data flows; 3) protect consumers; 4) minimise non-tarriff barriers to digital trade; 5) prevent discrimination against trade by electronic means; and 6) promote international cooperation and global AI governance. All of these aims support a pro -innovation agenda. Pillar 1 - Investing in the Long Term Needs of the AI Ecosystem Actions: 1. Launch a new National AI Research and Innovation Programme, that will align funding programmes across UKRI Research Councils and Innovate UK, stimulating new investment in fundamental AI research while making critical mass investments in particular applications of AI. 2. Lead the global conversation on AI R&D and put AI at the heart of our science and technology alliances and partnerships worldwide through: Work with partners around the world on shared AI challenges, including participation in Horizon Europe to enable collaboration with other European researchers. Use of Overseas Development Assistance to support partnerships with developing AI nations. Delivering new initiatives through the US UK Declaration on Cooperation in AI R&D. 3. Develop a diverse and talented workforce which is at the core of maintaining the UK’s world leading position through: Supporting existing interventions across top talent, PhDs and Masters levels and developing world leading teams and collaborations, the government will continue to attract and develop the brightest and best people to build AI. Scoping what is required to upskill employees to use AI in a business setting. Then, working with the Department for Education, explore how skills provision can meet these needs through the Skills Value Chain and build out AI and data science skills through Skills Bootcamps. Inspiring all to be excited by the possibilities of AI, by supporting the National Centre for Computing Education (NCCE) to ensure AI programmes for children are accessible and reach the widest demographic and that career pathways for those working with or developing AI are clearly articulated on career guidance platforms. Promoting the revitalised and new visa routes that encourage innovators and entrepreneurs to the UK, making attractive propositions for prospective and leading AI talent. 4. Publish a policy framework setting the government’s role in enabling better data availability in the wider economy. The government is already consulting on the opportunity for data intermediaries to support responsible data sharing and data stewardship in the economy and the interplay of AI technologies with the UK’s data rights regime. 5. Consult on the potential role and options for a future national ‘cyber-physical infrastructure’ framework, to help identify how common interoperable digital tools and platforms and cyber-physical or living labs could come together to form a digital and physical ‘commons’ for innovators, enabling accelerated AI development and applications. 6. Publish a report on the UK’s compute capacity needs to support AI innovation, commercialisation and deployment. The report will feed into UKRI’s wider work on infrastructure. 7. Continue to publish open and machine-readable data on which AI models for both public and commercial benefit can depend. 8. Consider what valuable datasets the government should purposefully incentivise or curate that will accelerate the development of valuable AI applications. 9. Undertake a wider review of our international and domestic approach to the semiconductor sector. Given commercial and innovation priorities in AI, further support for the chip design community will be considered. 10. Evaluate the state of funding specifically for innovative firms developing AI technologies in the UK, and report on this work in Autumn 2022. 11. Protect national security through the National Security & Investment Act while keeping the UK open for business with the rest of the world, as our economy’s success and our citizens’ safety rely on the government’s ability to take swift and decisive action against potentially hostile foreign investment. 12. Include provisions on emerging digital technologies, including AI, in future trade deals alongside championing international data flows, preventing unjustified barriers to data crossing borders and maintaining the UK’s high standards for personal data protection. Pillar 2: Ensuring AI benefits all sectors and regions Supporting the transition to an AI-enabled economy, capturing the benefits of AI innovation in the UK, and ensuring AI technologies benefit all sectors and regions To ensure that all sectors and regions of the UK economy can benefit from the positive transformation that AI will bring, the government will back the domestic design and development of the next generation of AI systems, and support British business to adopt them, grow and become more productive. The UK has historically been excellent at developing new technologies but less so at commercialising them into products and services. As well as smart action to support both suppliers, developers and adopters, government also has a role to play when it comes to the use of AI, both as a significant market pull in terms of public procurement, such as the NHS and the defence sector, with a dedicated Defence AI Strategy and AI Centre, but also in terms of using the technology to solve big public policy challenges, such as in health and achieving net zero. Finally, it requires being bold and experimental, and supporting the use of AI in the service of mission-led policymaking. Government’s aim is to diffuse AI across the whole economy to drive the highest amount of economic and productivity growth due to AI. This will be achieved by: Supporting AI businesses on their commercial journey, understanding the unique challenges they face and helping them get to market and supporting innovation in high potential sectors and locations where the market currently doesn’t reach; Understanding better the factors that influence the decisions to adopt AI into organisations – which includes an understanding of when not to; Ensuring AI is harnessed to support outcomes across the government’s Innovation Strategy, including by purposefully leveraging our leading AI capabilities to tackle real-world problems facing the UK and world through our Innovation Missions,[footnote 33] while driving forward discovery; Leveraging the whole public sector’s capacity to create demand for AI and markets for new services. Commercialisation Developing a commercial AI product or service is more than just bringing an idea to market or accessing the right funding. Recent analysis from Innovate UK suggests that obtaining private funding is only one among many other obstacles to successful commercial outcomes in AI-related projects. As well as the well known barriers such as access to data, labour market supply and access to relevant skills discussed above, other challenges reported by businesses are the lack of engagement with end users, limiting adoption and commercialisation. Commercialisation outcomes are also often constrained by business models rather than technical issues and a lack of understanding of AI-related projects’ return on investment. AI deployment – understanding new dynamics To grow the market and spread AI to more areas of our economy, the government aims to support the demand side as well as the means for commercialising AI - understanding what, why, when and how companies choose to incorporate AI into their business planning is a prerequisite to any attempt to encourage wider adoption and diffusion across the UK. EY research delivered on behalf of DCMS shows that AI remains an emerging technology for private sector and third sector organisations in the UK. 27% of UK organisations have implemented AI technologies in business processes; 38% of organisations are planning and piloting AI technology; and 33% of organisations have not adopted AI and are not planning to. Consistent with studies of AI adoption,[footnote 34] the size of an organisation was found to be a large contributing factor to the decision to adopt AI, with large organisations far more likely to have already done so. Recognising that for many sectors this is the cutting edge of industrial transformation, and the need for more evidence, the Office for AI will publish research later this year into the drivers of AI adoption and diffusion. To stimulate the development and adoption of AI technologies in high-potential, low-AI maturity sectors the Office for AI and UKRI will launch a programme that will : Support the identification and creation of opportunities for businesses, whether SMEs or larger firms, to use AI and for AI developers to build new products and services that address these needs; Create a pathway for AI developers to start companies around new products and services or to extend and diversify their product offering if they are looking to grow and scale; Facilitate close engagement between businesses and AI developers to ensure products and services developed address business needs, are responsibly developed and implemented, and designed and deployed so that businesses and developers alike are prepped and primed for AI implementation; and Incentivise investors to learn about these new market opportunities, products, and services, so that, where equity finance is needed, the right financing is made available to AI developers. Creating and protecting Intellectual Property Intellectual Property (IP) plays a significant part in building a successful business by rewarding people for inventiveness and creativity and enabling innovation. IP supports business growth by incentivising investment, safe-guarding assets and enabling the sharing of know-how. The Intellectual Property Office (IPO) recognises that AI researchers and developers need the right support to commercialise their IP, and helps them to understand and identify their intellectual assets, providing them with the skills to protect, exploit and enforce their rights to improve their chances of survival and growth. AI and Intellectual Property (IP): Call for Views and Government Response An effective Intellectual Property (IP) system is fundamental to the Government’s ambition for the UK to be a ‘science superpower’ and the best place in the world for scientists, researchers and entrepreneurs to innovate. To ensure that IP incentivises innovation, our aspiration is that the UK’s domestic IP framework gives the UK a competitive edge. In support of this ambition, the IPO published its AI and IP call for views to put the UK at the forefront of emerging technological opportunities, by considering how AI impacts on the existing UK intellectual property framework and what impacts it might have for AI in the near to medium term. In March this year, the government published its response to the call for views, which committed to the following next steps: To consult on the extent to which copyright and patents should protect AI generated inventions and creative works; To consult on measures to make it easier to use copyright protected material in AI development; An economic study to enhance understanding of the role the IP framework plays in incentivising investment in AI. The consultation, on copyright areas of computer generated works and text and data mining, and on patents for AI devised inventions, will be launched before the end of the year so that the UK can harness the opportunities of AI to further support innovation and creativity. Using AI for the public benefit AI can contribute to solving the greatest challenges we face. AI has contributed to tackling COVID-19, demonstrating how these technologies can be brought to bear alongside other approaches to create effective, efficient and context-specific solutions. AI and COVID-19 When the pandemic began it created a unique environment where AI technologies were developed to identify the virus more quickly, to help with starting treatments earlier and to reduce the likelihood that people will need intensive care. Working with Faculty, NHS England and NHS Improvement developed the COVID-19 Early Warning System (EWS). A first-of-its-kind toolkit that forecasts vital metrics such as COVID-19 hospital admissions and required bed capacity up to three weeks in advance, based on a wide range of data from the NHS COVID-19 Data Store. This gave national, regional and local NHS teams the confidence to plan services for patients amid any potential upticks in COVID-related hospital activity. At the same time over the past year, the NHS AI Lab has collected more than 40,000 X-ray, CT and MRI chest images of over 13,000 patients from 21 NHS trusts through the National COVID-19 Chest Imaging Database (NCCID), one of the largest centralised collections of medical images in the UK. The NCCID is being used to study and understand the COVID-19 illness and to improve the care for patients hospitalised with severe infection. The database has enabled 13 projects to research new AI technologies to help speed up the identification, severity assessment and monitoring of COVID-19. UK AI companies have also shown how AI can help accelerate the search for potential drug candidates, streamline triage and contribute to global research efforts. BenevolentAI, a world-leading AI company focused on drug discovery and medicine development, used their biomedical knowledge graph to identify a potential coronavirus treatment from already approved drugs that could be repurposed to defeat the virus. This was later validated through experimental testing from AstraZeneca. UK AI company DeepMind have adapted their AI-enabled protein folding breakthrough to better understand the virus’ structure, contributing to a wider understanding of how the virus can function. There are many areas of AI development that have matured to the point that industry and third sector organisations are investing significantly in AI tools, techniques and processes. These investments are helping to move AI from the lab and into commercial products and services. But there remain more complex, cross-sector challenges that industry is unlikely to solve on its own. These challenges will require public sector leadership, identifying strategic priorities that can maximise the potential of AI for the betterment of the UK. The government has a clear role to play. In stimulating and applying AI innovation to priority applications and wider strategic goals, the government can help incentivise a group of different actors to harness innovation for improving lives, simultaneously reinforcing the innovation cycle that can drive wider economic benefits – from creating and invigorating markets, to the role of open source in the public, private and third sectors, to raising productivity. Over the next six to twelve months, the Office for AI will work closely with the Office for Science and Technology Strategy and government departments to understand the government’s strategic goals and where AI can provide a catalytic contribution,[footnote 35] including through Innovation Missions and the Integrated Review’s‘Own-Collaborate-Access’ framework. The COVID-19 pandemic has shown that global challenges need global solutions. The UK’s international science and technology partnerships, global network of science and innovation officers, and research and innovation hubs, are working alongside UK universities, research institutes and investors to foster new collaborations to tackle the global challenges we all share, including in innovations on global health and to achieve net zero emissions around the globe. Missions The Innovation Strategy set out the government’s plans to stimulate innovation to tackle major challenges facing the UK and the world, and drive capability in key technologies. This will be achieved through Innovation Missions,[footnote 36] which will draw on multiple technologies and research disciplines towards clear and measurable outcomes. They will be supported by Innovation Technologies,[footnote 37] including AI, supporting their capability to tackle pressing global and national challenges while supporting their adoption in novel areas, boosting growth and helping to consolidate our position as a science and AI superpower. Some of these challenges have been articulated and revolve around the future health, wellbeing, prosperity and security of people, the economy, and our environment – in the UK and globally. These challenges are worthwhile and therefore difficult, and will require harnessing the combined intellect and diversity of the AI ecosystem and the whole nation, and will consider a full range of possible impacts of a given solution. The pace of AI development is often fast, parallel and non-linear, and finding the right answer to these challenges will require a collection of actors beyond just government departments, agencies and bodies to consider the technical and social implications of certain solutions and increase the creativity of problem solving. In doing so, the UK will be able to find new paths for AI to deliver on our security and prosperity objectives at home and abroad. At the same time, well-specified challenges have also led to some of the most impactful moments of progress in AI. Whether through Imagenet, CIFAR-10, MNIST, GLUE, SquAD, Kaggle, or more, challenge-related datasets and benchmarks have generated breakthroughs in vision, language, recommender systems, and other subfields.[footnote 38]. The government believes that challenges could be created that simultaneously incentivise significant progress in Innovation Missions while rapidly progressing the development in the technology along desirable lines. To this end, the government will develop a repository of short, medium and long term AI challenges to motivate industry and society to identify and implement real-world solutions to the strategic priorities. These priorities will be identified through the Missions Programme, and guided by the National AI R&I Programme. Climate change and global health threats are examples of shared international challenges, and science progresses through open international collaboration. This is particularly the case when AI development is able to take advantage of publicly available coding platforms to produce new algorithms. The UK will extend its science partnerships and its work investing UK aid to support local innovation ecosystems in developing countries. Through our leadership in international development and diplomacy, we will work to ensure international collaboration can unlock the enormous potential of AI to accelerate progress on global challenges, from climate change to poverty. Net zero The Prime Minister’s Ten Point Plan for a Green Industrial Revolution highlights the development of disruptive technologies such as AI for energy as a key priority, and in concert with the government’s Ten Tech Priorities to use digital innovations to reach net zero, the UK has the opportunity to lead the world in climate technologies, supporting us to deliver our ambitious net zero targets. This will be key to meet our stated ambition in the Sixth Carbon Budget, and with it a need to consider how to achieve the maximum possible level of emissions reductions. AI and net zero AI works best when presented with specific problem areas with clear system boundaries and where there are large datasets being produced. In these scenarios, AI has the capability to identify complex patterns, unlock new insights, and advise on how best to optimise system inputs in order to best achieve defined objectives. There are a range of climate change mitigation and adaptation challenges that fit this description. These include: using machine vision to monitor the environment; using machine learning to forecast electricity generation and demand and control its distribution around the network; using data analysis to find inefficiencies in emission-heavy industries; and using AI to model complex systems, like Earth’s own climate, so we can better prepare for future changes. AI applications for energy and climate challenges are already being developed, but they are predominantly outliers and there are many applications across sectors that are not yet attempted. A study by Microsoft and PwC estimated that AI can help deliver a global reduction in emissions of up to 4% by 2030 compared to business as usual, with a concurrent uplift of 4.4% to global GDP. Such estimates are likely to become more accurate over time as the potential of AI becomes more apparent. Over the last ten years there have been a series of advances in AI. These advances offer opportunities to rapidly increase the efficiency of energy systems and help reduce emissions across a wide array of climate change challenges. The AI Council’s AI Roadmap advocates for AI technologies to play a role in innovating towards solutions to climate change, and literature is emerging that shows how ‘exponential technologies’ such as AI can increase the pace of decarbonisation across the most impactful sectors. AI is increasingly seen as a critical technology to scale and enable these significant emissions cuts by 2030.[footnote 39],[footnote 40],[footnote 41] In the UK we have previously used mission-driven innovation policy to promote a range of technologies towards the delivery of social, economic and environmental goals. Government will continue this through the National AI R&I Programme, which will make critical mass investments in particular applications of AI technology that will generate new solutions to tackle our net zero objective. Missions will also be continued through the Innovation Strategy’s Missions Programme, which will form the heart of the government’s approach to respond to these priorities, and we will develop these missions in a way that considers the promise of AI technologies, particularly in areas of specific advantage such as energy. Government will ensure that, in key areas of international collaboration such as the US UK Declaration on Cooperation in AI Research and Development and the Global Partnership on AI, we will pursue technological developments in world-leading areas of expertise in the energy sector to maximise our strategic advantage. Health In August 2019, the Health Secretary announced a £250 million investment[footnote 42] to create the NHS AI Lab in HSX to accelerate the safe, ethical and effective development and use of AI-driven technologies to help tackle some of the toughest challenges in health and social care, including earlier cancer detection, addressing priorities in the NHS Long Term Plan, and relieving pressure on the workforce. AI-driven technologies have the potential to improve health outcomes for patients and service users, and to free up staff time for care.[footnote 43] The NHS AI Lab along with partners, such as the Accelerated Access Collaborative, the National Institute of Health and Care Excellenceand the Medicines and Healthcare products Regulatory Agency, are working to provide a facilitative environment to enable the health and social care system to confidently adopt safe, effective and ethical AI-driven technologies at pace and scale. The NHS AI Lab is creating a National Strategy for AI in Health and Social Care in line with the National AI Strategy. The strategy, which will begin engagement on a draft this year and is expected to launch in early 2022, will consolidate the system transformation achieved by the Lab to date and will set the direction for AI in health and social care up to 2030. The public sector as a buyer To build a world-leading strategic advantage in AI and build an ecosystem that harnesses innovation for the public good, the UK will need to take a number of approaches. As the government, we can also work with industry leaders to develop a shared understanding and vision for the emerging AI ecosystem, creating longer-term certainty that enables new supply chains and markets to form. This requires leveraging public procurement and pre-commercial procurement to be more in line with the development of deep and transformative technologies such as AI. The recent AI Council ecosystem survey revealed that 72% agreed the government should take steps to increase buyer confidence and AI capability. The Innovation Strategy and forthcoming National Procurement Policy Statement have recently articulated how we can further refine public procurement processes around public sector culture, expertise and incentive structures. This complements previous work across government to inform and empower buyers in the public sector, helping them to evaluate suppliers, then confidently and responsibly procure AI technologies for the benefit of citizens.[footnote 44] The government has outlined how it plans to rapidly modernise our Armed Forces[footnote 45][footnote 46] and how investments will be guided.[footnote 47][footnote 48] The Ministry of Defence will soon be publishing its AI strategy which will contribute to how we will achieve and sustain technological advantage, and be a great science power in defence. This will include the establishment of the new Defence AI Centre which will champion AI development and use, and enable rapid development of AI projects. Defence should be a natural partner for the UK AI sector and the defence strategy will outline how to galvanise a stronger relationship between industry and defence. Ministry of Defence using AI to reduce costs and meet climate goals The MOD is trialling a US startups’ Software Defined Electricity (SDE) system, which uses AI to optimise electricity in real time, to help meet its climate goals and reduce costs. Initial tests suggest it could reduce energy draw by at least 25% which, given the annual electricity bill for MOD’s non-PFI sites in FY 2018/19 was £203.6M, would equate to savings of £50.9M every year and significant reductions in CO2 emissions. Crown Commercial Service The Crown Commercial Service worked closely with colleagues in the Office for AI and across government during drafting of guidelines for AI procurement. This was used to design their AI Dynamic Purchasing System (DPS) agreement to align with these guidelines, and included a baselines ethics assessment so that suppliers commit only to bidding where they are capable and willing to deliver both the ethical and technical dimensions of a tender. The Crown Commercial Service is piloting a training workshop to help improve the public sector’s capability to buy AI products and services, and will continue to work closely with the Office for AI and others across government to ensure we are addressing the key drivers set out in the National AI Strategy. Pillar 2 - Ensuring AI Benefits all Sectors and Regions Actions: Launch a programme as part of UKRI’s National AI R&I Programme, designed to stimulate the development and adoption of AI technologies in high-potential, lower-AI maturity sectors. The programme will be primed to exploit commercialisation interventions, enabling early innovators to access potential market opportunities where their products and services are relevant. Launch a draft National Strategy for AI in Health and Social Care in line with the National AI Strategy. This will set the direction for AI in health and social care up to 2030, and is expected to launch in early 2022. Ensure that AI policy supports the government’s ambition to secure strategic advantage through science and technology. Consider how the development of Innovation Missions also incorporates the potential of AI solutions to tackling big, real-world problems such as net zero. This will also be complemented by pursuing ambitious bilateral and multilateral agreements that advance our strategic advantages in net zero sectors such as energy, and through the extension of UK aid to to support local innovation ecosystems in developing AI nations. Build an open repository of AI challenges with real-world applications, to empower wider civil society to identify and implement real-world solutions to the strategic priorities identified through the Missions Programme and guided by the National AI Research and Innovation Programme. Publish research into the determinants impacting the diffusion of AI across the economy. Publish the Ministry of Defence AI Strategy, which will explain how we can achieve and sustain technological advantage and be a science superpower in defence, including detail on the establishment of a new Defence AI Centre. Pillar 3: Governing AI effectively Ensuring that national governance of AI technologies encourages innovation, investment, protects the public and safeguards our fundamental values, while working with global partners to promote the responsible development of AI internationally. An effective governance regime that supports scientists, researchers and entrepreneurs to innovate while ensuring consumer and citizen confidence in AI technologies is fundamental to the government’s vision over the next decade. In a world where systematic international competition will have significant impacts on security and prosperity around the world, the government wants the UK to be the most trustworthy jurisdiction for the development and use of AI, one that protects the public and the consumer while increasing confidence and investment in AI technologies in the UK. Effective, pro-innovation governance of AI means that (i) the UK has a clear, proportionate and effective framework for regulating AI that supports innovation while addressing actual risks and harms, (ii) UK regulators have the flexibility and capabilities to respond effectively to the challenges of AI, and (iii) organisations can confidently innovate and adopt AI technologies with the right tools and infrastructure to address AI risks and harms. The UK public sector will lead the way by setting an example for the safe and ethical deployment of AI through how it governs its own use of the technology. We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights. Government’s aim is to build the most trusted and pro-innovation system for AI governance in the world. This will be achieved by: - Establishing an AI governance framework that addresses the unique challenges and opportunities of AI, while being flexible, proportionate and without creating unnecessary burdens; Enabling AI products and services to be trustworthy, by supporting the development of an ecosystem of AI assurance tools and services to provide meaningful information about AI systems to users and regulators; Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance; Building UK regulators’ capacities to use and assess AI, ensuring that they can deliver on their responsibilities as new AI-based products and services come to market; Setting an example in the safe and ethical deployment of AI, with the government leading from the front; Working with our partners around the world to promote international agreements and standards that deliver for our prosperity and security, and promote innovation that harnesses the benefits of AI as we embed our values such as fairness, openness, liberty, security, democracy, rule of law and respect for human rights. Supporting innovation and adoption while protecting the public and building trust The UK has a strong international reputation for the rule of law and technological breakthroughs. To build on this the government set out its pro-innovation approach through its Plan for Digital Regulation. The Plan recognises that well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation. The Plan also acknowledges that digital businesses, which include those developing and using AI technologies, are currently operating in some instances without appropriate guardrails. The existing rules and norms, which have so far guided business activity, were in many cases not designed for these modern technologies and business models. In addition, these technologies are themselves disrupting these established rules and norms. This is especially the case for AI which, with its powerful data processing and analytical capabilities, is disrupting traditional business models and processes.[footnote 49] There is growing awareness in industry and by citizens of the potential risks and harms associated with AI technologies. These include concerns around fairness, bias and accountability of AI systems. For example, the report from the Commission on Race and Ethnic Disparities raised concerns around the potential for novel ways for bias to be introduced through AI. Other concerns include the ability of AI to undermine privacy and human agency; and physical, economic and financial harms being enabled or exacerbated by AI technologies. For example, cyber security should be considered early in the development and deployment of AI systems to prevent such harms from arising, by adopting a ‘secure by design’ approach to mitigate against cyber security becoming an afterthought. This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency). As the use of AI increases, the UK has responded by reviewing and adapting the regulatory environment. For example, the Data: A new direction consultation, published earlier this month, invites views on the role of the data protection framework within the broader context of AI governance. Specifically, the consultation examines the role of sensitive personal data in bias detection and mitigation in AI systems, and the use of the term ‘fairness’ in a data protection context. Data Protection Framework and AI: Data: A new directionconsultation The UK data protection framework (UK General Data Protection Regulations and Data Protection Act 2018) is technology neutral and was not intended to comprehensively govern AI systems, or any other specific technologies. Many AI systems do not use personal data at all. Navigating and applying relevant data protection provisions can be perceived as a complex or confusing exercise for an organisation looking to develop or deploy AI systems, possibly impeding uptake of AI technologies. DCMS is currently running a consultation on potential reforms to the data protection framework, closing on the 19th November 2021. The consultation calls for views on specific data protection provisions that are currently triggered in the process of developing and deploying AI. In particular, the consultation covers: Clarifying the use and reuse of personal data for research (including AI development) (Ch 1); Clarifying the use and reuse of personal data under the legitimate interests test, including bias detection and mitigation anonymisation (Ch 1); Explicitly authorising the use of sensitive personal data (special category data) for bias detection and mitigation in AI systems (Ch 1); Clarifying the use of the term ‘fairness’ in a data protection context (Ch 1); Assessing the challenges with the current data protection framework in developing and deploying AI responsibly (Ch 1); Assessing the general suitability and operation of UK GDPR Article 22 (rights relating to automated decision-making and profiling) (Ch 1); Mandatory transparency requirements for the use of algorithmic decision-making in the public sector (Ch 5). In 2018, the government agreed with the House of Lords’ view that \"blanket AI-specific regulation, at this stage, would be inappropriate… [and] that existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed.\" There are some strong reasons why our sector-led approach makes sense: The boundaries of AI risks and harms are grey, because the harms raised by these technologies are often non-AI, or extensions of non-AI, issues, and also because AI is rapidly developing and therefore what counts as the AI part of a system is constantly changing. Use cases for AI, and their wider impacts, can be highly complex in their own right. There is a big limitation in what can be covered in cross-cutting legislation on AI, and regardless of the overall regulatory approach, the detail will always need to be dealt with at the level of individual harms and use cases. Individual regulators and industries are already starting to respond to the risks of AI, and to work with innovators in their sectors to guide on interpretation of existing regulations, and on what further regulatory responses are appropriate. Enabling and empowering individual bodies to respond is a much quicker response to individual harms than agreeing to an AI regulatory regime that makes sense across all sectors. AI is not the only ongoing technology change, and its impacts are often interlinked with other innovations and behaviour changes, including increased connectivity, the move to mobile working, the dominant role of major platforms etc. It is often hard to unpick the specific impact of AI; focusing regulation on the particular use cases where there is risk allows risks to be addressed holistically, and simplifies things for innovators. Having embraced a strong sector-based approach to date, now is the time to decide whether our existing approach remains the right one. As the UK’s regulators have begun to respond to the emergence of AI, challenges have emerged. These include: Inconsistent or contradictory approaches across sectors. While a sector-led approach allows responsiveness to sector specific challenges, it could create barriers to adoption across sectors by creating confusing or contradictory compliance requirements; Overlap between regulatory mandates, creating uncertainty about responsibility, the potential for issues to fall between the gaps, and increased need for coordination; AI regulation could become framed narrowly around prominent, existing cross-cutting frameworks, e.g. the data protection framework, while the range of AI risks and harms is much broader; The growing activity in multilateral and multi stakeholder fora internationally, and global standards development organisations that addresses AI across sectors could overtake a national effort to build a consistent approach. These challenges raise the question of whether the UK’s current approach is adequate, and whether there is a case for greater cross-cutting AI regulation or greater consistency across regulated sectors. At the same time, alternative methods and approaches to governing AI have emerged from multilateral and multi stakeholder fora, at international and regional levels, including global standards development organisations, academia, thought leaders, and businesses. This has raised awareness about the importance of AI governance, but also potentially confusion for the consumer about what good AI governance looks like and where responsibility lies. Working with the AI ecosystem the Office for AI will develop our national position on governing and regulating AI, which will be set out in a White Paper in early 2022. The White Paper will set out the government’s position on the potential risks and harms posed by AI technologies and our proposal to address them. Alternative options The UK’s 2018 policy position that \"existing sector-specific regulators are best placed to consider the impact on their sector of any subsequent regulation which may be needed\" will be tested in our work towards the development of a White Paper, along with potential alternatives. The main alternative options are: Removing some existing regulatory burdens where there is evidence they are creating unnecessary barriers to innovation. Retaining the existing sector-based approach, ensuring that individual regulators are empowered to work flexibly within their own remits to ensure AI delivers the right outcomes. Introducing additional cross-sector principles or rules, specific to AI, to supplement the role of individual regulators to enable more consistency across existing regimes. For any of these options, it will be necessary to ensure that regulators and other relevant bodies are equipped to tackle the challenges raised by AI. This may require additional capabilities, capacity, and better coordination among existing regulators; new guidance; or standards to better enable consistency across existing regulatory regimes. In developing our White Paper position, the Office for AI will consider all of these, and potentially other, options for governing AI technologies. Having exited the EU, we have the opportunity to build on our world-leading regulatory regime by setting out a pro-innovation approach, one that drives prosperity and builds trust in the use of AI. We will consider what outcomes we want to achieve and how best to realise them, across existing regulators’ remits and consider the role that standards, assurance, and international engagement plays. Regulators’ coordination and capacity While some regulators are leading the way in understanding the implications of AI for their sector or activity, we need all regulators to be able to do this. The cross-sector and disruptive nature of AI also raises new challenges in terms of regulatory overlap. For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance. The government is working with The Alan Turing Institute and regulators to examine regulators’ existing AI capacities. In particular, this work is exploring monitoring and assessing products and services using AI and dealing with complexities arising from cross-sectoral AI systems.[footnote 50] Greater cooperation is also being enabled through initiatives such as through the Digital Regulation Cooperation Forum, a recently formed voluntary forum comprising the Competition & Markets Authority (CMA), Financial Conduct Authority (FCA), Information Commissioner’s Office (ICO) and Office of Communications (Ofcom) to deliver a joined up approach to digital regulation. International governance and collaboration The UK will work with partners to support the international development of AI governance in line with our values. We will do this by working with partners around the world to shape approaches to AI governance under development, such as the proposed EU AI Act and potential Council of Europe legal framework. We will work to reflect the UK’s views on international AI governance and prevent divergence and friction between partners, and guard against abuse of this critical technology. The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes. As the international debate on these frameworks has gained momentum, the UK has proactively engaged on AI at the OECD[footnote 51], Council of Europe and UNESCO, and helped found the Global Partnership on AI (GPAI), providing significant support for evidence underpinning these initiatives, such as the recently announced £1m investment in GPAI’s data trust research by BEIS. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression and through our science partnerships and wider development and diplomacy work seek to engage early with countries on AI governance, including when existing technology governance is less developed, to promote open society values and defend human rights. UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI. The government will continue to work with our partners around the world to shape international norms and standards relating to AI, including those developed by multilateral and multistakeholder bodies at global and regional level. This will support our vision for a global ecosystem that promotes innovation and responsible development and use of technology, underpinned by our shared values of freedom, fairness, and democracy. AI and global digital technical standards The UK’s Plan for Digital Regulation sets out our ambition to use digital technical standards to provide an agile and pro-innovation way to regulate AI technologies and build consistency in technical approaches, as part of a wider suite of governance tools complementing ‘traditional’ regulation. The integration of standards in our model for AI governance and regulation is crucial for unlocking the benefits of AI for the economy and society, and will play a key role in ensuring that the principles of trustworthy AI are translated into robust technical specifications and processes that are globally-recognised and interoperable. What are technical standards and how do they benefit the UK? Global technical standards set out good practice that can be consistently applied to ensure that products, processes and services perform as intended – safely and efficiently. They are generally voluntary and developed through an industry-led process in global standards developing organisations, based on the principles of consensus, openness, and transparency, and benefiting from global technical expertise and best practice. For example, technical standards are referenced alongside regulatory tools in the UK’s digital identity and attributes trust framework (2021), which represents a cohesive set of rules for digital identity services. We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake. Supporting trade. Technical standards should facilitate digital trade by minimising regulatory requirements and technical barriers to trade. Giving UK businesses more opportunities. Standardisation is a co-creation process that spans different roles and sectors, providing businesses with access to market knowledge, new customers, and commercial and research partnerships. Delivering on safety, security and trust. The Integrated Review set out the role of technical standards in embedding transparency and accountability in the design and deployment of technologies. AI technical standards (e.g. for accuracy, explainability and reliability) should ensure that safety, trust and security are at the heart of AI products and services. Supporting conformity assessments and regulatory compliance. Technical standards should support testing and certification to ensure the quality, performance, reliability of products before they enter the market. This includes providing a means of compliance with requirements set out in legislation. The UK is taking a global approach to shaping technical standards for AI trustworthiness, seeking to embed accuracy, reliability, security, and other facets of trust in AI technologies from the outset. The government’s work to date on AI technical standards with international partners, industry, and other stakeholders provides a potential foundation to complement our governance and regulatory approach. Domestically, the government has established a strategic coordination initiative with the British Standards Institution (BSI) and the National Physical Laboratory to explore ways to step up the UK’s engagement in global standards developing organisations.[footnote 52] The government is also exploring with stakeholders to: Pilot an AI Standards Hub to expand the UK’s international engagement and thought leadership; and Develop an AI standards engagement toolkit to guide multidisciplinary UK stakeholders to engage in the global AI standardisation landscape. Internationally, the government is: Increasing bilateral engagement with partners, including strengthening coordination and information sharing. Bringing together conversations at standards developing organisations and multilateral fora. BSI and the government are members of the Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS), which unites global SDOs, businesses, and research institutes. Engaging in the OECD’s Network of Experts Group on Implementing Trustworthy AI, collaborating with governments, academics, and experts to build guidance. Promoting the 2021 Carbis Bay G7 Leaders’ Communiqué, on supporting inclusive, multi-stakeholder approaches to standards development, by ensuring our UK approach to AI standards is multidisciplinary, and encourages a wide set of stakeholders in standards developing organisations. The UK is leading the way on AI technical standards internationally The UK’s global approach to AI standardisation is exemplified by our leadership in the International Organisation for Standardisation and International Electrotechnical Commission (ISO/IEC) on four active AI projects, as well as the UK’s initiation of and strong engagement in the Industry Specification Group on Securing AI at the European Telecommunications Standards Institute (ETSI). At ISO/IEC, the UK, through BSI, is leading the development of AI international standards in concepts and terminology; data; bias; governance implications; and data life cycles. At ETSI we have published, among other documents, ETSI GR SAI 002 on Data Supply Chain Security, which was led by the UK’s National Cyber Security Centre. The ISO/IEC work programme includes the development of an AI Management System Standard (MSS), which intends to help solve some of the implementation challenges of AI. This standard will be known as ISO/IEC 42001 and will help an organisation develop or use artificial intelligence responsibly in pursuing its objectives, and deliver its expected obligations related to interested parties. AI Assurance Understanding whether AI systems are safe, fair or are otherwise trustworthy requires measuring, evaluating and communicating a variety of information, including how these systems perform, how they are governed and managed, whether they are compliant with standards and regulations, and whether they will reliably operate as intended. AI assurance will play an important enabling role, unlocking economic and social benefits of AI systems. What is Assurance? Assurance covers a number of governance mechanisms for third parties to develop trust in the compliance and risk of a system or organisation.Assurance as a service draws originally from the accounting profession, but has since been adapted to cover many areas such as cyber security, product safety, quality and risk management. In these areas, mature ecosystems of assurance products and services enable people to understand whether systems are trustworthy and direct their trust or distrust appropriately. These products and services include: process and technical standards; repeatable audits; impact assessments; certification schemes; advisory and training services. An AI assurance ecosystem is emerging within both the public and private sectors, with a range of companies including established accountancy firms and specialised start-ups, beginning to offer assurance services. A number of possible assurance techniques[footnote 53] have been proposed and regulators are beginning to set out how AI might be assured (for example, the ICO’s Auditing Framework for AI). However, the assurance ecosystem is currently fragmented and there have been several calls for better coordination, including from the Committee on Standards in Public Life and the Office for Statistics Regulation. The CDEI’s recently published review into bias in algorithmic decision-making also points to the need for an ecosystem of industry standards and professional services to help organisations address algorithmic bias in the UK and beyond. Playing this crucial role in the development and deployment of AI, assurance is likely to become a significant economic activity in its own right and is an area in which the UK, with particular strengths in legal and professional services, has the potential to excel. To support the development of a mature AI assurance ecosystem, the CDEI is publishing an AI assurance roadmap. This roadmap clarifies the set of activities needed to build a mature assurance ecosystem and identifies the roles and responsibilities of different stakeholders across these activities. Public sector as an exemplar The government must lead from the front and set an example in the safe and ethical deployment of AI. The Office for AI and the Government Digital Service worked with The Alan Turing Institute to produce guidance on AI ethics and safety in the public sector in 2019. This guidance identifies the potential harms caused by AI systems and proposes measures to counteract them. The government is working with The Alan Turing Institute to update this guidance in order to provide public servants with the most current information about the state of the art in responsible AI innovation. This update incorporates the delivery of interactive workbooks aimed to equip public sector stakeholders with the practical tools and skills needed to bring the content of the original guidance to life.[footnote 54] The Ministry of Defence is moving quickly against a fast-evolving threat picture to secure the benefits of these transformative technologies. The Ministry of Defence has rigorous codes of conduct and regulation which uphold responsible AI use, and is working closely with the wider government on approaches to ensure clear alignment with the values and norms of the society we represent. As the CDEI conducts its ongoing work to address bias in algorithmic decision-making, the Commission on Race and Ethnic Disparities recommended that a mandatory transparency obligation be placed on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals, highlighting the importance of stewarding AI systems in a responsible manner to increase overall trust in their use. To ensure that citizens have confidence and trust in how data is being processed and analysed to derive insights, the Central Digital and Data Office (CDDO) is conducting research with a view to developing a cross-government standard for algorithmic transparency in line with the commitment in the National Data Strategy. The CDDO work is being conducted collaboratively with leading organisations in AI and data ethics and it has been informed by a range of public engagement processes. To date, no other country has developed a standard for algorithmic transparency at a national level. Proactive transparency in this field will be an extension of the UK’s long standing open data and data ethics leadership. AI risk, safety, and long-term development The government takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for the UK and the world, seriously. There are also risks, safety and national security concerns that must be considered here and now - from deepfakes and targeted misinformation from authoritarian regimes, to sophisticated attacks on consumers or critical infrastructure. As AI becomes increasingly ubiquitous, it has the potential to bring risks into everyday life, into businesses and into national security and defence. So as AI becomes more general and is simply used in more domains, we must maintain a broad perspective on implications and threats, with the tools to understand its most subtle impacts, and ensure the UK is protected from bad actors using AI, as well as risks inherent in unsafe future versions of the technology itself. The Office for AI will coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Given the speed at which AI developments are impacting our world, it is also critical that the government takes a more precise and timely approach to monitoring progress on AI, and the government will work to do so. The government will support the safe and ethical development of these technologies as well as using powers through the National Security & Investment Act to mitigate risks arising from a small number of potentially concerning actors. At a strategic level, the National Resilience Strategy will review our approach to emerging technologies; the Ministry of Defence will set out the details of the approaches by which Defence AI is developed and used; the National AI R&I Programme’s emphasis on AI theory will support safety; and central government will work with the national security apparatus to consider narrow and more general AI as a top-level security issue. Pillar 3 - Governing AI Effectively Actions: Develop a pro-innovation national position on governing and regulating AI, which will be set out in a White Paper, to be published in early 2022. Publish the CDEI AI assurance roadmap and use this to continue work to develop a mature AI assurance ecosystem in the UK. Pilot an AI Standards Hub to coordinate UK engagement in AI standardisation globally, and explore with stakeholders the development of an AI standards engagement toolkit to support the AI ecosystem to engage in the global AI standardisation landscape. Continue our engagement to help shape international frameworks, and international norms and standards for governing AI, to reflect human rights, democratic principles, and the rule of law on the international stage. Support the continuing development of new capabilities around trustworthiness, acceptability, adoptability, and transparency of AI technologies via the national AI Research and Innovation Programme. Publish details of the approaches which the Ministry of Defence will use when adopting and using AI. Develop a cross-government standard for algorithmic transparency. Work with The Alan Turing Institute to update the guidance on AI ethics and safety in the public sector. Coordinate cross-government processes to accurately assess long term AI safety and risks, which will include activities such as evaluating technical expertise in government and the value of research infrastructure. Work with national security, defence, and leading researchers to understand how to anticipate and prevent catastrophic risks. Next steps The National AI Strategy proposes three core pillars which, taken together, are areas the UK can make the biggest impact to set the country on its way to being an AI and science superpower fit for the coming decade. By their nature, strategies are a response to the moment in which they exist - further actions will also be required to elaborate on the paths set out in this document in a way that responds to the fast-changing landscape in the years to come. A plan to execute against the vision set out in this strategy will be published in the near future. Alongside this, we will put mechanisms in place to monitor and assess progress. We will publish a set of quantitative indicators, given the far-ranging and hard-to-define impacts AI will have on the economy and society. We will publish these indicators separately to this document and at regular intervals to provide transparency on our progress and to hold ourselves to account. Given the cross-cutting nature of AI, collaboration across a wide range of sectors and stakeholders will be paramount. The Office for AI will be responsible for overall delivery of the strategy, monitoring progress and enabling its implementation across government, industry, academia and civil society. We will also continue talking with the wider community to get their feedback on AI in the UK. Taken together, this quantitative analysis and qualitative intelligence will enable us to track progress and course-correct if we are at risk of falling short in any particular area. The government’s AI Council, an independent expert group formed to represent high-level leadership of the UK’s AI ecosystem, has played a key role in reaching a National AI Strategy and informing its direction. As we move into an implementation phase, the AI Council will continue to help galvanise action from across the ecosystem in fulfilling our objectives and holding the government to account on the actions contained in the strategy. The recently established Office for Science and Technology Strategy, National Science and Technology Council and National Technology Adviser will work with the rest of government to drive forward Whitehall’s science and technology priorities from the centre. As a part of this, we will collectively identify the technological capabilities required in the UK and in the government to deliver the Prime Minister’s global science superpower ambitions through AI. Deep technologies are based on significant scientific advances or engineering innovations, but which require a longer period of development and/or considerable capital investment before commercial application. Transformative technologies are those that have the potential for impact across many sectors of the economy, not just within a single sector.↩ This definition is different due to the clarity needed for legislation. See National security and investment: mandatory notification sectors for more information.↩ This refers to the ownership of creative content generated by an algorithm. While this is an open discussion, the Intellectual Property Office has covered this topic in a recent consultation outcome and has committed to consult on the extent to which copyright and patents should protect AI generated creative works and inventions.↩ Technology Review, Yes, We Are Worried About the Existential Risk of Artificial Intelligence (2016)↩ Human Compatible, Stuart Russell (2019)↩ GCHQ, Pioneering a New National Security: The Ethics of Artificial Intelligence (2021)↩ Stanford University, Artificial Intelligence Index Report 2021 (2021)↩ DeepMind, AlphaFold: a solution to a 50-year-old grand challenge in biology (2020)↩ Perry World House, The Immigration Preferences of Top AI Researchers (2021)↩ This is not an exhaustive list and does not capture the full spectrum of AI spend, either day-to-day or as single investments, across the whole of central government. This also excludes defence spend on AI.↩ The Innovation Strategy’s seven technology families were derived from an analytical synthesis drawing on work from BEIS, UK Research and Innovation including Innovate UK, and the Intellectual Property Office. The methodology considered UK R&D strength, industrial capacity, and global opportunity.↩ Microsoft, AI Skills in The UK (2020)↩ Ipsos MORI, Understanding the UK AI labour market: 2020 (2021)↩ ibid.↩ ibid.↩ ibid.↩ GOV.UK, UK Innovation Strategy: Leading the future by creating it, pg 55 (2021)↩ Times Higher Education, Which countries and universities are leading on AI research? (2017)↩ GOV.UK, Growing the Artificial Intelligence Industry in the UK (2017)↩ House of Lords Select Committee on Artificial Intelligence, AI in the UK: ready, willing and able? (2018)↩ Global Innovation Index, Global Innovation Index 2020 Report (2020)↩ This is supported by research findings from EY, which reveals that private and third sector organisations overwhelmingly identified quality as the most important data characteristic to their success.↩ Sometimes referred to as the ‘metaverse’.↩ Large-Scale Computing means computer systems where processing power, memory, data storage and networks are assembled at scale to tackle computational tasks beyond the capabilities of everyday computers. Often involves the widespread use of parallelisation. An umbrella term encompassing terms such as high performance computing, high throughput computing, supercomputing and novel computing paradigms.↩ Recognition of the important role of computing capacity as an enabler for AI technologies is increasing. The OECD has established an OECD.AI task force on AI compute to create a framework for understanding, measuring and benchmarking domestic AI computing supply by country and region.↩ UKRI, £213m to upgrade the UK’s world-class research infrastructure (2021)↩ The Verge, British chip designer Graphcore unveils new AI processor more complex than Nvidia’s (2020)↩ Gerard Grech, CEO of Tech Nation, Figures from 2021 survey, unpublished↩ British Business Bank, Small Business Equity Tracker (2021)↩ Innovate UK research found that the benefits from investing or developing these technologies lead to significant economic impacts by increasing the number of ‘investable’ propositions but, given the long commercialisation cycles, it is something that takes time and might not be considered an attractive quick win, leading to a decrease of funding for lower maturity AI technologies with less developed commercialisation plan.↩ Deep tech companies have additional difficulties raising equity funding compared to software companies because of their complex nature, long development times and large amounts of financing required. Tech Nation (2021) supports this finding, with \"deep tech start-ups taking 8–12 years for VCs to see returns, versus 3–5 years\" for start up companies in general, including software companies.↩ Based on data from DCMS Sectors Economic Estimates 2019: exports of digital goods and exports of digital services.↩ pg. 80-84 of the Innovation Strategy↩ e.g. Advanced Technologies Adoption And Use By U.S. Firms: Evidence From The Annual Business Survey (2020)↩ GOV.UK, Prime Minister sets out plans to realise and maximise the opportunities of scientific and technological breakthroughs (2021)↩ pg. 80-84 of the Innovation Strategy↩ pg. 84-100 of the Innovation Strategy↩ Quartz, ImageNet: the data that spawned the current AI boom (2017)↩ The Exponential Roadmap Initiative (2019)↩ ITU/UN, Frontier Technologies to Protect the Environment and Tackle Climate Change (2020)↩ D. Rolnick et. al., Tackling Climate Change with Machine Learning (2019)↩ GOV.UK, Health Secretary announces £250 million investment in artificial intelligence (2019)↩ Global Digital Health Partnership, AI for healthcare: Creating an international approach together (2020)↩ This includes work with the Crown Commercial Service to produce a new AI services procurement framework, and work with the World Economic Forum Centre for the Fourth Industrial Revolution to produce guidelines on AI procurement.↩ GOV.UK, Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy (2021)↩ GOV.UK, The Defence Command Paper sets out the future for our armed forces (2021)↩ GOV.UK, MoD Science and Technology Strategy (2020)↩ GOV.UK, Defence and Security Industrial Strategy (2021)↩ Deloitte, Artificial intelligence (AI) goes mainstream (2021)↩ This work is also looking at how AI technologies can be used by regulators to discharge their legal duties.↩ OECD AI Principles and OECD AI Policy Observatory↩ NPL, Unlocking standards for 4th industrial revolution (2021)↩ Ada Lovelace Institute, Examining the Black Box: Tools for assessing algorithmic systems (2020)↩ The practice- and activity-based approach of the workbooks aims to increase public sector adoption of the guidance by engaging civil servants in capacity building workshops that support the execution of ethically sound practices throughout the AI design, development, and implementation lifecycle.↩'), Document(metadata={'uuid': UUID('c2f9fe84-c665-4606-ad6d-7a2d0faaecc9'), 'index': 3, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/sin-canada-secures-investment-and-jobs-in-artificial-intelligence-in-the-uk', 'token_count': 537}, page_content='In 2018, SIN Canada team was instrumental in securing almost £2 million investment from Canada’s most successful AI start-up, Element AI, nearly £4 million from Canadian Venture Capitals to BIOS a Cambridge-based to export their expertise to Canada, while also organising a UK-Canada AI Innovation Challenge set by Bombardier. SIN Secures Business Wins Element AI launched its first international office In London with an initial investment of almost £2 million and rapid job creation. This was a direct result of interactions with SIN and DIT local teams and followed the SIN inward AI mission to the UK. Montreal-based Element AI grew from 7 people in October 2016 to over 500 employees in late 2018 with offices now in Toronto, Seoul and Singapore and has already raised over £400 million in funding to date, aiming for unicorn status. This investment builds upon the UK’s historic expertise in AI and the ongoing, pioneering work that the UK continues to promote. SIN Canada in collaboration with the UK’s Knowledge Transfer Network (KTN) facilitated BIOS with access to nearly £4 million in seed funding from Canadian investors. BIOS has recently opened an R&D office in Montreal. The company is developing a “neural interface” using AI, which can be used to develop new cutting-edge treatments on organs and nerve systems throughout the body. BIOS will use the funding to double its technical team and further develop its core neural interface technologies and readily commercialise its products. SIN organised 1st UK-Canada AI Innovation Challenge SIN Canada, Digital Catapult and the consortium in Aersospace Research and Innovation in Canada delivered a UK-Canada AI Innovation Challenge set by Bombardier. Launched by Baroness Fairhead in September 2018, this activity responds to the Industrial Strategy, AI Sector Deal, AI Grand Challenge. The challenge called on innovators to use AI to make aircraft less costly and more eco-friendly by burning less fuel. UK and Canadian start-ups and researchers pitched ideas for AI to help improve the systems used to prevent ice build-up on wings and help aircraft reach their optimum performance. The winners, London-based start-up DecisionLab and Canadian start-up BI Expertise, had the opportunity to visit Bombardier and explore a potential multimillion future collaboration and also a bespoke visit to the UK and Canada. The success of this bilateral activity and positive impact of the UK-Canada AI challenge on UK exports and innovation has been highlighted in the Industrial Strategy One Year report. In addition, DIT and SIN colleagues in Germany, Singapore, Malaysia and UAE are considering organising similar bilateral activities in post. SIN Canada (Montreal): mario.rivero-huguet@fco.gov.uk'), Document(metadata={'uuid': UUID('10d3b18c-d902-4628-a5a0-bd7e84b5c118'), 'index': 4, 'created_datetime': datetime.datetime(2025, 1, 29, 15, 35, 0, 664466, tzinfo=datetime.timezone.utc), 'chunk_resolution': <ChunkResolution.normal: 'normal'>, 'creator_type': <ChunkCreatorType.gov_uk: 'GOV.UK'>, 'uri': 'https://www.gov.uk/government/publications/ai-opportunities-action-plan', 'token_count': 10317}, page_content=\"The AI Opportunities Action Plan, led by Matt Clifford CBE , tech entrepreneur and Chair of the Advanced Research and Invention Agency ( ARIA ). This document has 50 recommendations for government to: grow the UK’s AI sector drive adoption of AI across the economy to boost growth improve products and services Read the government response to the AI Opportunities Action Plan . The AI Opportunities Action Plan is a roadmap for government to capture the opportunities of AI to enhance growth and productivity and create tangible benefits for UK citizens. Read the terms of reference here . AI Opportunities Action Plan Presented to Parliament by the Secretary of State Science, Innovation and Technology by Command of His Majesty. CP1241 © Crown copyright 2025 ISBN 978-1-5286-5362-6 E03258815 01/25 AI Opportunities Action Plan. Ramping up AI adoption across the UK to boost economic growth, provide jobs for the future and improve people's everyday lives. Foreword by the Secretary of State for Science, Innovation and Technology Today, Britain is the third largest AI market in the world. We are home to an extraordinary array of global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite our record of scientific discovery - from Alan Turing on algorithms and general-purpose computing to Tim Berners-Lee’s World Wide Web - the UK risks falling behind the advances in Artificial Intelligence made in the USA and China. In this next phase of AI development, we want Britain to step up; to shape the AI revolution rather than wait to see how it shapes us. Because we believe Britain has a particular responsibility to provide global leadership in fairly and effectively seizing the opportunities of AI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to commission Matt Clifford to devise an AI Opportunities Action Plan for the British government. This plan shows how we can shape the application of AI within a modern social market economy. We will do so by working closely with the world’s leading AI companies, Britain’s world leading academics and entrepreneurs, and those talented individuals keen to start-up and scale-up their businesses here. Our ambition is to shape the AI revolution on principles of shared economic prosperity, improved public services and increased personal opportunities so that: AI drives the economic growth on which the prosperity of our people and the performance of our public services depend; AI directly benefits working people by improving health care and education and how citizens interact with their government; and the increasing of prevalence of AI in people’s working lives opens up new opportunities rather than just threatens traditional patterns of work. Across government, we have already taken decisive action to support the AI sector and take down the barriers to growth. Our transformative planning reforms will make it easier to build the data centres that are the engines of the AI age. Skills England will help ensure that British people are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of Government I have created in my Department will drive forward the technological transformation of the state, ensuring that public services offer citizens the same seamless experience they can find in the private sector. The recommendations in this plan are unapologetic in their ambition; Government must be the same. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a commitment to real partnership between public and private sectors. There’s no time to waste. Today, we have set out how we will rise to the challenge. The Rt Hon Peter Kyle MP Secretary of State for Science, Innovation and Technology The opportunity AI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence (AI) could be the government’s single biggest lever to deliver its five missions, especially the goal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the ambition for highest sustained growth in the G7 - and the countless quality-of-life benefits that flow from that - without embracing the opportunities of AI. Any national AI plan needs to be founded on a realistic assessment of the country’s strengths and weaknesses. Fortunately, the UK has solid - and in places genuinely world-leading - foundations on which to build: Strong fundamental AI research, and high-quality research and engineering talent coming out of our universities, which are some of the best in the world for AI. A vibrant startup and scaleup scene, with an increasingly skilled and experienced entrepreneurial workforce and growing quantities of sophisticated capital available for ambitious companies. Leading frontier AI companies in London, including Google DeepMind’s headquarters, significant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local winners - such as Wayve, the autonomous vehicle company. Global leadership on AI safety and governance via the AI Safety Institute, and a proportionate, flexible regulatory approach. These are all crucial prerequisites to making the most of AI opportunities; without them, the ambition in this plan would not be credible. However, we cannot be complacent: to remain a world leader we need to lead in both building and using AI. Our goal should be a thriving domestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread use of AI products and services across the economy. The UK’s starting point makes this aspiration plausible, but achieving it will require bold and visionary action. The government must: Invest in the foundations of AI: We need world-class computing and data infrastructure, access to talent and regulation (Section 1). Push hard on cross-economy AI adoption: The public sector should rapidly pilot and scale AI products and services and encourage the private sector to do the same. This will drive better experiences and outcomes for citizens and boost productivity (Section 2). Position the UK to be an AI maker, not an AI taker: As the technology becomes more powerful, we should be the best state partner to those building frontier AI. The UK should aim to have true national champions at critical layers of the AI stack so that the UK benefits economically from AI advancement and has influence on future AI’s values, safety and governance (Section 3). This Action Plan is made up of three sections - one for each of these goals. There are detailed recommendations in each. In making them, I have tried to draw consistently on a small number of core principles: Be on the side of innovators: In every element of the Action Plan, the government should ask itself: does this benefit people and organisations trying to do new and ambitious things in the UK? If not, we will fail to meet our potential. Invest in becoming a great customer: government purchasing power can be a huge lever for improving public services, shaping new markets in AI, and boosting the domestic ecosystem. But doing this well is not easy - it will require real leadership and radical change, especially in procurement. Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal situation. We need the best talent around the world to want to start and scale companies here. If we do that, the best investors globally will want to deploy capital here - both into our startups and our AI infrastructure. Build on UK strengths and catalytic emerging areas: The UK has strong companies in the AI application and integration layers that are well positioned to grow. We also have emerging areas of research and engineering strength - particularly in AI for science and robotics - that could have a transformational impact across the economy, advance AI and unlock further innovation. No one can say with certainty what AI will look like a decade from now. My judgement is that experts, on balance, expect rapid progress to continue. The risks from underinvesting and underpreparing, though, seem much greater than the risks from the opposite. Even if AI progress slows, we will see large benefits from deploying today’s frontier capabilities and investing in our infrastructure and talent base. If, however, capabilities continue to advance, having a stake in - and being the natural home of - advanced AI could be the difference between shaping the future of science, technology and work and seeing these decisions made entirely outside our borders. This is a crucial asymmetric bet - and one the UK can and must make . 1. Lay the foundations to enable AI 1.1 Building sufficient, secure and sustainable AI Infrastructure The foundation of the last decade of AI progress has been an extraordinary and sustained investment in computational power (often called “compute”). AI requires data centres that house the large and complex computers that are used to train AI models and to run ‘inference’ (where AI is used to complete tasks and answer queries). Of course, the UK does not need to own or operate all the compute it will need. Indeed, only a small fraction of our needs will be through such compute (though this fraction is important). A decade from now the economy will almost certainly be more computationally intensive: new high-skill jobs and compute-adjacent industries will have been created and access to compute will be a key pillar of economic security. Countries that enable the build out of AI infrastructure will reap benefits through increased economic growth, the reinvigoration of former industrial sites and ownership of critical strategic assets. The availability of powerful computing resources sends an important signal to academic, technical and entrepreneurial talent and is a critical ingredient of innovation. We should expect enormous improvements in computation over the next decade, both in research and deployment. Having this “learning by doing” happen in the UK is crucial if we want the industries of the future to be built here. The government must therefore secure access to a sufficient supply of compute. There is no precise mechanism to allocate the proportions, but it should consist of: Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK to quickly and independently allocate compute to national priorities. For example, we need the ability to: drive mission-focused AI research; empower academics and startups to train AI models; and ensure access to AI compute for critical services in times of market disruption. Sovereign AI compute will almost certainly be the smallest component of the UK’s overall compute portfolio. NB: this review has not considered the requirements of non-AI high-performance computing, for which there is already a well-established case, including the need to deliver an exascale capability. Government should seek to resolve this as soon as possible, noting that these systems will play a crucial role in supporting AI science and research. Domestic compute, that is based within the UK but privately owned and operated and that will position the UK as a leading AI economy and ensure the UK’s economic security. Due to the criticality of compute for AI, domestic compute will create spillover benefits in the form of jobs, investment and new, AI based, service businesses. In this part of the portfolio, crowding in private and international capital is critical. International compute, accessed via reciprocal agreements and partnerships with like-minded partners, to give the UK access to complementary capabilities and facilitate joint AI research in areas of shared interest. We should proactively develop these partnerships, while also taking an active role in the EuroHPC Joint Undertaking. To achieve this, government should: 1. Set out, within 6 months, a long-term plan for the UK’s AI infrastructure needs, backed by a 10-year investment commitment. Building a world class AI compute ecosystem requires a clear objective and long-term capability and expertise. Government should consider what the most appropriate delivery body is for large scale research infrastructure that is delivered in partnership with universities and industry. We have pockets of deep academic expertise in this space, such as at Edinburgh, Bristol and Cambridge universities, and we should draw on this. A credible plan will consider emerging compute technologies, include investment in software, skills, and wider high-performance computing capabilities to complement our AI compute and enable AI for science. 2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 - starting within 6 months. The AIRR should evolve into a set of mission-oriented clusters that bring together compute, data, and talent to pursue frontier AI research and other national priorities. Expansion by at least 20x by 2030 would ensure the AIRR enables the training of multiple AI models a year and provides an up to date research capability.[footnote 1] Given trends in hardware performance, this would not mean a 20x increase in investment if the government procures smartly.[footnote 2] Such expansion is needed to keep up with the expected increases in computing power that we should assume will be needed for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As part of this, government should ensure that the public compute ecosystem hosts a range of hardware providers to avoid vendor lock-in and ensure value for money. 3. Strategically allocate sovereign compute by appointing mission-focused “AIRR programme directors” with significant autonomy. These could be modelled after the Defense Advanced Research Projects Agency (DARPA) or the Advanced Research and Invention Agency (ARIA) to quickly and independently provide large amounts of compute to high-potential projects of national importance, operating in a way that is strategic and mission driven. Allocation is an essential part of any compute strategy: spreading large amounts of compute thinly will have little impact. We will have to make choices about when to subsidise compute and when to provide it at cost, recognising that this could form part of an attractive offer to entrepreneurs and researchers deciding where to base themselves. 4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI data centres. As AI infrastructure providers seek access to land and power, governments who move quickly and mirror the pace of growth and innovation in the AI data centre market will be best placed to secure investment. AIGZs could introduce a streamlined planning approvals process and accelerate the provisioning of clean power. This is a major opportunity to crowd in private capital to boost our domestic compute portfolio and to build strategic partnerships with AI developers to work on shared AI and AI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, channelling investment into areas with existing energy capacity such as post-industrial towns and coastal Scotland. Government should quickly nominate at least one AIGZ and work with local regions to secure buy-in for further AIGZs that contribute to local needs. Existing government sites could be prioritised as pilots, including Culham Science Centre, the UK Atomic Energy Authority’s headquarters, which has access to significant power and land. Alongside this, government should consider other measures to accelerate buildout of data centres, such as offering central guidance, creating a bespoke planning use-class and considering the case for AI data centres to be eligible for relevant relief schemes that incentivise private sector investment. 5. Mitigate the sustainability and security risks of AI infrastructure, while positioning the UK to take advantage of opportunities to provide solutions. This should focus both on secure private-sector compute as well as collaboration with the UK Intelligence Community. Government should also explore ways to support novel approaches to compute hardware and, where appropriate, create partitions in national supercomputers to support new and innovative hardware. In doing so, government should look to support and partner with UK companies who can demonstrate performance, sustainability or security advancements. 6. Agree international compute partnerships with like-minded countries to increase the types of compute capability available to researchers and catalyse research collaborations. This should focus on building arrangements with key allies, as well as expanding collaboration with existing partners like the EuroHPC Joint Undertaking. 1.2 Unlocking data assets in the public and private sector To fuel both frontier AI progress and high-quality AI applications, developers need access to high-quality data - the lifeblood of modern AI. Data that isn’t in the training sets of current models and encodes new insights about the world is particularly valuable. Public data sets, including scientific data sets, may be extremely important in this context. We should seek to responsibly unlock both public and private data sets to enable innovation by UK startups and researchers and to attract international talent and capital. As part of this, government needs to develop a more sophisticated understanding of the value of the data it holds, how this value can be responsibly realised, and how to ensure the preservation of public trust across all its work to unlock its data assets. The creation of the National Data Library (NDL) presents an enormous opportunity. As it develops the NDL, the government should: 7. Rapidly identify at least 5 high-impact public datasets it will seek to make available to AI researchers and innovators. Prioritisation should consider the potential economic and social value of the data, as well as public trust, national security, privacy, ethics, and data protection considerations. We should explore use of synthetic data generation techniques to construct privacy-preserving versions of highly sensitive data sets. Government data sets are a public asset, and careful consideration should be given to their valuation. 8. Strategically shape what data is collected, rather than just making data available that already exists. Government should look to collect data in strategically significant areas, building on existing UK strengths. For example, the NDL could build on the achievements of the UK Biobank to enhance research in areas such as disease recognition and the prediction of health outcomes. The NDL should run open calls to receive proposals from researchers and industry to propose new data sets. 9. Develop and publish guidelines and best practices for releasing open government datasets which can be used for AI, including on the development of effective data structures and data dissemination methods. 10. Couple compute allocation with access to proprietary data sets as part of an attractive offer to researchers and start-ups choosing to establish themselves in the UK and to unlock innovation. 11. Build public sector data collection infrastructure and finance the creation of new high-value datasets that meet public sector, academia and startup needs. Government should identify how public data will be collected and its quality enhanced, including the use of AI-driven data cleansing tools to curate data sets stored across government, making them suitable for AI developers and researchers. 12. Actively incentivise and reward researchers and industry to curate and unlock private datasets. In particular, the NDL should engage with UKRI to identify how the creation of valuable high-quality data sets that support the research community could be better acknowledged via the Research Excellence Framework. Government should also explore how to shape the market in data set curation, including contributions from the private sector. 13. Establish a copyright-cleared British media asset training data set, which can be licensed internationally at scale. This could be done through partnering with bodies that hold valuable cultural data like the National Archives, Natural History Museum, British Library and the BBC to develop a commercial proposition for sharing their data to advance AI. 1.3 Training, attracting and retaining the next generation of AI scientists and founders If we want the UK to have both world-class AI research and a world-leading AI application ecosystem, we need to be the natural home for elite talent. In the next 5 years, the UK must be prepared to train tens of thousands of additional AI professionals across the technology stack to meet expected demand and proactively increase its share of the world’s top 1,000 AI researchers. In the long-term, government needs to create a deeper pool of AI skills and talent that will build, diffuse and use AI products across the economy.[footnote 3] Setting a short-term target to train tens of thousands of AI professionals by 2030 will help bridge the estimated gap between supply and demand.[footnote 4] This would put the UK in step with countries like France, whose National AI Commission calculates that the number of French AI graduates would need to triple over the next decade to match estimated demand.[footnote 5] As a priority first step, government should: 14. Accurately assess the size of the skills gap. Current estimates are imprecise and outdated; the last government-funded AI labour market survey was in 2020 and the Unit for Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses supply data from 2019.[footnote 6] The success of the following recommendations depends on accurately understanding the skills gap, and so government must make efforts to come to a concrete and up-to-date number. Once the size of the skills gap is confirmed, to reach this target over the next 5 years government should: 15. Support Higher Education Institutions to increase the numbers of AI graduates and teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-relevant higher education programme in the UK. While this is the highest in Europe, with Germany (32,000) second, the UK is behind Finland and others on a per capita basis and there remains unmet demand for skilled workers.[footnote 7] Supporting universities to develop new courses co-designed with industry - such as the successful co-operative education model of Canada’s University of Waterloo, CDTM at the Technical University of Munich or France’s CIFRE PhD model - and increasing their teaching and recruitment capacity would help train the tens of thousands of AI professionals needed by 2030. 16. Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women.[footnote 8] Achieving parity would mean thousands of additional workers. The AI conversion courses have helped to diversify the AI pipeline, but only at the top end. Government should build on this investment and promote diversity throughout the education pipeline. Interventions must be tailored - there is no one-size-fits-all approach. Hackathons and competitions in schools have proven effective at getting overlooked groups into cyber and so should be considered for AI.[footnote 9] 17. Expand education pathways into AI. Higher education is the most common pathway into AI careers and will likely remain so at least until 2030.[footnote 10] To meet the demands of the labour market and the changing skills needs of the future, however, government should encourage and promote alternative domestic routes into the AI profession - including through further education and apprenticeships, as well as employer and self-led upskilling. 18. Launch a flagship undergraduate and masters AI scholarship programme on the scale of Rhodes, Marshall, or Fulbright for students to study in the UK. Open to a diverse initial cohort of 100 scholars from the UK and abroad, the programme would combine financial support, cohort building, industry co-investment, and placements in government or private sector AI organisations. Potential scholars must show exceptional promise, but recognising the broad range of talents needed for success in AI, this could be in a variety of fields, such as strong performance in a leading STEM competition (e.g. the International Mathematical or Informatics Olympiads). 19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the labour market, though exactly how and when is unclear. What is certain is while some jobs will be replaced by AI, many will be augmented - and an unknown number will be created. Government should ensure there are sufficient opportunities for workers to reskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and adopt best practice from other countries who are preparing their skills systems for the long-term impacts of AI. Singapore, for example, developed a national AI skills online platform with multiple training offers. South Korea is integrating AI, data and digital literacy throughout its education pipelines through an AI curriculum and a variety of training and education programmes. Skills England and the independent Curriculum and Assessment Review present an opportunity to consider the merit of such approaches in our system. Alongside these longer-term investments, the government’s priority should be to rapidly increase the number of top AI research talents who work in the UK. These leading AI scientists and engineers are few in number and highly prized globally. The countries that attract them will play an outsized role in the future of AI. It is not surprising that the US, which is the number 1 destination for top talent, has also been at the forefront of recent AI breakthroughs. International competition for top talent is fierce. The UK must go further than existing measures and take a more proactive approach at every stage of the talent pipeline. Though ambitious, these efforts could yield large benefits for the UK if one individual founds the next DeepMind or OpenAI. Within the next year, government should: 20. Establish an internal headhunting capability on a par with top AI firms to bring a small number of elite individuals to the UK. Government should build on the success of the AI Safety Institute in attracting top talent. This may include recruiting more people into AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. Officials will need flexibility to develop specific offers and provide wraparound support to talent targets - recognising that to truly ‘headhunt’ talent the programme will need to be backed by appropriate funding. 21. Explore how the existing immigration system can be used to attract graduates from universities producing some of the world’s top AI talent. Graduates from some leading AI institutions, such as the Indian Institutes of Technology and (since 2020) Carnegie Mellon University in the US, are not currently included in the High Potential Individual visa eligibility list. Government should take steps to develop new pathways, and strengthen existing ones, to support these graduates. It should also explore how best to address wider barriers like the cost and complexity of visas which create obstacles for startups and deter overseas talent from re-locating to the UK.[footnote 11] 22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should be created for specialists in other sectors who wish to develop deep technical skills in AI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading fellowships should be committed to maintain the current cohort size over the next 3 years, as existing fellows graduate from the programme. 1.4 Enabling safe and trusted AI development and adoption through regulation, safety and assurance The UK’s current pro-innovation approach to regulation is a source of strength relative to other more regulated jurisdictions and we should be careful to preserve this. Well-designed and implemented regulation, alongside effective assurance tools, can fuel fast, wide and safe development and adoption of AI. Regulators themselves have an important role in supporting innovation as part of their Growth Duty. Government must protect UK citizens from the most significant risks presented by AI and foster public trust in the technology, particularly considering the interests of marginalised groups. That said, we must do this without blocking the path towards AI’s transformative potential. Ineffective regulation could hold back adoption in crucial sectors like the medical sector, but regulation, safety and assurance have the power to drive innovation and economic growth too, as shown by the success of regulatory sandboxes in supporting fintech startups and the development of the UK’s cyber security industry.[footnote 12] Clear rules provide clarity to businesses so they have the confidence to invest and bring new products and services to market. The government should: 23. Continue to support and grow the AI Safety Institute (AISI) to maintain and expand its research on model evaluations, foundational safety and societal resilience research. AISI is the first safety institute to have conducted pre-deployment evaluations of frontier models and its success is a significant and growing source of international influence for the UK. Continued investment is needed to ensure AISI retains its position as a world-leader and remains attractive to top AI safety researchers. It is also essential to act quickly to provide clarity on how frontier models will be regulated. A top priority of any such regulation should be preserving the capability, trust and collaboration that the AISI has built up since its creation. 24. Reform the UK text and data mining regime so that it is at least as competitive as the EU. The current uncertainty around intellectual property (IP) is hindering innovation and undermining our broader ambitions for AI, as well as the growth of our creative industries. This has gone on too long and needs to be urgently resolved. The EU has moved forward with an approach that is designed to support AI innovation while also enabling rights holders to have control over the use of content they produce. The UK is falling behind. It is also essential that we act now to ensure sector regulators are fit for the age of AI. In particular, government should: 25. Commit to funding regulators to scale up their AI capabilities, some of which need urgent addressing. Government should also ensure all sponsor departments demonstrate how they are funding this capability within their budgets through the Spending Review process. 26. Ensure all sponsor departments include a focus on enabling safe AI innovation in their strategic guidance to regulators. AI will touch every aspect of the economy and so it is essential that all regulators are prioritising understanding its impacts in their domains and considering how best to encourage its safe adoption. 27. Work with regulators to accelerate AI in priority sectors and implement pro-innovation initiatives like regulatory sandboxes. These should be targeted in areas with regulatory challenges but high-growth potential, such as products which integrate AI into the physical world like autonomous vehicles, drones and robotics. 28. Require all regulators to publish annually how they have enabled innovation and growth driven by AI in their sector. To ensure accountability, this should include transparent metrics such as timelines to publish guidance, make licence decisions and report on resources allocated to AI-focused work. Even with these initiatives, individual regulators may still lack the incentives to promote innovation at the scale of the government’s ambition. If evidence demonstrates that is the case, government should consider more radical changes to our regulatory model for AI, for example by empowering a central body with a mandate and higher risk tolerance to promote innovation across the economy. Such a body could have expertise and statutory powers to issue pilot sandbox licences for AI products that override sector regulations, taking on liability for all related risks. This approach could initially be explored and piloted for specific AI applications at small scale. Alongside investing in pro-innovation regulation, the government should: 29. Support the AI assurance ecosystem to increase trust and adoption by: Investing significantly in the development of new assurance tools, including through an expansion to AISI’s systemic AI safety fast grants programme, to support emerging safety research and methods. Building government-backed high-quality assurance tools that assess whether AI systems perform as claimed and work as intended. As part of taking forward the recommendations in this Action Plan, government should: 30. Consider the broader institutional landscape and the full potential of the Alan Turing Institute to drive progress at the cutting edge, support the government’s missions and attract international talent. 2. Change lives by embracing AI 2.1 AI Adoption is core to delivering the government’s missions The adoption of high-performing, trustworthy AI at scale will be critical to the government fulfilling the five missions. AI should become core to how we think about delivering services, transforming citizens’ experiences, and improving productivity. As well as strengthening the foundations - data, skills, talent, IP, and assurance measures set out above - government should also focus on its role as a major user and customer of AI and how it uses its powers to catalyse private sector adoption: Adoption missions Though we are still early in the development of the AI application layer - and all AI use should be tailored appropriately to the specific setting or sector in which it will be deployed. For example, AI use in health and care will raise different considerations than in advanced manufacturing. Indeed there are already great examples of AI use-cases driving tangible benefits across the private and public sectors: Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an employee’s time.[footnote 13] For example, it is helping some teachers cut down the 15+ hours a week they spend on lesson planning and marking in pilots. Drafting structured reports and forms with AI can cut final document production times by 20-80% in professional services.[footnote 14] Trials are underway exploring how these methods can save time for clinical practitioners in the NHS. Automated threat and anomaly detection is already being responsibly deployed by police forces across the country and used to clean up social media. Assessment and diagnosis can be improved through the use of AI. For example, through the £21 million AI Diagnostics fund, Department for Health and Social Care (DHSC) is supporting the deployment of technologies in key, high-demand areas such as chest X-Ray and chest CT scans to enable faster diagnosis and treatment of lung cancer in over half of acute trusts in England. Assessments can be done better, cheaper, and more quickly across multiple sectors. We also anticipate that AI will be a useful tool for assessment in the education sector. For example, the Department for Education’s generative AI and rules-based marking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when drawing from appropriately coded educational data and content.[footnote 15] 2.2 Adopt a “Scan > Pilot > Scale” approach in government While there are instances of AI being used well across the public sector, often they are at small scale and in silos. Scaling these successes is essential, but will require us to think differently about procurement, especially if this activity is to support the domestic startup and innovation ecosystem. As the digital centre of government, DSIT should support public sector partners where needed to “move fast and learn things”. Government should generally employ a flexible “Scan > Pilot > Scale” approach. Scan Investing in building a deep and continually updated understanding of AI capabilities mapped to their highest impact challenges and opportunities. This will require: 31. Appointing an AI lead for each mission to help identify where AI could be a solution within the mission setting, considering the user needs from the outset. 32. A cross government, technical horizon scanning and market intelligence capability who understands AI capabilities and use-cases as they evolve to work closely with the mission leads and maximise the expertise of both. 33. Two-way partnerships with AI vendors and startups to anticipate future AI developments and signal public sector demand. This would involve government meeting product teams to understand upcoming releases and shape development by sharing their challenges. Pilot Rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-impact areas, robust evaluation and publishing results. This will require: 34. Consistent use of a framework for how to source AI - whether to build in-house, buy, or run innovation challenges - that evolves over time, given data, capability, industry contexts and evaluation of what’s worked. Where appropriate, the government should support open-source solutions that can be adopted by other organisations and design processes with startups and other innovators in mind. 35. A rapid prototyping capability that can be drawn on for key projects where needed, including technical and delivery resource to build and test proof of concepts, leveraging in-house AI expertise, together with specialists in design and user experience. 36. Specific support to hire external AI talent. Creation of a technical senior civil servant stream, benchmarking of internal AI-related role pay to at least 75% of private-sector rate and a technical AI recruitment screening process.[footnote 16] 37. A data-rich experimentation environment including a streamlined approach to accessing data sets, access to language models and necessary infrastructure like compute. 38. A faster, multi-stage gated and scaling AI procurement process that enables easy and quick access to small-scale funding for pilots and only layers bureaucratic controls as the investment-size gets larger. Multi-staged “Competitive Flexible Procedures” should be encouraged, and startups compensated for the rounds they make it through.[footnote 17] Scale Identifying successful pilots that can be applied in different settings to support citizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and rolling them out beyond organisational boundaries. Scale is essential if AI is to have a meaningful impact on productivity, effectiveness and citizen experience, as well as maximising government spending power. Moreover, doing this well and procuring in a way that benefits innovators is a powerful lever for upending the cliché that the UK is good at invention, but poor at commercialisation. It will require: 39. A scaling service for successful pilots with senior support and central funding resource. The government should support a select number of proven pilots to scale - with central finance and tools available to avoid fragmentation across systems and budgets - and achieve up to national level reach. 40. Mission-focussed national AI tenders to support rapid adoption across de-centralised systems led by the mission delivery boards. An example of tendering to enable scale is the NHS’s AI Diagnostic Fund allocating £21 million to twelve imaging networks, covering 66 NHS trusts across England, significantly speeding up the roll out of AI diagnostic tools nationwide.[footnote 18] However, these tenders should be designed to encourage new entrants, avoiding reliance on commercial frameworks where possible. 41. Development or procurement of a scalable AI tech stack that supports the use of specialist narrow and large language models for tens or hundreds of millions of citizen interactions across the UK. 42. Mandating infrastructure interoperability, code reusability and open sourcing. The AI infrastructure choice at-scale should be standardised, tools should be built with reusable modular code components, and code-base open-sourcing where possible. 2.3 Enable public and private sectors to reinforce each other The public and private sectors should play mutually reinforcing roles in AI adoption. To get the most from working together, government should: 43. Procure smartly from the AI ecosystem as both its largest customer and as a market shaper. Innovative AI suppliers from the UK and around the world should be engaged to support demand and encourage investment. Procurement contract terms should set standards (e.g. quality), requirements, and best practice (e.g. performance evaluations). “Contemplation” clauses should be included in contracts to ensure the government remains agile to a rapidly changing AI ecosystem by mandating that contractors regularly assess and adopt newer technologies. 44. Use digital government infrastructure to create new opportunities for innovators. For example, an approach akin to Jeff Bezos’s API mandate at Amazon could be adopted. This required all teams’ data and functionality to be exposed through APIs (Application Programme Interfaces). All standard documentation interactions, like compliance or planning, could be done through APIs, to which companies could connect their own tools. Similarly, mandating e-Invoices from government suppliers could automate billing, speed up payments and reduce fraud. 45. Publish best-practice guidance, results, case-studies and open-source solutions through a single “AI Knowledge Hub” accessible to technical and non-technical users across private and public sectors as a single place to access frameworks and insights. 46. In the next 3 months, the Digital Centre of Government should identify a series of quick wins to support the adoption of the scan, pilot scale approach and enable public and private sector to reinforce each other. 2.4 Address private-sector-user-adoption barriers AI adoption could grow the UK economy by an additional £400 billion by 2030 through enhancing innovation and productivity in the workplace.[footnote 19] Safe, effective and swift AI adoption has the potential to enhance the international competitiveness of sectors of UK strength and unlock new growth opportunities across the whole economy, including for SMEs. To capture the benefits of AI adoption across the private sector, the government should: 47. Leverage the new Industrial Strategy. The development of a new Industrial Strategy presents an opportunity to drive collective action to support AI adoption across the economy. The Industrial Strategy will need to set out how AI adoption can best be supported in key industries, noting particular use cases that could boost productivity and present a particular competitive advantage while also identifying possible regulatory barriers and specific skills needs that need to be addressed. DSIT and others with AI expertise within government can play a critical role in combining with those who have a deep understanding of their sectors to engage business leaders, identify high-potential use cases, co-design targeted interventions to promote them and overcome barriers to adopting them. 48. Appoint AI Sector Champions in key industries like the life sciences, financial services and the creative industries to work with industry and government and develop AI adoption plans. 49. Drive AI adoption across the whole country. Widespread adoption of AI can address regional disparities in growth and productivity. To achieve this, government should leverage local trusted intermediaries and trade bodies to support business leaders, and also consider opportunities to accelerate AI adoption by working across supply chains. A particular focus should be put on supporting SMEs and the specific challenges they face. 3. Secure our future with homegrown AI By the end of the decade, having national champions at the frontier of AI capabilities may be a critical pillar of our national and economic security. Government should use the full powers it has available to ensure this happens. AI systems are increasingly matching or surpassing humans across a range of tasks. Today’s AI systems have many limitations, but industry is investing at a scale that assumes capabilities will continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing power than in 2019, and we are likely to see a similar rate of growth by 2029. If progress continues at the rate of the last 5 years, by 2029 we can expect AI to be a dominant factor in economic performance and national security. Many of us have become familiar with the remarkable capabilities of large language models across a broad set of domains. Leading AI companies continue to push this frontier, and we are also seeing stunning progress in other modalities, including breakthroughs in video and image generation, robotics, mathematics, and scientific discovery. To take one example, DeepMind’s AlphaFold - which predicts protein structures - is estimated to have saved the equivalent of 400 million years of researcher time. We can imagine the impact on science, medicine and the broader economy if we see this sort of success in other domains. Given the pace of progress, we will also very soon see agentic systems - systems that can be given an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with are just an early glimpse as to what is possible. The economic consequences of continued progress in these areas could be enormous. Just as with previous technological revolutions, the people and countries who make decisions about how these systems operate and what values they reflect - including their approach to safety - will have huge influence over our lives. If this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies at the frontier that will be our UK national champions. We have all the raw ingredients to make this possible. AI research and product development is a UK strength rooted in world-class engineering talent coming out of our excellent universities and local AI winners such as DeepMind and Wayve. Our position between the US and Europe, and convenient time-zone, make the UK an ideal place for international founders to collaborate. Section 1 and Section 2 of this Action Plan above are critical to building on this. Section 1 covered the policy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered the policies needed for widespread AI adoption - a necessary condition for a world-leading AI application ecosystem. We should assume that most advanced economies will soon be doing much of the above. If we aspire to be one of the biggest winners from AI and drive national renewal, we need to go further. Given the lead the current frontier firms enjoy, we cannot expect the market to solely underwrite a new challenger, especially in the next 2 to 3 years. But government holds critical levers for the next stage of AI development. Generating national champions will require a more activist approach and something more akin to Japan’s MITI or Singapore’s Economic Development Board in the 1960s, not the “invisible hand”. The government must maximise its ambition and ensure the UK has national champions at the frontier of economically and strategically important capabilities. This means government needs to: Ensure that research and development of frontier AI capabilities takes place in the UK - both in the current foundation model paradigm and in emerging spaces such as AI for science, robotics, and “embodied AI”. Ensure that the UK maximises both its economic upside from and influence on these capabilities as they advance. Achieving this will require bold, concerted and coherent action, using all the levers of the state to make the UK the best place in the world to build and scale frontier AI companies. While I don’t want to understate how difficult this will be, I am confident that with the right focus and backing, the UK can do this. To this end, the government should: 50. Create a new unit, UK Sovereign AI, with the power to partner with the private sector to deliver the clear mandate of maximising the UK’s stake in frontier AI. Public-private collaboration will be at the heart of this unit. It will support the private and academic sectors in doing what they do best, with the ability to collaborate internationally, create joint ventures, as well as invest in, incubate and spin out AI companies - refining its strategy and approach as the technology matures. To achieve this, the unit must develop a clear position on which areas of AI research are strategically important for the future of the technology and make concentrated bets in these areas. This could involve supporting entrepreneurs to create new companies, backing startups to scale or partnering with existing AI companies that are already at the frontier to maximise the UK’s upside however the technology develops. With a clear and powerful mandate the unit will play a critical coordinating role, able to remove barriers and make deals to maximise the UK’s chance of growing globally competitive national champions. It will need to be able to draw on the resources of government to act quickly and decisively. If it is to succeed, it will require support from other government organisations. Especially important will be Innovate UK, which should make AI a top priority and support the unit through the funding it provides to promising start-ups. Early tolerance for scientific and technical risk can be hugely valuable. For example, the unit or its public sector partners might join funding rounds or provide advanced market commitments to credible and ambitious startups in emerging fields of AI. AI for science is an area with the potential to be particularly important because of its economic value and security implications; the UK’s existing talent strengths; and the particularly high value of the state’s assets in this space. The use of these non-financial assets, alongside capital and procurement, will be critical to the unit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and existing frontier AI companies that includes: Direct investment into companies, including promising start-ups as well as joint ventures with other commercial partners. Delivering appropriate sites for compute in the UK, including through AI Growth Zones, and international partnerships to guarantee compute access from appropriate allies. Packaging and providing responsible access to the most valuable UK-owned data sets and relevant research. Supporting UK-based AI organisations working on national priority projects to bring in overseas talent and headhunting promising founders or CEOs (and their teams) by convincing them to relocate to the UK. Facilitating deep collaboration with the national security community. In exchange, UK Sovereign AI should ensure economic upside from, and influence on, governance of frontier AI for the UK. AI may well be the most important technology of our time. Now is the moment to act boldly and with vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. Conclusion The Action Plan I have set out will require the government to both take a long-term view and take action immediately. It will need to commit to securing the physical infrastructure and human capital that will underpin all future AI developments. Government should also have the self-confidence and ambition to set an example for the rest of the economy. This will require a novel approach involving close collaboration with industry to ensure the whole of society can benefit from the opportunities offered by AI. Business-as-usual is not an option. Instead, government will need to be prepared to absorb some risk in the context of uncertainty. This will require a whole of government commitment, with senior and visible leadership and a relentless focus on driving progress. This is no small task. Nevertheless, the benefits are likely to be transformational, not just to support economic growth, but to people’s lives across the whole of the UK. Assumes compute requirements continue to grow at 4x per year. ↩ Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more FLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase in investment. ↩ Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition’, 2010. ↩ Based on internal DSIT estimates. ↩ French Government, ‘25 Recommendations for AI in France’, 2024. ↩ Ipsos Mori ‘Understanding the UK AI labour market’, 2020; Unit for Future Skills, ‘Jobs and skills dashboard’, 2023. ↩ Stanford AI Index, ‘AI Index Annual Report’, 2024. ↩ The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed 15 October 2024) ↩ Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed 15 October 2024) ↩ Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024) ↩ Startup Coalition, ‘Startup Manifesto 2024’, 2024. ↩ NHS England, ‘AI Regulation’, 2022. Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 (revised 2023). DSIT, ‘Cyber security sectoral analysis 2024’, 2024. ↩ Business leader interviews, August 2024 ↩ Business leader interviews, August 2024 ↩ Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for Generative AI feedback and resource generation in education contexts: Technical report’, 2024 (accessed 03 December 2024) ↩ Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 October 2024) ↩ Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) ↩ NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) ↩ Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) ↩\")]),\n",
      "              AIMessage(content=\"<search_quality_reflection>\\nThe documents provided give a good overview of the UK government's perspective and efforts around promoting AI development and adoption. The National AI Strategy lays out a comprehensive vision and plan across areas like research, skills, data, compute infrastructure, governance, and sector adoption. The other reports and publications provide additional details and examples of specific initiatives, challenges, and opportunities.\\n\\nHowever, the information is focused primarily on the government's policies, strategies and programs. To fully assess the impact of AI on UK jobs, I would need more data and analysis from other sources as well, such as:\\n\\n- Economic/labor market studies quantifying the actual impact of AI on employment levels, job loss/creation across different sectors and occupations, wage impacts, etc. The government reports touch on anticipated impacts but lack concrete data.\\n\\n- Business surveys or case studies looking at how UK companies across industries are actually adopting and being impacted by AI in areas like automation, productivity, workforce needs, etc.\\n\\n- Research on how AI is changing required workforce skills and how well the education/training system is adapting to produce workers with AI/data science capabilities.\\n\\n- Analysis of differential impacts across demographics, skill levels, geographies, etc. And how policies may need to address inequities.\\n\\n- Projections and scenarios for how more advanced/general AI systems could reshape labor markets in the future as the technology matures.\\n\\nSo in summary, the provided information gives good insight into the government's perspective and efforts, but does not comprehensively cover and quantify the actual realized impacts of AI on UK jobs and workforce to date. Additional third-party research and data would be needed to fully assess that topic.\\n</search_quality_reflection>\\n\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nThe UK government recognizes the potentially transformative impact of AI on the economy and workforce, and has developed a comprehensive National AI Strategy to shape that transition. Key elements of the strategy related to jobs and labor markets include:\\n\\nSkills and Talent Development:\\n- Increasing the number of AI graduates through support for university AI programs and conversion courses. Goal of training tens of thousands of new AI professionals by 2030.\\n- Promoting diversity and alternative education pathways like apprenticeships into AI fields.\\n- Ensuring the skills system can adapt to provide AI and data literacy for the broader workforce as roles are augmented by AI.\\n- Attracting top global AI talent to the UK through programs like a flagship AI scholarship program and enhanced visa routes.\\n\\nSupporting AI Adoption Across the Economy:\\n- Helping businesses across sectors identify high-impact AI use cases and overcome barriers to adoption through interventions like regulatory sandboxes.\\n- Central government itself scaling up adoption of AI technologies to improve public services and operations.\\n- Public procurement used as a lever to drive AI adoption by purchasing from innovative AI suppliers.\\n\\nGrowing the UK AI Industry:\\n- Enabling sufficient AI research and compute infrastructure to drive innovation.\\n- Improving access to data assets and responsible data sharing to fuel AI development.\\n- Regulatory approaches like the AI Assurance ecosystem to build trust in AI systems.\\n- New initiatives like the UK Sovereign AI unit to partner with the private sector and maximize the UK's stake in frontier/transformative AI capabilities.\\n\\nHowever, the reports do not provide comprehensive data on the actual impacts realized so far on UK employment levels, job turnover, wage impacts, etc. While acknowledging AI's potential to augment and displace jobs, the strategy focuses more on proactive positioning than reacting to current effects.\\n\\nAdditional third-party research would be needed to quantify realized impacts across sectors, skill levels, demographics, and geographies to date. The strategy aims to steer the UK into a leading position in an AI-enabled economy, but the effects on jobs and workforce adaptation will require ongoing study as AI capabilities advance.\\n</result>\", additional_kwargs={'usage': {'prompt_tokens': 62109, 'completion_tokens': 831, 'total_tokens': 62940}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 62109, 'completion_tokens': 831, 'total_tokens': 62940}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-daf32ea9-4e40-4636-848c-5669b2f29f2d-0', usage_metadata={'input_tokens': 62109, 'output_tokens': 831, 'total_tokens': 62940})],\n",
      " 'request': {'ai_settings': AISettings(context_window_size=128000, llm_max_tokens=1024, max_document_tokens=1000000, self_route_enabled=False, map_max_concurrency=128, stuff_chunk_context_ratio=0.75, recursion_limit=50, system_info_prompt='You are Redbox, an AI assistant to civil servants in the United Kingdom.', persona_info_prompt='You follow instructions and respond to queries accurately and concisely, and are professional in all your interactions with users.', caller_info_prompt='', chat_system_prompt='You are tasked with providing information objectively and responding helpfully to users', chat_question_prompt='{question}\\n=========\\n Response: ', chat_with_docs_system_prompt='You are tasked with providing information objectively and responding helpfully to users using context from their provided documents', chat_with_docs_question_prompt='Question: {question}. \\n\\n Documents: \\n\\n {formatted_documents} \\n\\n Answer: ', chat_with_docs_reduce_system_prompt='You are tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the answer is easy to understand,\\n4) Maintain the original context and meaning.\\n', self_route_system_prompt=\"Given the list of extracted parts of long documents and a question, answer the question if possible.\\nIf the question cannot be answered respond with only the word 'unanswerable' \\nIf the question can be answered accurately from the documents given then give that response \\n\", retrieval_system_prompt='Your task is to answer user queries with reliable sources.\\n**You must provide the citations where you use the information to answer.**\\nUse UK English spelling in response.\\nUse the document `creator_type` as `source_type` if available.\\n\\n', retrieval_question_prompt='{question} \\n=========\\n{formatted_documents}\\n=========\\nFINAL ANSWER: ', agentic_retrieval_system_prompt='You are an advanced problem-solving assistant. Your primary goal is to carefully analyse and work through complex questions or problems. You will receive a collection of documents (all at once, without any information about their order or iteration) and a list of tool calls that have already been made (also without order or iteration information). Based on this data, you are expected to think critically about how to proceed.\\n\\nObjective:\\n1. Examine the available documents and tool calls:\\n- Evaluate whether the current information is sufficient to answer the question.\\n- Consider the success or failure of previous tool calls based on the data they returned.\\n- Hypothesise whether new tool calls might bring more valuable information.\\n\\n2. Decide whether you can answer this question:\\n- If additional tool calls are likely to yield useful information, make those calls.\\n- If the available documents are sufficient to proceed, provide an answer\\nYour role is to think deeply before taking any action. Carefully weigh whether new information is necessary or helpful. Only take action (call tools or providing and answer) after thorough evaluation of the current documents and tool calls.', agentic_retrieval_question_prompt='{question}', agentic_give_up_system_prompt='You are an expert assistant tasked with answering user questions based on the provided documents and research. Your main objective is to generate the most accurate and comprehensive answer possible from the available information. If the data is incomplete or insufficient for a thorough response, your secondary role is to guide the user on how they can provide additional input or context to improve the outcome.\\n\\nYour instructions:\\n\\n1. **Utilise Available Information**: Carefully analyse the provided documents and tool outputs to form the most detailed response you can. Treat the gathered data as a comprehensive resource, without regard to the sequence in which it was gathered.\\n2. **Assess Answer Quality**: After drafting your answer, critically assess its completeness. Does the information fully resolve the user’s question, or are there gaps, ambiguities, or uncertainties that need to be addressed?\\n3. **When Information Is Insufficient**:\\n   - If the answer is incomplete or lacks precision due to missing information, **clearly      state the limitations** to the user.\\n   - Be specific about what is unclear or lacking and why it affects the quality of the answer.\\n\\n4. **Guide the User for Better Input**:\\n   - Provide **concrete suggestions** on how the user can assist you in refining the answer.      This might include:\\n     - Sharing more context or specific details related to the query.\\n     - Supplying additional documents or data relevant to the topic.\\n     - Clarifying specific parts of the question that are unclear or open-ended.\\n   - The goal is to empower the user to collaborate in improving the quality of the final      answer.\\n\\n5. **Encourage Collaborative Problem-Solving**: Always maintain a constructive and proactive tone, focusing on how the user can help improve the result. Make it clear that your objective is to provide the best possible answer with the resources available.\\n\\nRemember: While your priority is to answer the question, sometimes the best assistance involves guiding the user in providing the information needed for a complete solution.', agentic_give_up_question_prompt='{question}', condense_system_prompt=\"Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \\n\", condense_question_prompt='{question}\\n=========\\n Standalone question: ', chat_map_system_prompt='Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', chat_map_question_prompt='Question: {question}. \\n Documents: \\n {formatted_documents} \\n\\n Answer: ', reduce_system_prompt='Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \\n1) Identify and highlight key points,\\n2) Avoid repetition,\\n3) Ensure the summary is easy to understand,\\n4) Maintain the original context and meaning.\\n', rag_k=30, rag_num_candidates=10, rag_gauss_scale_size=3, rag_gauss_scale_decay=0.5, rag_gauss_scale_min=1.1, rag_gauss_scale_max=2.0, elbow_filter_enabled=False, match_boost=1.0, match_name_boost=2.0, match_description_boost=0.5, match_keywords_boost=0.5, knn_boost=2.0, similarity_threshold=0.7, chat_backend=ChatLLMBackend(name='anthropic.claude-3-sonnet-20240229-v1:0', provider='bedrock', description=None), tool_govuk_retrieved_results=100, tool_govuk_returned_results=5),\n",
      "             'chat_history': [],\n",
      "             'permitted_s3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'question': 'What is the impact of AI on UK jobs?',\n",
      "             's3_keys': ['natasha.boyse@digital.trade.gov.uk/The_impact_of_AI_on_UK_jobs_and_training_report2.pdf'],\n",
      "             'user_uuid': UUID('b773f752-2b85-4c47-a9e1-6afea14052a1')}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<search_quality_reflection>\n",
      "The documents provided give a good overview of the UK government's perspective and efforts around promoting AI development and adoption. The National AI Strategy lays out a comprehensive vision and plan across areas like research, skills, data, compute infrastructure, governance, and sector adoption. The other reports and publications provide additional details and examples of specific initiatives, challenges, and opportunities.\n",
      "\n",
      "However, the information is focused primarily on the government's policies, strategies and programs. To fully assess the impact of AI on UK jobs, I would need more data and analysis from other sources as well, such as:\n",
      "\n",
      "- Economic/labor market studies quantifying the actual impact of AI on employment levels, job loss/creation across different sectors and occupations, wage impacts, etc. The government reports touch on anticipated impacts but lack concrete data.\n",
      "\n",
      "- Business surveys or case studies looking at how UK companies across industries are actually adopting and being impacted by AI in areas like automation, productivity, workforce needs, etc.\n",
      "\n",
      "- Research on how AI is changing required workforce skills and how well the education/training system is adapting to produce workers with AI/data science capabilities.\n",
      "\n",
      "- Analysis of differential impacts across demographics, skill levels, geographies, etc. And how policies may need to address inequities.\n",
      "\n",
      "- Projections and scenarios for how more advanced/general AI systems could reshape labor markets in the future as the technology matures.\n",
      "\n",
      "So in summary, the provided information gives good insight into the government's perspective and efforts, but does not comprehensively cover and quantify the actual realized impacts of AI on UK jobs and workforce to date. Additional third-party research and data would be needed to fully assess that topic.\n",
      "</search_quality_reflection>\n",
      "\n",
      "<search_quality_score>4</search_quality_score>\n",
      "\n",
      "<result>\n",
      "The UK government recognizes the potentially transformative impact of AI on the economy and workforce, and has developed a comprehensive National AI Strategy to shape that transition. Key elements of the strategy related to jobs and labor markets include:\n",
      "\n",
      "Skills and Talent Development:\n",
      "- Increasing the number of AI graduates through support for university AI programs and conversion courses. Goal of training tens of thousands of new AI professionals by 2030.\n",
      "- Promoting diversity and alternative education pathways like apprenticeships into AI fields.\n",
      "- Ensuring the skills system can adapt to provide AI and data literacy for the broader workforce as roles are augmented by AI.\n",
      "- Attracting top global AI talent to the UK through programs like a flagship AI scholarship program and enhanced visa routes.\n",
      "\n",
      "Supporting AI Adoption Across the Economy:\n",
      "- Helping businesses across sectors identify high-impact AI use cases and overcome barriers to adoption through interventions like regulatory sandboxes.\n",
      "- Central government itself scaling up adoption of AI technologies to improve public services and operations.\n",
      "- Public procurement used as a lever to drive AI adoption by purchasing from innovative AI suppliers.\n",
      "\n",
      "Growing the UK AI Industry:\n",
      "- Enabling sufficient AI research and compute infrastructure to drive innovation.\n",
      "- Improving access to data assets and responsible data sharing to fuel AI development.\n",
      "- Regulatory approaches like the AI Assurance ecosystem to build trust in AI systems.\n",
      "- New initiatives like the UK Sovereign AI unit to partner with the private sector and maximize the UK's stake in frontier/transformative AI capabilities.\n",
      "\n",
      "However, the reports do not provide comprehensive data on the actual impacts realized so far on UK employment levels, job turnover, wage impacts, etc. While acknowledging AI's potential to augment and displace jobs, the strategy focuses more on proactive positioning than reacting to current effects.\n",
      "\n",
      "Additional third-party research would be needed to quantify realized impacts across sectors, skill levels, demographics, and geographies to date. The strategy aims to steer the UK into a leading position in an AI-enabled economy, but the effects on jobs and workforce adaptation will require ongoing study as AI capabilities advance.\n",
      "</result>\n"
     ]
    }
   ],
   "source": [
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMITATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop criteria hasn't been implemented and might cause GraphRecursionError. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
