from typing import Dict

from pydantic import BaseModel, Field

from redbox.chains.parser import BaseCumulativeTransformOutputParser, ClaudeParser
from redbox.models import prompts
from redbox.models.settings import ChatLLMBackend


class PromptVariable(BaseModel):
    """
    This data class for storing variables that are used in the prompt template.
    """

    task: bool = Field(description="Task information", default=False)
    expected_output: bool = Field(description="Expected output from a task", default=False)
    metadata: bool = Field(
        description="User uploaded file metadata containing file name, description, and keywords", default=False
    )
    chat_history: bool = Field(description="User chat history", default=False)
    question: bool = Field(description="User question", default=False)
    document_filenames: bool = Field(description="User selected document file names", default=False)
    format_instructions: bool = Field(description="Format instruction for structured output", default=False)
    previous_plan: bool = Field(description="Previous plan generated by planner", default=False)
    user_feedback: bool = Field(description="User feedback prompt", default=False)
    agents_results: bool = Field(description="Information from other agents", default=False)
    formatted_documents: bool = Field(description="Document content", default=False)
    previous_tool_error: bool = Field(description="Message from previous tool error", default=False)
    previous_tool_results: bool = Field(description="Results from previous tool call", default=False)
    knowledge_base_metadata: bool = Field(description="Knowledge base files metadata", default=False)


class PromptConfig(BaseModel):
    """
    This data class is for capturing prompt config
    """

    system: str = Field(description="Sytem prompt")
    question: str = Field(description="Question prompt", default="")
    format: str = Field(description="Prompt used for format instruction", default="")
    prompt_vars: PromptVariable = Field(description="Variables that are used in the prompt", default=PromptVariable())

    @property
    def get_prompt(self):
        return self.system + "\n" + self.question + "\n" + self.format


# This dict is for storing prompt configs for all the agents.
prompt_configs: Dict[str, PromptConfig] = {
    "Planner_Agent": PromptConfig(
        system=prompts.PLANNER_PROMPT_TOP,  # the refactor will need to add PLANNER_PROMPT_BOTTOM
        question=prompts.PLANNER_QUESTION_PROMPT,
        format=prompts.PLANNER_FORMAT_PROMPT,
        prompt_vars=PromptVariable(
            chat_history=True,
            question=True,
            document_filenames=True,
            metadata=True,
            format_instruction=True,
            knowledge_base_metadata=True,
        ),
    ),
    "Replanner_Agent": PromptConfig(
        system=prompts.REPLAN_PROMPT,
        question=prompts.PLANNER_QUESTION_PROMPT,
        format=prompts.PLANNER_FORMAT_PROMPT,
        prompt_vars=PromptVariable(
            previous_plan=True,
            user_feedback=True,
            question=True,
            document_filenames=True,
            metadata=True,
            format_instruction=True,
            knowledge_base_metadata=True,
        ),
    ),
    "Internal_Retrieval_Agent": PromptConfig(
        system=prompts.INTERNAL_RETRIEVAL_AGENT_PROMPT + prompts.METADATA,
        prompt_vars=PromptVariable(task=True, expected_output=True, metadata=True),
    ),
    "External_Retrieval_Agent": PromptConfig(
        system=prompts.EXTERNAL_RETRIEVAL_AGENT_PROMPT,
        prompt_vars=PromptVariable(task=True, expected_output=True),
    ),
    "Web_Search_Agent": PromptConfig(
        system=prompts.WEB_SEARCH_AGENT_PROMPT,
        prompt_var=PromptVariable(task=True, expected_output=True),
    ),
    "Legislation_Search_Agent": PromptConfig(
        system=prompts.LEGISLATION_SEARCH_AGENT_PROMPT,
        prompt_var=PromptVariable(task=True, expected_output=True),
    ),
    "Summarisation_Agent": PromptConfig(
        system=prompts.CHAT_WITH_DOCS_SYSTEM_PROMPT,
        question=prompts.CHAT_WITH_DOCS_QUESTION_PROMPT,
        prompt_vars=PromptVariable(question=True, formatted_documents=True),
    ),
    "Tabular_Agent": PromptConfig(
        system=prompts.TABULAR_PROMPT,
        question=prompts.TABULAR_QUESTION_PROMPT,
        prompt_vars=PromptVariable(question=True, formatted_documents=True),
    ),
    "Evaluator_Agent": PromptConfig(
        system=prompts.NEW_ROUTE_RETRIEVAL_SYSTEM_PROMPT,
        question=prompts.NEW_ROUTE_RETRIEVAL_QUESTION_PROMPT,
        format=prompts.CITATION_PROMPT,
        prompt_vars=PromptVariable(agents_results=True, question=True, format_instructions=True),
    ),
    "Submission_Checker_Agent": PromptConfig(
        system=prompts.SUBMISSION_PROMPT,
        prompt_vars=PromptVariable(
            task=True,
            expected_output=True,
            chat_history=True,
            question=True,
            metadata=True,
            previous_tool_error=True,
            previous_tool_results=True,
        ),
    ),
    "Submission_Question_Answer_Agent": PromptConfig(
        system=prompts.SUBMISSION_QA_PROMPT,
        prompt_vars=PromptVariable(
            task=True,
            expected_output=True,
            chat_history=True,
            question=True,
            metadata=True,
            previous_tool_error=True,
            previous_tool_results=True,
        ),
    ),
    "Datahub_Agent": PromptConfig(
        system=prompts.DATAHUB_PROMPT,
        question=prompts.DATAHUB_QUESTION_PROMPT,
        prompt_vars=PromptVariable(question=True)),
    "Knowledge_Base_Retrieval_Agent": PromptConfig(
        system=prompts.INTERNAL_RETRIEVAL_AGENT_PROMPT + prompts.KNOWLEDGE_BASE_METADTA,
        prompt_vars=PromptVariable(task=True, expected_output=True, knowledge_base_metadata=True),
    ),
}


class AgentConfig(BaseModel):
    name: str = Field(description="Name of agent")
    description: str = Field(description="Agent desciption used for planning", default="")
    prompt: PromptConfig = Field(description="Prompts used for this agent")
    tools: list = Field(description="A set of tools available for this agent", default_factory=list)
    agents_max_tokens: int = Field(
        description="Maximum tokens for this agent. Response exceed this limit will be truncated.", default=5000
    )
    llm_backend: ChatLLMBackend | None = Field(
        description="The LLM backend model used by the agent. Use None for default model", default=None
    )
    parser: BaseCumulativeTransformOutputParser | None = Field(description="Parser for structured output", default=None)
    default_agent: bool = Field(description="Is this a default redbox worker agents", default=False)


# This dict is for storing agent configs for all the agents.
agent_configs: Dict[str, AgentConfig] = {
    "Planner_Agent": AgentConfig(
        name="Planner_Agent",
        description="Create a plan consisting of a list of tasks to achieve user request",
        prompt=prompt_configs["Planner_Agent"],
        parser=ClaudeParser(),
    ),
    "Replanner_Agent": AgentConfig(
        name="Replanner_Agent",
        description="Re-create a plan consisting of a list of tasks to achieve user request",
        prompt=prompt_configs["Replanner_Agent"],
        parser=ClaudeParser(),
    ),
    "Internal_Retrieval_Agent": AgentConfig(
        name="Internal_Retrieval_Agent",
        description=prompts.INTERNAL_RETRIEVAL_AGENT_DESC,
        prompt=prompt_configs["Internal_Retrieval_Agent"],
        agents_max_tokens=10000,
        parser=None,
        default_agent=True,
    ),
    "External_Retrieval_Agent": AgentConfig(
        name="External_Retrieval_Agent",
        description=prompts.EXTERNAL_RETRIEVAL_AGENT_DESC,
        prompt=prompt_configs["External_Retrieval_Agent"],
        parser=None,
        default_agent=True,
        agents_max_tokens=5000,
    ),
    "Web_Search_Agent": AgentConfig(
        name="Web_Search_Agent",
        description=prompts.WEB_SEARCH_AGENT_DESC,
        prompt=prompt_configs["Web_Search_Agent"],
        parser=None,
        default_agent=True,
        agents_max_tokens=10000,
    ),
    "Legislation_Search_Agent": AgentConfig(
        name="Legislation_Search_Agent",
        description=prompts.LEGISLATION_SEARCH_AGENT_DESC,
        prompt=prompt_configs["Legislation_Search_Agent"],
        parser=None,
        default_agent=True,
        agents_max_tokens=10000,
    ),
    "Summarisation_Agent": AgentConfig(
        name="Summarisation_Agent",
        description=prompts.SUMMARISATION_AGENT_DESC,
        prompt=prompt_configs["Summarisation_Agent"],
        parser=ClaudeParser(),
        default_agent=True,
        agents_max_tokens=20000,
    ),
    "Submission_Checker_Agent": AgentConfig(
        name="Submission_Checker_Agent",
        description=prompts.SUBMISSION_AGENT_DESC,
        prompt=prompt_configs["Submission_Checker_Agent"],
        parser=None,
        agents_max_tokens=10000,
    ),
    "Submission_Question_Answer_Agent": AgentConfig(
        name="Submission_Question_Answer_Agent",
        description=prompts.SUBMISSION_QA_AGENT_DESC,
        prompt=prompt_configs["Submission_Question_Answer_Agent"],
        parser=None,
        agents_max_tokens=10000,
    ),
    "Tabular_Agent": AgentConfig(
        name="Tabular_Agent",
        description=prompts.TABULAR_AGENT_DESC,
        prompt=prompt_configs["Tabular_Agent"],
        parser=None,
        default_agent=True,
        agents_max_tokens=10000,
    ),
    "Datahub_Agent": AgentConfig(
        name="Datahub_Agent",
        description=prompts.DATAHUB_AGENT_DESC,
        prompt=prompt_configs["Datahub_Agent"],
        parser=None,
        agents_max_tokens=10000,
        default_agent=True),
    "Knowledge_Base_Retrieval_Agent": AgentConfig(
        name="Knowledge_Base_Retrieval_Agent",
        description=prompts.KNOWLEDGE_BASE_RETRIEVAL_AGENT_DESC,
        prompt=prompt_configs["Knowledge_Base_Retrieval_Agent"],
        agents_max_tokens=10000,
        parser=None,
    ),
}
