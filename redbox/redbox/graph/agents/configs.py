from pydantic import BaseModel, Field

from redbox.chains.parser import BaseCumulativeTransformOutputParser, ClaudeParser
from redbox.models import prompts
from redbox.models.settings import ChatLLMBackend


class PromptVariable(BaseModel):
    """
    This data class for storing variables that are used in the prompt template.
    """

    task: bool = Field(description="task information", default=False)
    expected_output: bool = Field(description="expected output from a task", default=False)
    metadata: bool = Field(description="file metadata containing file name, description, and keywords", default=False)
    chat_history: bool = Field(description="user chat history", default=False)
    question: bool = Field(description="user question", default=False)
    document_filenames: bool = Field(description="user selected document file names", default=False)
    format_instructions: bool = Field(description="format instruction for structured output", default=False)
    previous_plan: bool = Field(description="previous plan generated by planner", default=False)
    user_feedback: bool = Field(description="user feedback prompt", default=False)
    agents_results: bool = Field(description="information from other agents", default=False)
    formatted_documents: bool = Field(description="", default=False)


class PromptConfig(BaseModel):
    """
    This data class is for capturing prompt config
    """

    system: str = Field(description="sytem prompt")
    question: str | None = Field(description="question prompt", default=None)
    format: str | None = Field(description="prompt used for format instruction", default=None)
    prompt_vars: PromptVariable | None = Field(description="variables that are used in the prompt", default=None)


class PromptConfigs:
    """
    This class is for storing prompt configs for all the agents.
    """

    planner_agent = PromptConfig(
        system=prompts.PLANNER_PROMPT_TOP,
        question=prompts.PLANNER_QUESTION_PROMPT,
        format=prompts.PLANNER_FORMAT_PROMPT,
        prompt_var=PromptVariable(
            chat_history=True, question=True, document_filenames=True, metadata=True, format_instruction=True
        ),
    )

    replanner_agent = PromptConfig(
        system=prompts.REPLAN_PROMPT,
        question=prompts.PLANNER_QUESTION_PROMPT,
        format=prompts.PLANNER_FORMAT_PROMPT,
        prompt_var=PromptVariable(
            previous_plan=True,
            user_feedback=True,
            question=True,
            document_filenames=True,
            metadata=True,
            format_instruction=True,
        ),
    )

    internal_retrieval_agent = PromptConfig(
        system=prompts.INTERNAL_RETRIEVAL_AGENT_PROMPT,
        question=None,
        format=None,
        prompt_var=PromptVariable(task=True, expected_output=True, metadata=True),
    )

    web_search_agent = PromptConfig(
        system=prompts.WEB_SEARCH_AGENT_PROMPT,
        question=None,
        format=None,
        prompt_var=PromptVariable(task=True, expected_output=True, metadata=True),
    )

    summarisation_agent = PromptConfig(
        system=prompts.CHAT_WITH_DOCS_SYSTEM_PROMPT,
        question=prompts.CHAT_WITH_DOCS_QUESTION_PROMPT,
        format=None,
        prompt_var=PromptVariable(question=True, formatted_documents=True),
    )

    evaluator_agent = PromptConfig(
        system=prompts.NEW_ROUTE_RETRIEVAL_SYSTEM_PROMPT,
        question=prompts.NEW_ROUTE_RETRIEVAL_QUESTION_PROMPT,
        format=prompts.CITATION_PROMPT,
        prompt_var=PromptVariable(agents_results=True, question=True, format_instructions=True),
    )


class AgentConfig(BaseModel):
    name: str = Field(description="Name of agent")
    description: str = Field(description="Agent desciption used for planning", default="")
    prompt: PromptConfig = Field(description="Prompts used for this agent")
    tools: list | None = Field(description="A set of tools available for this agent", default=None)
    max_tokens: int = Field(
        description="Maximum tokens for this agent. Response exceed this limit will be truncated.", default=5000
    )
    llm_backend: ChatLLMBackend | None = Field(
        description="The LLM backend model used by the agent. Use None for default model", default=None
    )
    parser: BaseCumulativeTransformOutputParser | None = Field(description="Parser for structured output", default=None)


class AgentConfigs:
    planner_agent = AgentConfig(
        name="Planner_Agent",
        prompt=PromptConfigs.planner_agent,
        tools=[],
        llm_backend=ChatLLMBackend(name="sonnet-4", provider="bedrock"),
        parser=ClaudeParser(),
    )

    internal_retrieval_agent = AgentConfig(
        name="Internal_Retrieval_Agent",
        prompt=PromptConfigs.internal_retrieval_agent,
        tools=[],
        llm_backend=ChatLLMBackend(name="sonnet-4", provider="bedrock"),
        parser=ClaudeParser(),
    )

    web_search_agent = AgentConfig(
        name="Web_Search_Agent",
        prompt=PromptConfigs.internal_retrieval_agent,
        tools=[],
        llm_backend=ChatLLMBackend(name="sonnet-4", provider="bedrock"),
        parser=ClaudeParser(),
    )

    summarisation_agent = AgentConfig(
        name="Summarisation_Agent",
        prompt=PromptConfigs.summarisation_agent,
        tools=[],
        llm_backend=ChatLLMBackend(name="sonnet-4", provider="bedrock"),
        parser=ClaudeParser(),
    )
